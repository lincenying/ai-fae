2024-06-05 15:07:52,169 - mindformers[mindformers/tools/utils.py:155] - INFO - set output path to '/home/ma-user/work/mindformers/output'
[WARNING] DEVICE(11837,ffffacd61840,python):2024-06-05-15:07:52.537.712 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:103] Initialize] Reserved memory size for other components(1073741824) is less than recommend size(4008046592), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory'
[WARNING] HCCL_ADPT(11837,ffffacd61840,python):2024-06-05-15:08:14.979.763 [mindspore/ccsrc/plugin/device/ascend/hal/hccl_adapter/hccl_adapter.cc:63] GenHcclOptions] The environment variable DEPLOY_MODE is not set. Now set to default value 0
2024-06-05 15:08:14,985 - mindformers[mindformers/scripts/mf_parallel0/run_mindformer.py:116] - INFO - .........Build context config..........
2024-06-05 15:08:14,986 - mindformers[mindformers/core/parallel_config.py:39] - INFO - initial moe_config from dict: {'expert_num': 1, 'capacity_factor': 1.05, 'aux_loss_factor': 0.05, 'num_experts_chosen': 1}
2024-06-05 15:08:14,986 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': True, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}
2024-06-05 15:08:14,986 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 4, 'model_parallel': 1, 'pipeline_stage': 1, 'expert_parallel': 1, 'micro_batch_num': 1, 'vocab_emb_dp': True, 'gradient_aggregation_group': 4}
2024-06-05 15:08:14,987 - mindformers[mindformers/scripts/mf_parallel0/run_mindformer.py:118] - INFO - context config is: [ParallelConfig]
_recompute:[ParallelConfig]
_recompute:True
_select_recompute:False
_parallel_optimizer_comm_recompute:False
_mp_comm_recompute:True
_recompute_slice_activation:True

select_recompute:False
use_seq_parallel:False
_gradient_aggregation_group:4
_embed_dp_mp_config:[ParallelConfig]
_dp_mp_config:[ParallelConfig]
_data_parallel:4
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_vocab_emb_dp:True
use_seq_parallel:False
select_recompute:False

_pp_config:[ParallelConfig]
_pipeline_stage:1
_micro_batch_num:1

_moe_config:[ParallelConfig]
_dpmp:[ParallelConfig]
_data_parallel:4
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_expert_parallel:1
use_seq_parallel:False
select_recompute:False


2024-06-05 15:08:14,987 - mindformers[mindformers/scripts/mf_parallel0/run_mindformer.py:119] - INFO - moe config is: <mindformers.modules.transformer.moe.MoEConfig object at 0xfffda4713df0>
2024-06-05 15:08:14,988 - mindformers[mindformers/trainer/base_trainer.py:90] - INFO - Now Running Task is: text_generation, Model is: glm2_6b
2024-06-05 15:08:14,989 - mindformers[mindformers/trainer/base_trainer.py:196] - INFO - The current parallel mode is semi_auto_parallel, full batch is True,so global batch size will be changed: global_batch_size = batch_size * data_parallel * micro_batch_interleave_num * gradient_accumulation_steps = 32 = 8 * 4 * 1 * 1
2024-06-05 15:08:14,989 - mindformers[mindformers/trainer/base_trainer.py:624] - INFO - .........Build Dataset For Train..........
2024-06-05 15:08:14,989 - mindformers[mindformers/trainer/base_trainer.py:353] - INFO - .........Build Dataset From Config..........
2024-06-05 15:08:14,989 - mindformers[mindformers/dataset/keyword_gen_dataset.py:142] - INFO - Now Create Keyword Generation Dataset.
2024-06-05 15:08:16,542 - mindformers[mindformers/dataset/dataloader/adgen_dataloader.py:145] - INFO - Loading 114598 data success.
2024-06-05 15:08:16,542 - mindformers[mindformers/dataset/dataloader/adgen_dataloader.py:82] - INFO - [DATASET] shuffle status is True, phase is train.
2024-06-05 15:08:16,852 - mindformers[mindformers/trainer/utils.py:155] - INFO - Will be Training epochs:1, sink_size:4
2024-06-05 15:08:16,852 - mindformers[mindformers/trainer/utils.py:157] - INFO - Create training dataset finish, dataset size:3581
2024-06-05 15:08:16,853 - mindformers[mindformers/trainer/base_trainer.py:657] - INFO - .........Build Net For Train..........
2024-06-05 15:08:16,853 - mindformers[mindformers/trainer/base_trainer.py:388] - INFO - .........Build Network From Config..........
2024-06-05 15:08:16,854 - mindformers[mindformers/version_control.py:60] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1
2024-06-05 15:08:16,854 - mindformers[mindformers/version_control.py:64] - INFO - 
The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: 
export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.
2024-06-05 15:08:16,855 - mindformers[mindformers/version_control.py:73] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.
2024-06-05 15:08:16,869 - mindformers[mindformers/version_control.py:199] - INFO - Enable FlashAttention.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:08:16.892.471 [mindspore/common/parameter.py:786] This interface may be deleted in the future.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:21.366.117 [mindspore/train/serialization.py:1287] transformer.embedding.embedding_table is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:22.237.281 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:22.238.137 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:22.493.935 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:22.494.823 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:22.721.371 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:22.722.172 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:24.103.896 [mindspore/train/serialization.py:1287] transformer.encoder.layers.0.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:24.830.474 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:24.831.276 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:25.919.00 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:25.928.21 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:25.337.775 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:25.338.580 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:26.786.432 [mindspore/train/serialization.py:1287] transformer.encoder.layers.1.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:27.525.305 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:27.526.011 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:27.782.496 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:27.783.198 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:27.993.715 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:27.994.393 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:29.350.156 [mindspore/train/serialization.py:1287] transformer.encoder.layers.2.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:30.349.92 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:30.357.04 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:30.277.332 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:30.278.070 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:30.483.435 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:30.484.144 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:31.831.806 [mindspore/train/serialization.py:1287] transformer.encoder.layers.3.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:32.508.664 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:32.509.365 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:32.754.153 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:32.754.883 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:32.973.688 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:32.974.394 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:34.308.995 [mindspore/train/serialization.py:1287] transformer.encoder.layers.4.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:35.282.7 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:35.352.8 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:35.247.649 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:35.248.391 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:35.474.861 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:35.475.561 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:36.836.417 [mindspore/train/serialization.py:1287] transformer.encoder.layers.5.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:37.531.142 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:37.531.846 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:37.777.640 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:37.778.391 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:38.110.74 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:38.118.64 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:39.381.476 [mindspore/train/serialization.py:1287] transformer.encoder.layers.6.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:40.493.25 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:40.500.24 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:40.278.737 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:40.279.458 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:40.473.652 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:40.474.339 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:41.827.293 [mindspore/train/serialization.py:1287] transformer.encoder.layers.7.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:42.534.208 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:42.534.918 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:42.772.090 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:42.772.933 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:42.975.899 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:42.976.626 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:44.376.641 [mindspore/train/serialization.py:1287] transformer.encoder.layers.8.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:45.590.32 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:45.599.03 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:45.307.333 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:45.308.281 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:45.505.614 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:45.506.377 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:46.842.309 [mindspore/train/serialization.py:1287] transformer.encoder.layers.9.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:47.528.118 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:47.528.833 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:47.766.316 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:47.767.047 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:47.971.815 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:47.972.574 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:49.298.723 [mindspore/train/serialization.py:1287] transformer.encoder.layers.10.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:49.980.081 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:49.980.806 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:50.217.407 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:50.218.125 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:50.429.208 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:50.429.934 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:51.760.657 [mindspore/train/serialization.py:1287] transformer.encoder.layers.11.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:52.437.775 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:52.438.488 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:52.688.043 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:52.688.797 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:52.900.340 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:52.901.071 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:54.215.651 [mindspore/train/serialization.py:1287] transformer.encoder.layers.12.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:54.953.537 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:54.954.288 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:55.190.419 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:55.191.135 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:55.401.253 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:55.401.963 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:56.740.267 [mindspore/train/serialization.py:1287] transformer.encoder.layers.13.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:57.419.226 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:57.419.924 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:57.663.307 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:57.664.048 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:57.891.184 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:57.891.996 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:59.239.327 [mindspore/train/serialization.py:1287] transformer.encoder.layers.14.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:59.920.594 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:11:59.921.359 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:00.140.296 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:00.141.194 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:00.345.666 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:00.346.367 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:01.716.475 [mindspore/train/serialization.py:1287] transformer.encoder.layers.15.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:02.385.140 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:02.385.874 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:02.648.300 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:02.649.175 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:02.867.723 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:02.868.435 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:04.184.895 [mindspore/train/serialization.py:1287] transformer.encoder.layers.16.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:04.866.666 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:04.867.370 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:05.105.747 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:05.106.486 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:05.331.030 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:05.331.735 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:06.673.035 [mindspore/train/serialization.py:1287] transformer.encoder.layers.17.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:07.367.543 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:07.368.251 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:07.600.632 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:07.601.359 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:07.806.242 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:07.806.994 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:09.150.373 [mindspore/train/serialization.py:1287] transformer.encoder.layers.18.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:09.841.525 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:09.842.251 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:10.804.04 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:10.811.24 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:10.290.783 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:10.291.520 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:11.676.740 [mindspore/train/serialization.py:1287] transformer.encoder.layers.19.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:12.373.532 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:12.374.227 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:12.623.809 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:12.624.562 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:12.849.738 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:12.850.467 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:14.216.306 [mindspore/train/serialization.py:1287] transformer.encoder.layers.20.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:14.911.912 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:14.912.711 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:15.143.522 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:15.144.280 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:15.366.050 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:15.366.773 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:16.707.989 [mindspore/train/serialization.py:1287] transformer.encoder.layers.21.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:17.425.701 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:17.426.413 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:17.660.304 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:17.661.039 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:17.869.290 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:17.870.001 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:19.269.801 [mindspore/train/serialization.py:1287] transformer.encoder.layers.22.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:19.936.044 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:19.936.760 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:20.178.904 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:20.179.618 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:20.392.973 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:20.393.672 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:21.775.286 [mindspore/train/serialization.py:1287] transformer.encoder.layers.23.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:22.443.163 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:22.443.865 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:22.685.457 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:22.686.295 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:22.897.084 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:22.897.859 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:24.211.221 [mindspore/train/serialization.py:1287] transformer.encoder.layers.24.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:24.886.437 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:24.887.138 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:25.115.523 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:25.116.235 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:25.331.185 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:25.331.884 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:26.696.416 [mindspore/train/serialization.py:1287] transformer.encoder.layers.25.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:27.393.857 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:27.394.592 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:27.629.142 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:27.629.860 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:27.847.752 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:27.848.480 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:29.213.412 [mindspore/train/serialization.py:1287] transformer.encoder.layers.26.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:29.914.788 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.input_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:29.915.495 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.self_attention.query_key_value.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:30.145.615 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.self_attention.query_key_value.bias is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:30.146.321 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.self_attention.dense.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:30.345.410 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.post_attention_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:30.346.122 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.mlp.dense_h_to_4h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:31.742.870 [mindspore/train/serialization.py:1287] transformer.encoder.layers.27.mlp.dense_4h_to_h.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:32.427.221 [mindspore/train/serialization.py:1287] transformer.encoder.final_layernorm.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:32.427.938 [mindspore/train/serialization.py:1287] transformer.output_layer.weight is not init while load ckpt.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:36.247.613 [mindspore/train/serialization.py:183] The type of transformer.embedding.embedding_table:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:38.343.978 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.0.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:38.439.432 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.0.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:38.874.626 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.1.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:38.963.251 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.1.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:39.392.294 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.2.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:39.479.648 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.2.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:39.882.237 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.3.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:39.971.672 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.3.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:40.407.603 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.4.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:40.496.907 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.4.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:40.926.830 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.5.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:41.664.32 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.5.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:41.480.701 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.6.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:41.571.276 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.6.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:41.996.878 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.7.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:42.921.33 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.7.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:42.518.203 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.8.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:42.608.905 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.8.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:43.341.54 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.9.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:43.125.114 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.9.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:43.556.237 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.10.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:43.646.822 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.10.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:44.694.97 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.11.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:44.161.185 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.11.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:44.576.653 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.12.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:44.667.352 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.12.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:45.831.94 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.13.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:45.176.722 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.13.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:45.600.341 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.14.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:45.690.631 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.14.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:46.109.072 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.15.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:46.199.868 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.15.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:46.627.318 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.16.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:46.717.252 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.16.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:47.133.285 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.17.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:47.223.278 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.17.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:47.646.435 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.18.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:47.736.387 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.18.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:48.158.011 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.19.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:48.248.696 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.19.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:48.663.131 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.20.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:48.753.192 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.20.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:49.181.408 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.21.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:49.272.085 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.21.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:49.689.110 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.22.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:49.779.860 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.22.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:50.200.528 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.23.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:50.291.356 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.23.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:50.707.235 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.24.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:50.798.126 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.24.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:51.215.471 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.25.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:51.306.048 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.25.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:51.716.751 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.26.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:51.813.102 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.26.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:52.234.093 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.27.input_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:52.329.654 [mindspore/train/serialization.py:183] The type of transformer.encoder.layers.27.post_attention_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:52.738.049 [mindspore/train/serialization.py:183] The type of transformer.encoder.final_layernorm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
2024-06-05 15:12:53,405 - mindformers[mindformers/models/base_model.py:115] - INFO - weights in /home/ma-user/work/mindformers/research/glmv2/glm2_6b.ckpt are loaded
2024-06-05 15:12:53,420 - mindformers[mindformers/trainer/base_trainer.py:539] - INFO - Network Parameters: 6243 M.
2024-06-05 15:12:53,421 - mindformers[mindformers/trainer/base_trainer.py:682] - INFO - .........Build Optimizer For Train..........
2024-06-05 15:12:53,421 - mindformers[mindformers/trainer/base_trainer.py:435] - INFO - .........Build Optimizer From Config..........
2024-06-05 15:12:53,421 - mindformers[mindformers/trainer/base_trainer.py:468] - INFO - .........Build LR Schedule From Config..........
2024-06-05 15:12:53,425 - mindformers[mindformers/trainer/optimizer_grouped_parameters.py:74] - WARNING - dynamic_lr_schedule will be reset and invalid when layer_scale is False.
2024-06-05 15:12:53,428 - mindformers[mindformers/trainer/optimizer_grouped_parameters.py:113] - INFO - Param groups = {
  "decay": {
    "weight_decay": 0.1,
    "params": [
      "transformer.embedding.embedding_table",
      "transformer.encoder.layers.0.self_attention.query_key_value.weight",
      "transformer.encoder.layers.0.self_attention.dense.weight",
      "transformer.encoder.layers.0.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.0.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.1.self_attention.query_key_value.weight",
      "transformer.encoder.layers.1.self_attention.dense.weight",
      "transformer.encoder.layers.1.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.1.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.2.self_attention.query_key_value.weight",
      "transformer.encoder.layers.2.self_attention.dense.weight",
      "transformer.encoder.layers.2.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.2.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.3.self_attention.query_key_value.weight",
      "transformer.encoder.layers.3.self_attention.dense.weight",
      "transformer.encoder.layers.3.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.3.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.4.self_attention.query_key_value.weight",
      "transformer.encoder.layers.4.self_attention.dense.weight",
      "transformer.encoder.layers.4.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.4.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.5.self_attention.query_key_value.weight",
      "transformer.encoder.layers.5.self_attention.dense.weight",
      "transformer.encoder.layers.5.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.5.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.6.self_attention.query_key_value.weight",
      "transformer.encoder.layers.6.self_attention.dense.weight",
      "transformer.encoder.layers.6.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.6.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.7.self_attention.query_key_value.weight",
      "transformer.encoder.layers.7.self_attention.dense.weight",
      "transformer.encoder.layers.7.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.7.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.8.self_attention.query_key_value.weight",
      "transformer.encoder.layers.8.self_attention.dense.weight",
      "transformer.encoder.layers.8.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.8.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.9.self_attention.query_key_value.weight",
      "transformer.encoder.layers.9.self_attention.dense.weight",
      "transformer.encoder.layers.9.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.9.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.10.self_attention.query_key_value.weight",
      "transformer.encoder.layers.10.self_attention.dense.weight",
      "transformer.encoder.layers.10.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.10.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.11.self_attention.query_key_value.weight",
      "transformer.encoder.layers.11.self_attention.dense.weight",
      "transformer.encoder.layers.11.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.11.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.12.self_attention.query_key_value.weight",
      "transformer.encoder.layers.12.self_attention.dense.weight",
      "transformer.encoder.layers.12.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.12.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.13.self_attention.query_key_value.weight",
      "transformer.encoder.layers.13.self_attention.dense.weight",
      "transformer.encoder.layers.13.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.13.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.14.self_attention.query_key_value.weight",
      "transformer.encoder.layers.14.self_attention.dense.weight",
      "transformer.encoder.layers.14.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.14.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.15.self_attention.query_key_value.weight",
      "transformer.encoder.layers.15.self_attention.dense.weight",
      "transformer.encoder.layers.15.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.15.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.16.self_attention.query_key_value.weight",
      "transformer.encoder.layers.16.self_attention.dense.weight",
      "transformer.encoder.layers.16.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.16.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.17.self_attention.query_key_value.weight",
      "transformer.encoder.layers.17.self_attention.dense.weight",
      "transformer.encoder.layers.17.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.17.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.18.self_attention.query_key_value.weight",
      "transformer.encoder.layers.18.self_attention.dense.weight",
      "transformer.encoder.layers.18.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.18.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.19.self_attention.query_key_value.weight",
      "transformer.encoder.layers.19.self_attention.dense.weight",
      "transformer.encoder.layers.19.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.19.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.20.self_attention.query_key_value.weight",
      "transformer.encoder.layers.20.self_attention.dense.weight",
      "transformer.encoder.layers.20.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.20.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.21.self_attention.query_key_value.weight",
      "transformer.encoder.layers.21.self_attention.dense.weight",
      "transformer.encoder.layers.21.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.21.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.22.self_attention.query_key_value.weight",
      "transformer.encoder.layers.22.self_attention.dense.weight",
      "transformer.encoder.layers.22.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.22.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.23.self_attention.query_key_value.weight",
      "transformer.encoder.layers.23.self_attention.dense.weight",
      "transformer.encoder.layers.23.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.23.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.24.self_attention.query_key_value.weight",
      "transformer.encoder.layers.24.self_attention.dense.weight",
      "transformer.encoder.layers.24.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.24.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.25.self_attention.query_key_value.weight",
      "transformer.encoder.layers.25.self_attention.dense.weight",
      "transformer.encoder.layers.25.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.25.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.26.self_attention.query_key_value.weight",
      "transformer.encoder.layers.26.self_attention.dense.weight",
      "transformer.encoder.layers.26.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.26.mlp.dense_4h_to_h.weight",
      "transformer.encoder.layers.27.self_attention.query_key_value.weight",
      "transformer.encoder.layers.27.self_attention.dense.weight",
      "transformer.encoder.layers.27.mlp.dense_h_to_4h.weight",
      "transformer.encoder.layers.27.mlp.dense_4h_to_h.weight",
      "transformer.output_layer.weight"
    ]
  },
  "no_decay": {
    "weight_decay": 0.0,
    "params": [
      "transformer.encoder.layers.0.input_layernorm.weight",
      "transformer.encoder.layers.0.self_attention.query_key_value.bias",
      "transformer.encoder.layers.0.post_attention_layernorm.weight",
      "transformer.encoder.layers.1.input_layernorm.weight",
      "transformer.encoder.layers.1.self_attention.query_key_value.bias",
      "transformer.encoder.layers.1.post_attention_layernorm.weight",
      "transformer.encoder.layers.2.input_layernorm.weight",
      "transformer.encoder.layers.2.self_attention.query_key_value.bias",
      "transformer.encoder.layers.2.post_attention_layernorm.weight",
      "transformer.encoder.layers.3.input_layernorm.weight",
      "transformer.encoder.layers.3.self_attention.query_key_value.bias",
      "transformer.encoder.layers.3.post_attention_layernorm.weight",
      "transformer.encoder.layers.4.input_layernorm.weight",
      "transformer.encoder.layers.4.self_attention.query_key_value.bias",
      "transformer.encoder.layers.4.post_attention_layernorm.weight",
      "transformer.encoder.layers.5.input_layernorm.weight",
      "transformer.encoder.layers.5.self_attention.query_key_value.bias",
      "transformer.encoder.layers.5.post_attention_layernorm.weight",
      "transformer.encoder.layers.6.input_layernorm.weight",
      "transformer.encoder.layers.6.self_attention.query_key_value.bias",
      "transformer.encoder.layers.6.post_attention_layernorm.weight",
      "transformer.encoder.layers.7.input_layernorm.weight",
      "transformer.encoder.layers.7.self_attention.query_key_value.bias",
      "transformer.encoder.layers.7.post_attention_layernorm.weight",
      "transformer.encoder.layers.8.input_layernorm.weight",
      "transformer.encoder.layers.8.self_attention.query_key_value.bias",
      "transformer.encoder.layers.8.post_attention_layernorm.weight",
      "transformer.encoder.layers.9.input_layernorm.weight",
      "transformer.encoder.layers.9.self_attention.query_key_value.bias",
      "transformer.encoder.layers.9.post_attention_layernorm.weight",
      "transformer.encoder.layers.10.input_layernorm.weight",
      "transformer.encoder.layers.10.self_attention.query_key_value.bias",
      "transformer.encoder.layers.10.post_attention_layernorm.weight",
      "transformer.encoder.layers.11.input_layernorm.weight",
      "transformer.encoder.layers.11.self_attention.query_key_value.bias",
      "transformer.encoder.layers.11.post_attention_layernorm.weight",
      "transformer.encoder.layers.12.input_layernorm.weight",
      "transformer.encoder.layers.12.self_attention.query_key_value.bias",
      "transformer.encoder.layers.12.post_attention_layernorm.weight",
      "transformer.encoder.layers.13.input_layernorm.weight",
      "transformer.encoder.layers.13.self_attention.query_key_value.bias",
      "transformer.encoder.layers.13.post_attention_layernorm.weight",
      "transformer.encoder.layers.14.input_layernorm.weight",
      "transformer.encoder.layers.14.self_attention.query_key_value.bias",
      "transformer.encoder.layers.14.post_attention_layernorm.weight",
      "transformer.encoder.layers.15.input_layernorm.weight",
      "transformer.encoder.layers.15.self_attention.query_key_value.bias",
      "transformer.encoder.layers.15.post_attention_layernorm.weight",
      "transformer.encoder.layers.16.input_layernorm.weight",
      "transformer.encoder.layers.16.self_attention.query_key_value.bias",
      "transformer.encoder.layers.16.post_attention_layernorm.weight",
      "transformer.encoder.layers.17.input_layernorm.weight",
      "transformer.encoder.layers.17.self_attention.query_key_value.bias",
      "transformer.encoder.layers.17.post_attention_layernorm.weight",
      "transformer.encoder.layers.18.input_layernorm.weight",
      "transformer.encoder.layers.18.self_attention.query_key_value.bias",
      "transformer.encoder.layers.18.post_attention_layernorm.weight",
      "transformer.encoder.layers.19.input_layernorm.weight",
      "transformer.encoder.layers.19.self_attention.query_key_value.bias",
      "transformer.encoder.layers.19.post_attention_layernorm.weight",
      "transformer.encoder.layers.20.input_layernorm.weight",
      "transformer.encoder.layers.20.self_attention.query_key_value.bias",
      "transformer.encoder.layers.20.post_attention_layernorm.weight",
      "transformer.encoder.layers.21.input_layernorm.weight",
      "transformer.encoder.layers.21.self_attention.query_key_value.bias",
      "transformer.encoder.layers.21.post_attention_layernorm.weight",
      "transformer.encoder.layers.22.input_layernorm.weight",
      "transformer.encoder.layers.22.self_attention.query_key_value.bias",
      "transformer.encoder.layers.22.post_attention_layernorm.weight",
      "transformer.encoder.layers.23.input_layernorm.weight",
      "transformer.encoder.layers.23.self_attention.query_key_value.bias",
      "transformer.encoder.layers.23.post_attention_layernorm.weight",
      "transformer.encoder.layers.24.input_layernorm.weight",
      "transformer.encoder.layers.24.self_attention.query_key_value.bias",
      "transformer.encoder.layers.24.post_attention_layernorm.weight",
      "transformer.encoder.layers.25.input_layernorm.weight",
      "transformer.encoder.layers.25.self_attention.query_key_value.bias",
      "transformer.encoder.layers.25.post_attention_layernorm.weight",
      "transformer.encoder.layers.26.input_layernorm.weight",
      "transformer.encoder.layers.26.self_attention.query_key_value.bias",
      "transformer.encoder.layers.26.post_attention_layernorm.weight",
      "transformer.encoder.layers.27.input_layernorm.weight",
      "transformer.encoder.layers.27.self_attention.query_key_value.bias",
      "transformer.encoder.layers.27.post_attention_layernorm.weight",
      "transformer.encoder.final_layernorm.weight"
    ]
  }
}
2024-06-05 15:12:53,579 - mindformers[mindformers/trainer/base_trainer.py:688] - INFO - .........Build Running Wrapper From Config For Train..........
2024-06-05 15:12:53,579 - mindformers[mindformers/trainer/base_trainer.py:505] - INFO - .........Build Model Wrapper for Train From Config..........
2024-06-05 15:12:53,590 - mindformers[mindformers/trainer/base_trainer.py:695] - INFO - .........Build Callbacks For Train..........
2024-06-05 15:12:53,592 - mindformers[mindformers/core/callback/callback.py:531] - INFO - Integrated_save is changed to False when using auto_parallel.
2024-06-05 15:12:53,594 - mindformers[mindformers/trainer/base_trainer.py:730] - INFO - .........Starting Init Train Model..........
2024-06-05 15:12:53,594 - mindformers[mindformers/trainer/base_trainer.py:765] - INFO - .........Starting Training Model..........
{'auto_trans_ckpt': False,
 'auto_tune': False,
 'autotune_per_step': 10,
 'callbacks': [OrderedDict([('type', 'MFLossMonitor')]),
               OrderedDict([('type', 'CheckpointMointor'),
                            ('prefix', 'glm2-6b'),
                            ('save_checkpoint_steps', 1000),
                            ('keep_checkpoint_max', 1),
                            ('integrated_save', False),
                            ('async_save', False)]),
               OrderedDict([('type', 'ObsMonitor'), ('keep_last', False)])],
 'context': {'device_id': 0,
             'device_target': 'Ascend',
             'enable_graph_kernel': False,
             'graph_kernel_flags': '--disable_expand_ops=Softmax,Dropout '
                                   '--enable_parallel_fusion=true '
                                   '--reduce_fuse_depth=8 '
                                   '--enable_auto_tensor_inplace=true',
             'max_call_depth': 10000,
             'save_graphs': False},
 'data_size': 3581,
 'device_num': 4,
 'do_eval': False,
 'eval_callbacks': [OrderedDict([('type', 'ObsMonitor'),
                                 ('keep_last', False)])],
 'eval_dataset': {'auto_tune': False,
                  'autotune_per_step': 10,
                  'batch_size': 32,
                  'data_loader': {'dataset_dir': '/home/ma-user/work/mindformers/research/glmv2/AdvertiseGen/dev.json',
                                  'origin_columns': ['content', 'summary'],
                                  'phase': 'train',
                                  'shuffle': False,
                                  'type': 'ADGenDataLoader',
                                  'version': 2},
                  'do_eval': True,
                  'drop_remainder': True,
                  'filepath_prefix': './autotune',
                  'ignore_pad_token_for_loss': True,
                  'input_columns': ['input_ids', 'labels'],
                  'max_source_length': 64,
                  'max_target_length': 127,
                  'num_parallel_workers': 8,
                  'numa_enable': False,
                  'prefetch_size': 1,
                  'profile': False,
                  'python_multiprocessing': False,
                  'repeat': 1,
                  'seed': 0,
                  'tokenizer': {'type': 'ChatGLM2Tokenizer',
                                'vocab_file': '/home/ma-user/work/mindformers/research/glmv2/tokenizer.model'}},
 'eval_dataset_task': {'dataset_config': {'auto_tune': False,
                                          'autotune_per_step': 10,
                                          'batch_size': 32,
                                          'data_loader': {'dataset_dir': '/home/ma-user/work/mindformers/research/glmv2/AdvertiseGen/dev.json',
                                                          'origin_columns': ['content',
                                                                             'summary'],
                                                          'phase': 'train',
                                                          'shuffle': False,
                                                          'type': 'ADGenDataLoader',
                                                          'version': 2},
                                          'do_eval': True,
                                          'drop_remainder': True,
                                          'filepath_prefix': './autotune',
                                          'ignore_pad_token_for_loss': True,
                                          'input_columns': ['input_ids',
                                                            'labels'],
                                          'max_source_length': 64,
                                          'max_target_length': 127,
                                          'num_parallel_workers': 8,
                                          'numa_enable': False,
                                          'prefetch_size': 1,
                                          'profile': False,
                                          'python_multiprocessing': False,
                                          'repeat': 1,
                                          'seed': 0,
                                          'tokenizer': {'type': 'ChatGLM2Tokenizer',
                                                        'vocab_file': '/home/ma-user/work/mindformers/research/glmv2/tokenizer.model'}},
                       'type': 'KeyWordGenDataset'},
 'eval_epoch_interval': -1,
 'eval_step_interval': 1788,
 'filepath_prefix': './autotune',
 'init_start_profile': True,
 'layer_decay': 0.65,
 'layer_scale': False,
 'load_checkpoint': None,
 'local_rank': 0,
 'lr_scale': False,
 'lr_scale_factor': 256,
 'lr_schedule': {'learning_rate': 5e-05,
                 'lr_end': 1e-06,
                 'total_steps': 3580,
                 'type': 'polynomial',
                 'warmup_steps': 0},
 'metric': {'type': 'PerplexityMetric'},
 'micro_batch_interleave_num': 1,
 'model': {'arch': {'type': 'ChatGLM2ForConditionalGeneration'},
           'model_config': {'add_bias_linear': False,
                            'add_qkv_bias': True,
                            'apply_query_key_layer_scaling': True,
                            'apply_residual_connection_post_layernorm': False,
                            'attention_dropout': 0.0,
                            'attention_softmax_in_fp32': True,
                            'batch_size': 1,
                            'bias_dropout_fusion': True,
                            'checkpoint_name_or_path': '/home/ma-user/work/mindformers/research/glmv2/glm2_6b.ckpt',
                            'compute_dtype': 'float16',
                            'do_sample': True,
                            'eos_token_id': 2,
                            'ffn_hidden_size': 13696,
                            'fp32_residual_connection': False,
                            'hidden_dropout': 0.0,
                            'hidden_size': 4096,
                            'kv_channels': 128,
                            'layernorm_compute_type': 'float32',
                            'layernorm_epsilon': '1e-5',
                            'max_decode_length': 256,
                            'multi_query_attention': True,
                            'multi_query_group_num': 2,
                            'num_attention_heads': 32,
                            'num_layers': 28,
                            'pad_token_id': 0,
                            'padded_vocab_size': 65024,
                            'param_init_type': 'float16',
                            'post_layer_norm': True,
                            'pre_seq_len': 0,
                            'prefix_projection': False,
                            'quantization_bit': 0,
                            'repetition_penalty': 1.0,
                            'rmsnorm': True,
                            'seq_length': 192,
                            'top_k': 1,
                            'top_p': 1,
                            'type': 'ChatGLM2Config',
                            'use_flash_attention': True,
                            'use_past': False}},
 'moe_config': <mindformers.modules.transformer.moe.MoEConfig object at 0xfffda4713df0>,
 'only_save_strategy': False,
 'optimizer': {'beta1': 0.9,
               'beta2': 0.95,
               'eps': 1e-08,
               'type': 'FP32StateAdamWeightDecay',
               'weight_decay': 0.1},
 'output_dir': '../.././output',
 'parallel': {'device_num': 4,
              'enable_alltoall': False,
              'enable_parallel_optimizer': True,
              'full_batch': True,
              'gradients_mean': False,
              'loss_repeated_mean': True,
              'parallel_mode': 'semi_auto_parallel',
              'search_mode': 'sharding_propagation',
              'strategy_ckpt_config': {'save_file': './ckpt_strategy.ckpt'},
              'strategy_ckpt_save_file': '../.././output/strategy/ckpt_strategy_rank_0.ckpt'},
 'parallel_config': <mindformers.modules.transformer.transformer.TransformerOpParallelConfig object at 0xfffde4751550>,
 'processor': {'return_tensors': 'ms',
               'tokenizer': {'bos_token': '<sop>',
                             'end_token': '</s>',
                             'eos_token': '<eop>',
                             'gmask_token': '[gMASK]',
                             'mask_token': '[MASK]',
                             'pad_token': '<pad>',
                             'type': 'ChatGLM2Tokenizer',
                             'unk_token': '<unk>'},
               'type': 'GLMProcessor'},
 'profile': False,
 'profile_communication': True,
 'profile_memory': True,
 'profile_start_step': 1,
 'profile_stop_step': 10,
 'recompute_config': <mindformers.modules.transformer.transformer.TransformerRecomputeConfig object at 0xfffeb4183ee0>,
 'remote_save_url': 'Please input obs url on AICC platform.',
 'resume_training': False,
 'run_mode': 'finetune',
 'runner_config': {'batch_size': 32,
                   'epochs': 895,
                   'gradient_accumulation_steps': 1,
                   'initial_epoch': 0,
                   'initial_step': 0,
                   'origin_epochs': 1,
                   'sink_mode': True,
                   'sink_size': 4},
 'runner_wrapper': {'scale_sense': DynamicLossScaleUpdateCell<>,
                    'type': 'MFTrainOneStepCell',
                    'use_clip_grad': True},
 'seed': 0,
 'src_strategy_path_or_dir': '',
 'train_dataset': {'auto_tune': False,
                   'autotune_per_step': 10,
                   'batch_size': 32,
                   'data_loader': {'origin_columns': ['content', 'summary'],
                                   'phase': 'train',
                                   'shuffle': True,
                                   'type': 'ADGenDataLoader',
                                   'version': 2},
                   'device_num': None,
                   'do_eval': False,
                   'drop_remainder': True,
                   'filepath_prefix': './autotune',
                   'ignore_pad_token_for_loss': True,
                   'input_columns': ['input_ids', 'labels'],
                   'max_source_length': 64,
                   'max_target_length': 127,
                   'num_parallel_workers': 8,
                   'numa_enable': False,
                   'prefetch_size': 1,
                   'profile': False,
                   'python_multiprocessing': False,
                   'rank_id': None,
                   'repeat': 1,
                   'seed': 0,
                   'tokenizer': {'type': 'ChatGLM2Tokenizer',
                                 'vocab_file': '/home/ma-user/work/mindformers/research/glmv2/tokenizer.model'}},
 'train_dataset_task': {'dataset_config': {'auto_tune': False,
                                           'autotune_per_step': 10,
                                           'batch_size': 32,
                                           'data_loader': {'origin_columns': ['content',
                                                                              'summary'],
                                                           'phase': 'train',
                                                           'shuffle': True,
                                                           'type': 'ADGenDataLoader',
                                                           'version': 2},
                                           'device_num': None,
                                           'do_eval': False,
                                           'drop_remainder': True,
                                           'filepath_prefix': './autotune',
                                           'ignore_pad_token_for_loss': True,
                                           'input_columns': ['input_ids',
                                                             'labels'],
                                           'max_source_length': 64,
                                           'max_target_length': 127,
                                           'num_parallel_workers': 8,
                                           'numa_enable': False,
                                           'prefetch_size': 1,
                                           'profile': False,
                                           'python_multiprocessing': False,
                                           'rank_id': None,
                                           'repeat': 1,
                                           'seed': 0,
                                           'tokenizer': {'type': 'ChatGLM2Tokenizer',
                                                         'vocab_file': '/home/ma-user/work/mindformers/research/glmv2/tokenizer.model'}},
                        'type': 'KeyWordGenDataset'},
 'trainer': {'model_name': 'glm2_6b', 'type': 'CausalLanguageModelingTrainer'},
 'use_parallel': True}
2024-06-05 15:12:53,600 - mindformers[mindformers/trainer/base_trainer.py:768] - INFO - .........Model Compiling, Please Wait a Moment...........
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:53.601.389 [mindspore/train/model.py:1106] For MFLossMonitor callback, {'epoch_begin', 'step_begin', 'step_end', 'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:53.601.524 [mindspore/train/model.py:1106] For Local2ObsMonitor callback, {'step_end', 'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.
[WARNING] ME(11837:281473581455424,MainProcess):2024-06-05-15:12:53.601.852 [mindspore/train/model.py:651] In dataset_sink mode (dataset_size % sink_size) should equal to 0, it is suggested to pad/drop data or adjust sink_size. But got 'dataset_size': 3581, 'sink_size': 4.
2024-06-05 15:12:53,610 - mindformers[mindformers/models/base_tokenizer.py:2293] - WARNING - Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
[WARNING] UTILS(11837,ffffacd61840,python):2024-06-05-15:13:04.432.903 [mindspore/ccsrc/utils/parallel_context.cc:268] ParallelParameterContextRestoreShape] The parameter scale_sense's parameter_shape in param_info is empty
[WARNING] UTILS(11837,ffffacd61840,python):2024-06-05-15:13:04.434.374 [mindspore/ccsrc/utils/parallel_context.cc:268] ParallelParameterContextRestoreShape] The parameter current_iterator_step's parameter_shape in param_info is empty
[WARNING] UTILS(11837,ffffacd61840,python):2024-06-05-15:13:04.434.415 [mindspore/ccsrc/utils/parallel_context.cc:268] ParallelParameterContextRestoreShape] The parameter last_overflow_iterator_step's parameter_shape in param_info is empty
[WARNING] PARALLEL(11837,ffffacd61840,python):2024-06-05-15:13:59.086.104 [mindspore/ccsrc/frontend/parallel/step_parallel.cc:1986] ReshapeInit] FindNextLayout return nullptr, if reshape is not the last primitive, there must be some error
-
\
|
/
2024-06-05 15:17:29,059 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[    4/ 3581], loss: 5.851, per_step_time: 68041ms, lr: 5e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:29,078 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.1% |                                                  | 0.11758 samples/s/p  2 days, 19:36:23 }
2024-06-05 15:17:33,279 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[    8/ 3581], loss: 3.504, per_step_time: 827ms, lr: 4.9945247e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:33,288 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.2% |                                                  | 9.66659 samples/s/p  0:49:16 }
2024-06-05 15:17:36,593 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   12/ 3581], loss: 3.486, per_step_time: 822ms, lr: 4.9890503e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:36,593 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.3% |                                                  | 9.73214 samples/s/p  0:48:53 }
2024-06-05 15:17:39,880 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   16/ 3581], loss: 3.356, per_step_time: 820ms, lr: 4.983575e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:39,880 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.4% |                                                  | 9.75084 samples/s/p  0:48:44 }
2024-06-05 15:17:43,175 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   20/ 3581], loss: 3.395, per_step_time: 822ms, lr: 4.9781003e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:43,175 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.6% |                                                  | 9.72563 samples/s/p  0:48:49 }
2024-06-05 15:17:46,467 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   24/ 3581], loss: 3.283, per_step_time: 821ms, lr: 4.9726255e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:46,468 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.7% |                                                  | 9.74075 samples/s/p  0:48:41 }
2024-06-05 15:17:49,755 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   28/ 3581], loss: 3.332, per_step_time: 820ms, lr: 4.9671507e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:49,755 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.8% |                                                  | 9.74929 samples/s/p  0:48:35 }
2024-06-05 15:17:53,062 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   32/ 3581], loss: 3.331, per_step_time: 825ms, lr: 4.961676e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:53,063 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    0.9% |                                                  | 9.68947 samples/s/p  0:48:50 }
2024-06-05 15:17:56,359 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   36/ 3581], loss: 3.430, per_step_time: 822ms, lr: 4.9562008e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:56,360 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.0% |                                                  | 9.72197 samples/s/p  0:48:37 }
2024-06-05 15:17:59,657 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   40/ 3581], loss: 3.367, per_step_time: 823ms, lr: 4.9507264e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:17:59,657 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.1% |                                                  | 9.71821 samples/s/p  0:48:34 }
2024-06-05 15:18:02,937 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   44/ 3581], loss: 3.158, per_step_time: 818ms, lr: 4.9452512e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:02,937 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.2% |                                                  | 9.77156 samples/s/p  0:48:15 }
2024-06-05 15:18:06,223 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   48/ 3581], loss: 3.204, per_step_time: 820ms, lr: 4.9397764e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:06,223 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.3% |                                                  | 9.75446 samples/s/p  0:48:17 }
2024-06-05 15:18:09,520 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   52/ 3581], loss: 3.214, per_step_time: 823ms, lr: 4.9343016e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:09,521 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.5% |                                                  | 9.71909 samples/s/p  0:48:24 }
2024-06-05 15:18:12,812 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   56/ 3581], loss: 3.254, per_step_time: 821ms, lr: 4.9288265e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:12,813 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.6% |                                                  | 9.73597 samples/s/p  0:48:16 }
2024-06-05 15:18:16,109 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   60/ 3581], loss: 3.079, per_step_time: 822ms, lr: 4.9233517e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:16,109 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.7% |                                                  | 9.72088 samples/s/p  0:48:17 }
2024-06-05 15:18:19,413 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   64/ 3581], loss: 3.239, per_step_time: 824ms, lr: 4.9178772e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:19,413 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.8% |                                                  | 9.70220 samples/s/p  0:48:19 }
2024-06-05 15:18:22,703 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   68/ 3581], loss: 3.183, per_step_time: 821ms, lr: 4.912402e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:22,704 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    1.9% |                                                  | 9.74001 samples/s/p  0:48:05 }
2024-06-05 15:18:25,993 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   72/ 3581], loss: 3.179, per_step_time: 821ms, lr: 4.9069273e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:25,993 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.0% |                                                 | 9.74196 samples/s/p  0:48:01 }
2024-06-05 15:18:29,288 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   76/ 3581], loss: 3.294, per_step_time: 822ms, lr: 4.901452e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:29,288 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.1% |                                                 | 9.72767 samples/s/p  0:48:02 }
2024-06-05 15:18:32,577 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   80/ 3581], loss: 2.903, per_step_time: 820ms, lr: 4.8959777e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:32,578 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.2% |                                                 | 9.75289 samples/s/p  0:47:51 }
2024-06-05 15:18:35,865 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   84/ 3581], loss: 3.015, per_step_time: 820ms, lr: 4.890502e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:35,865 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.3% |                                                 | 9.75161 samples/s/p  0:47:48 }
2024-06-05 15:18:39,152 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   88/ 3581], loss: 3.170, per_step_time: 820ms, lr: 4.8850277e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:39,153 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.5% |                                                 | 9.74962 samples/s/p  0:47:46 }
2024-06-05 15:18:42,436 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   92/ 3581], loss: 3.043, per_step_time: 819ms, lr: 4.879553e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:42,437 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.6% |                                                 | 9.76126 samples/s/p  0:47:39 }
2024-06-05 15:18:45,724 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[   96/ 3581], loss: 3.187, per_step_time: 820ms, lr: 4.8740778e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:45,724 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.7% |                                                 | 9.75010 samples/s/p  0:47:39 }
2024-06-05 15:18:49,021 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  100/ 3581], loss: 2.881, per_step_time: 823ms, lr: 4.8686034e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:49,022 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.8% |                                                 | 9.71957 samples/s/p  0:47:45 }
2024-06-05 15:18:52,309 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  104/ 3581], loss: 3.114, per_step_time: 820ms, lr: 4.8631286e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:52,309 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    2.9% |                                                 | 9.74848 samples/s/p  0:47:33 }
2024-06-05 15:18:55,616 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  108/ 3581], loss: 3.105, per_step_time: 825ms, lr: 4.8576534e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:55,616 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.0% |                                                 | 9.69201 samples/s/p  0:47:46 }
2024-06-05 15:18:58,904 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  112/ 3581], loss: 3.020, per_step_time: 820ms, lr: 4.8521786e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:18:58,904 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.1% |                                                 | 9.74916 samples/s/p  0:47:26 }
2024-06-05 15:19:02,191 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  116/ 3581], loss: 3.045, per_step_time: 820ms, lr: 4.8467035e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:02,192 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.2% |                                                 | 9.74833 samples/s/p  0:47:23 }
2024-06-05 15:19:05,478 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  120/ 3581], loss: 3.082, per_step_time: 820ms, lr: 4.841229e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:05,478 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.4% |                                                 | 9.75341 samples/s/p  0:47:18 }
2024-06-05 15:19:08,768 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  124/ 3581], loss: 3.121, per_step_time: 821ms, lr: 4.8357535e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:08,768 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.5% |                                                 | 9.74359 samples/s/p  0:47:18 }
2024-06-05 15:19:12,053 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  128/ 3581], loss: 3.168, per_step_time: 819ms, lr: 4.830279e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:12,053 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.6% |                                                 | 9.75785 samples/s/p  0:47:10 }
2024-06-05 15:19:15,329 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  132/ 3581], loss: 3.161, per_step_time: 817ms, lr: 4.8248043e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:15,329 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.7% |                                                 | 9.78386 samples/s/p  0:47:00 }
2024-06-05 15:19:18,611 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  136/ 3581], loss: 3.008, per_step_time: 819ms, lr: 4.819329e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:18,612 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.8% |                                                 | 9.76491 samples/s/p  0:47:02 }
2024-06-05 15:19:21,891 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  140/ 3581], loss: 2.904, per_step_time: 818ms, lr: 4.8138547e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:21,891 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    3.9% |                                                 | 9.77226 samples/s/p  0:46:56 }
2024-06-05 15:19:25,175 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  144/ 3581], loss: 3.089, per_step_time: 819ms, lr: 4.80838e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:25,175 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.0% |                                                | 9.76141 samples/s/p  0:46:56 }
2024-06-05 15:19:28,454 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  148/ 3581], loss: 3.039, per_step_time: 818ms, lr: 4.8029047e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:28,455 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.1% |                                                | 9.77197 samples/s/p  0:46:50 }
2024-06-05 15:19:31,741 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  152/ 3581], loss: 2.996, per_step_time: 820ms, lr: 4.79743e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:31,741 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.2% |                                                | 9.75317 samples/s/p  0:46:52 }
2024-06-05 15:19:35,040 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  156/ 3581], loss: 3.085, per_step_time: 823ms, lr: 4.7919548e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:35,040 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.4% |                                                | 9.71405 samples/s/p  0:47:00 }
2024-06-05 15:19:38,343 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  160/ 3581], loss: 2.975, per_step_time: 824ms, lr: 4.7864803e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:38,344 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.5% |                                                | 9.70476 samples/s/p  0:47:00 }
2024-06-05 15:19:41,629 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  164/ 3581], loss: 3.014, per_step_time: 820ms, lr: 4.7810056e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:41,630 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.6% |                                                | 9.75460 samples/s/p  0:46:42 }
2024-06-05 15:19:44,905 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  168/ 3581], loss: 3.032, per_step_time: 817ms, lr: 4.7755304e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:44,905 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.7% |                                                | 9.78486 samples/s/p  0:46:30 }
2024-06-05 15:19:48,205 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  172/ 3581], loss: 3.006, per_step_time: 823ms, lr: 4.7700556e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:48,205 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.8% |                                                | 9.71206 samples/s/p  0:46:48 }
2024-06-05 15:19:51,491 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  176/ 3581], loss: 2.985, per_step_time: 819ms, lr: 4.7645804e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:51,491 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    4.9% |                                                | 9.75636 samples/s/p  0:46:32 }
2024-06-05 15:19:54,793 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  180/ 3581], loss: 3.181, per_step_time: 824ms, lr: 4.759106e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:54,794 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.0% |                                                | 9.70478 samples/s/p  0:46:43 }
2024-06-05 15:19:58,080 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  184/ 3581], loss: 2.974, per_step_time: 820ms, lr: 4.7536312e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:19:58,080 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.1% |                                                | 9.75474 samples/s/p  0:46:25 }
2024-06-05 15:20:01,374 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  188/ 3581], loss: 2.979, per_step_time: 822ms, lr: 4.748156e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:01,375 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.2% |                                                | 9.72767 samples/s/p  0:46:30 }
2024-06-05 15:20:04,659 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  192/ 3581], loss: 3.098, per_step_time: 819ms, lr: 4.7426816e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:04,660 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.4% |                                                | 9.75804 samples/s/p  0:46:18 }
2024-06-05 15:20:07,946 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  196/ 3581], loss: 3.152, per_step_time: 820ms, lr: 4.737206e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:07,946 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.5% |                                                | 9.75108 samples/s/p  0:46:17 }
2024-06-05 15:20:11,229 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  200/ 3581], loss: 3.079, per_step_time: 819ms, lr: 4.7317317e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:11,230 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.6% |                                                | 9.76671 samples/s/p  0:46:09 }
2024-06-05 15:20:14,514 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  204/ 3581], loss: 3.019, per_step_time: 820ms, lr: 4.726257e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:14,515 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.7% |                                                | 9.75586 samples/s/p  0:46:09 }
2024-06-05 15:20:17,814 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  208/ 3581], loss: 2.935, per_step_time: 823ms, lr: 4.720782e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:17,814 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.8% |                                                | 9.71587 samples/s/p  0:46:17 }
2024-06-05 15:20:21,097 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  212/ 3581], loss: 2.781, per_step_time: 819ms, lr: 4.715307e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:21,097 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    5.9% |                                                | 9.76256 samples/s/p  0:46:00 }
2024-06-05 15:20:24,377 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  216/ 3581], loss: 3.029, per_step_time: 818ms, lr: 4.7098318e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:24,378 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.0% |                                               | 9.76936 samples/s/p  0:45:55 }
2024-06-05 15:20:27,673 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  220/ 3581], loss: 3.002, per_step_time: 822ms, lr: 4.7043573e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:27,673 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.1% |                                               | 9.72750 samples/s/p  0:46:04 }
2024-06-05 15:20:30,957 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  224/ 3581], loss: 2.941, per_step_time: 819ms, lr: 4.6988822e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:30,958 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.3% |                                               | 9.75866 samples/s/p  0:45:52 }
2024-06-05 15:20:34,256 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  228/ 3581], loss: 2.868, per_step_time: 823ms, lr: 4.6934078e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:34,256 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.4% |                                               | 9.71556 samples/s/p  0:46:00 }
2024-06-05 15:20:37,555 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  232/ 3581], loss: 2.948, per_step_time: 823ms, lr: 4.687933e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:37,555 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.5% |                                               | 9.71641 samples/s/p  0:45:57 }
2024-06-05 15:20:40,839 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  236/ 3581], loss: 2.939, per_step_time: 819ms, lr: 4.6824578e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:40,840 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.6% |                                               | 9.75738 samples/s/p  0:45:42 }
2024-06-05 15:20:44,120 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  240/ 3581], loss: 2.942, per_step_time: 818ms, lr: 4.676983e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:44,121 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.7% |                                               | 9.76955 samples/s/p  0:45:35 }
2024-06-05 15:20:47,411 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  244/ 3581], loss: 2.937, per_step_time: 821ms, lr: 4.671508e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:47,411 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.8% |                                               | 9.74021 samples/s/p  0:45:40 }
2024-06-05 15:20:50,717 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  248/ 3581], loss: 2.928, per_step_time: 825ms, lr: 4.6660334e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:50,717 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    6.9% |                                               | 9.69590 samples/s/p  0:45:50 }
2024-06-05 15:20:54,012 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  252/ 3581], loss: 2.987, per_step_time: 822ms, lr: 4.6605586e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:54,013 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.0% |                                               | 9.72622 samples/s/p  0:45:38 }
2024-06-05 15:20:57,293 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  256/ 3581], loss: 2.973, per_step_time: 818ms, lr: 4.6550835e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:20:57,293 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.1% |                                               | 9.77135 samples/s/p  0:45:22 }
2024-06-05 15:21:00,588 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  260/ 3581], loss: 3.049, per_step_time: 822ms, lr: 4.6496087e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:00,589 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.3% |                                               | 9.72563 samples/s/p  0:45:31 }
2024-06-05 15:21:03,875 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  264/ 3581], loss: 3.051, per_step_time: 820ms, lr: 4.6441335e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:03,875 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.4% |                                               | 9.75206 samples/s/p  0:45:21 }
2024-06-05 15:21:07,157 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  268/ 3581], loss: 2.906, per_step_time: 819ms, lr: 4.638659e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:07,158 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.5% |                                               | 9.76419 samples/s/p  0:45:14 }
2024-06-05 15:21:10,457 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  272/ 3581], loss: 2.967, per_step_time: 823ms, lr: 4.6331843e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:10,458 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.6% |                                               | 9.71307 samples/s/p  0:45:25 }
2024-06-05 15:21:13,750 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  276/ 3581], loss: 2.973, per_step_time: 821ms, lr: 4.627709e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:13,751 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.7% |                                               | 9.73286 samples/s/p  0:45:16 }
2024-06-05 15:21:17,042 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  280/ 3581], loss: 2.975, per_step_time: 821ms, lr: 4.6222347e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:17,042 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.8% |                                               | 9.73670 samples/s/p  0:45:12 }
2024-06-05 15:21:20,315 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  284/ 3581], loss: 2.900, per_step_time: 817ms, lr: 4.61676e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:20,316 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    7.9% |                                               | 9.79058 samples/s/p  0:44:54 }
2024-06-05 15:21:23,604 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  288/ 3581], loss: 3.149, per_step_time: 820ms, lr: 4.6112847e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:23,605 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.0% |                                              | 9.74532 samples/s/p  0:45:03 }
2024-06-05 15:21:26,894 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  292/ 3581], loss: 2.873, per_step_time: 820ms, lr: 4.60581e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:26,894 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.2% |                                              | 9.74457 samples/s/p  0:45:00 }
2024-06-05 15:21:30,182 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  296/ 3581], loss: 2.898, per_step_time: 820ms, lr: 4.6003348e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:30,182 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.3% |                                              | 9.74787 samples/s/p  0:44:55 }
2024-06-05 15:21:33,467 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  300/ 3581], loss: 2.921, per_step_time: 819ms, lr: 4.5948604e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:33,467 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.4% |                                              | 9.75800 samples/s/p  0:44:49 }
2024-06-05 15:21:36,749 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  304/ 3581], loss: 3.063, per_step_time: 819ms, lr: 4.589385e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:36,750 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.5% |                                              | 9.76469 samples/s/p  0:44:44 }
2024-06-05 15:21:40,030 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  308/ 3581], loss: 2.753, per_step_time: 818ms, lr: 4.5839104e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:40,030 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.6% |                                              | 9.77045 samples/s/p  0:44:39 }
2024-06-05 15:21:43,306 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  312/ 3581], loss: 2.899, per_step_time: 817ms, lr: 4.5784356e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:43,306 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.7% |                                              | 9.78381 samples/s/p  0:44:32 }
2024-06-05 15:21:46,593 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  316/ 3581], loss: 2.966, per_step_time: 820ms, lr: 4.5729605e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:46,594 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.8% |                                              | 9.74962 samples/s/p  0:44:39 }
2024-06-05 15:21:49,885 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  320/ 3581], loss: 2.937, per_step_time: 821ms, lr: 4.567486e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:49,885 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    8.9% |                                              | 9.73699 samples/s/p  0:44:39 }
2024-06-05 15:21:53,172 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  324/ 3581], loss: 2.760, per_step_time: 820ms, lr: 4.5620112e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:53,173 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.0% |                                              | 9.74946 samples/s/p  0:44:32 }
2024-06-05 15:21:56,455 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  328/ 3581], loss: 2.954, per_step_time: 819ms, lr: 4.556536e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:56,456 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.2% |                                              | 9.76161 samples/s/p  0:44:25 }
2024-06-05 15:21:59,738 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  332/ 3581], loss: 3.046, per_step_time: 819ms, lr: 4.5510613e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:21:59,738 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.3% |                                              | 9.76384 samples/s/p  0:44:22 }
2024-06-05 15:22:03,005 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  336/ 3581], loss: 3.022, per_step_time: 815ms, lr: 4.545586e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:03,005 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.4% |                                              | 9.81130 samples/s/p  0:44:05 }
2024-06-05 15:22:06,282 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  340/ 3581], loss: 2.688, per_step_time: 818ms, lr: 4.5401117e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:06,283 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.5% |                                              | 9.77834 samples/s/p  0:44:11 }
2024-06-05 15:22:09,568 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  344/ 3581], loss: 2.940, per_step_time: 819ms, lr: 4.534637e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:09,568 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.6% |                                              | 9.75768 samples/s/p  0:44:13 }
2024-06-05 15:22:12,850 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  348/ 3581], loss: 2.852, per_step_time: 819ms, lr: 4.529162e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:12,851 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.7% |                                              | 9.76417 samples/s/p  0:44:08 }
2024-06-05 15:22:16,132 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  352/ 3581], loss: 2.845, per_step_time: 818ms, lr: 4.523687e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:16,132 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.8% |                                              | 9.76932 samples/s/p  0:44:04 }
2024-06-05 15:22:19,415 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  356/ 3581], loss: 2.920, per_step_time: 819ms, lr: 4.5182118e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:19,416 - mindformers[mindformers/core/callback/callback.py:324] - INFO -    9.9% |                                              | 9.76169 samples/s/p  0:44:02 }
2024-06-05 15:22:22,702 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  360/ 3581], loss: 2.871, per_step_time: 820ms, lr: 4.5127374e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:22,703 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.1% |                                             | 9.75029 samples/s/p  0:44:02 }
2024-06-05 15:22:25,989 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  364/ 3581], loss: 2.968, per_step_time: 820ms, lr: 4.5072626e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:25,989 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.2% |                                             | 9.75322 samples/s/p  0:43:58 }
2024-06-05 15:22:29,270 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  368/ 3581], loss: 2.931, per_step_time: 818ms, lr: 4.5017874e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:29,270 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.3% |                                             | 9.76818 samples/s/p  0:43:51 }
2024-06-05 15:22:32,555 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  372/ 3581], loss: 3.057, per_step_time: 820ms, lr: 4.496313e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:32,556 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.4% |                                             | 9.75572 samples/s/p  0:43:51 }
2024-06-05 15:22:35,841 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  376/ 3581], loss: 2.935, per_step_time: 819ms, lr: 4.490838e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:35,841 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.5% |                                             | 9.75696 samples/s/p  0:43:47 }
2024-06-05 15:22:39,129 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  380/ 3581], loss: 2.831, per_step_time: 820ms, lr: 4.485363e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:39,130 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.6% |                                             | 9.74631 samples/s/p  0:43:47 }
2024-06-05 15:22:42,414 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  384/ 3581], loss: 2.955, per_step_time: 819ms, lr: 4.479888e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:42,415 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.7% |                                             | 9.75725 samples/s/p  0:43:41 }
2024-06-05 15:22:45,704 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  388/ 3581], loss: 2.781, per_step_time: 821ms, lr: 4.4744134e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:45,705 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.8% |                                             | 9.74167 samples/s/p  0:43:42 }
2024-06-05 15:22:48,987 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  392/ 3581], loss: 2.902, per_step_time: 819ms, lr: 4.4689383e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:48,988 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   10.9% |                                             | 9.76365 samples/s/p  0:43:32 }
2024-06-05 15:22:52,280 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  396/ 3581], loss: 2.971, per_step_time: 821ms, lr: 4.4634635e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:52,281 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.1% |                                             | 9.73342 samples/s/p  0:43:37 }
2024-06-05 15:22:55,550 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  400/ 3581], loss: 2.839, per_step_time: 816ms, lr: 4.4579887e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:55,550 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.2% |                                             | 9.80325 samples/s/p  0:43:15 }
2024-06-05 15:22:58,832 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  404/ 3581], loss: 2.901, per_step_time: 819ms, lr: 4.4525135e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:22:58,833 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.3% |                                             | 9.76424 samples/s/p  0:43:22 }
2024-06-05 15:23:02,109 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  408/ 3581], loss: 2.858, per_step_time: 817ms, lr: 4.447039e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:02,110 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.4% |                                             | 9.78021 samples/s/p  0:43:15 }
2024-06-05 15:23:05,396 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  412/ 3581], loss: 2.868, per_step_time: 820ms, lr: 4.4415643e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:05,397 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.5% |                                             | 9.75061 samples/s/p  0:43:20 }
2024-06-05 15:23:08,681 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  416/ 3581], loss: 2.835, per_step_time: 819ms, lr: 4.436089e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:08,681 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.6% |                                             | 9.76030 samples/s/p  0:43:14 }
2024-06-05 15:23:11,961 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  420/ 3581], loss: 2.893, per_step_time: 818ms, lr: 4.4306144e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:11,962 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.7% |                                             | 9.77098 samples/s/p  0:43:08 }
2024-06-05 15:23:15,244 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  424/ 3581], loss: 2.886, per_step_time: 819ms, lr: 4.4251392e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:15,245 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   11.8% |                                             | 9.76294 samples/s/p  0:43:06 }
2024-06-05 15:23:18,534 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  428/ 3581], loss: 2.868, per_step_time: 821ms, lr: 4.4196648e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:18,535 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.0% |                                             | 9.74177 samples/s/p  0:43:09 }
2024-06-05 15:23:21,821 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  432/ 3581], loss: 3.081, per_step_time: 820ms, lr: 4.4141892e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:21,821 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.1% |                                            | 9.75231 samples/s/p  0:43:03 }
2024-06-05 15:23:25,111 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  436/ 3581], loss: 2.785, per_step_time: 821ms, lr: 4.4087148e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:25,112 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.2% |                                            | 9.74130 samples/s/p  0:43:02 }
2024-06-05 15:23:28,393 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  440/ 3581], loss: 2.787, per_step_time: 819ms, lr: 4.40324e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:28,394 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.3% |                                            | 9.76606 samples/s/p  0:42:52 }
2024-06-05 15:23:31,681 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  444/ 3581], loss: 2.812, per_step_time: 820ms, lr: 4.397765e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:31,681 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.4% |                                            | 9.74843 samples/s/p  0:42:54 }
2024-06-05 15:23:34,969 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  448/ 3581], loss: 3.095, per_step_time: 820ms, lr: 4.3922904e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:34,970 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.5% |                                            | 9.74730 samples/s/p  0:42:51 }
2024-06-05 15:23:38,249 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  452/ 3581], loss: 2.813, per_step_time: 818ms, lr: 4.3868156e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:38,250 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.6% |                                            | 9.77034 samples/s/p  0:42:42 }
2024-06-05 15:23:41,530 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  456/ 3581], loss: 2.913, per_step_time: 818ms, lr: 4.3813405e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:41,531 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.7% |                                            | 9.76889 samples/s/p  0:42:39 }
2024-06-05 15:23:44,801 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  460/ 3581], loss: 3.004, per_step_time: 816ms, lr: 4.375866e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:44,801 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   12.8% |                                            | 9.79902 samples/s/p  0:42:28 }
2024-06-05 15:23:48,072 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  464/ 3581], loss: 2.911, per_step_time: 816ms, lr: 4.3703905e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:48,072 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.0% |                                            | 9.79926 samples/s/p  0:42:24 }
2024-06-05 15:23:51,350 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  468/ 3581], loss: 2.971, per_step_time: 818ms, lr: 4.364916e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:51,351 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.1% |                                            | 9.77877 samples/s/p  0:42:26 }
2024-06-05 15:23:54,628 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  472/ 3581], loss: 2.952, per_step_time: 818ms, lr: 4.3594413e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:54,629 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.2% |                                            | 9.77722 samples/s/p  0:42:23 }
2024-06-05 15:23:57,913 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  476/ 3581], loss: 2.954, per_step_time: 819ms, lr: 4.353966e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:23:57,913 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.3% |                                            | 9.75832 samples/s/p  0:42:25 }
2024-06-05 15:24:01,195 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  480/ 3581], loss: 2.908, per_step_time: 819ms, lr: 4.3484913e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:01,196 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.4% |                                            | 9.76450 samples/s/p  0:42:20 }
2024-06-05 15:24:04,482 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  484/ 3581], loss: 2.856, per_step_time: 820ms, lr: 4.3430162e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:04,482 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.5% |                                            | 9.75246 samples/s/p  0:42:20 }
2024-06-05 15:24:07,768 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  488/ 3581], loss: 2.750, per_step_time: 820ms, lr: 4.337542e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:07,769 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.6% |                                            | 9.75291 samples/s/p  0:42:17 }
2024-06-05 15:24:11,056 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  492/ 3581], loss: 2.861, per_step_time: 820ms, lr: 4.332067e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:11,056 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.7% |                                            | 9.74862 samples/s/p  0:42:14 }
2024-06-05 15:24:14,344 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  496/ 3581], loss: 2.800, per_step_time: 820ms, lr: 4.3265918e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:14,345 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   13.9% |                                            | 9.74784 samples/s/p  0:42:11 }
2024-06-05 15:24:17,630 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  500/ 3581], loss: 2.799, per_step_time: 820ms, lr: 4.3211174e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:17,631 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.0% |                                            | 9.75238 samples/s/p  0:42:07 }
2024-06-05 15:24:20,925 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  504/ 3581], loss: 2.825, per_step_time: 822ms, lr: 4.3156426e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:20,925 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.1% |                                           | 9.72830 samples/s/p  0:42:10 }
2024-06-05 15:24:24,205 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  508/ 3581], loss: 2.846, per_step_time: 818ms, lr: 4.3101674e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:24,205 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.2% |                                           | 9.77217 samples/s/p  0:41:55 }
2024-06-05 15:24:27,487 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  512/ 3581], loss: 2.854, per_step_time: 819ms, lr: 4.3046926e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:27,488 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.3% |                                           | 9.76383 samples/s/p  0:41:54 }
2024-06-05 15:24:30,768 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  516/ 3581], loss: 2.934, per_step_time: 818ms, lr: 4.2992175e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:30,768 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.4% |                                           | 9.77032 samples/s/p  0:41:49 }
2024-06-05 15:24:34,048 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  520/ 3581], loss: 2.813, per_step_time: 818ms, lr: 4.293743e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:34,048 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.5% |                                           | 9.77185 samples/s/p  0:41:45 }
2024-06-05 15:24:37,332 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  524/ 3581], loss: 2.704, per_step_time: 819ms, lr: 4.2882682e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:37,332 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.6% |                                           | 9.75952 samples/s/p  0:41:45 }
2024-06-05 15:24:40,615 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  528/ 3581], loss: 2.860, per_step_time: 819ms, lr: 4.282793e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:40,615 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.7% |                                           | 9.76442 samples/s/p  0:41:41 }
2024-06-05 15:24:43,897 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  532/ 3581], loss: 2.857, per_step_time: 819ms, lr: 4.2773183e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:43,897 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   14.9% |                                           | 9.76530 samples/s/p  0:41:37 }
2024-06-05 15:24:47,181 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  536/ 3581], loss: 2.833, per_step_time: 819ms, lr: 4.2718435e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:47,181 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.0% |                                           | 9.76051 samples/s/p  0:41:35 }
2024-06-05 15:24:50,461 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  540/ 3581], loss: 2.918, per_step_time: 818ms, lr: 4.2663687e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:50,462 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.1% |                                           | 9.76900 samples/s/p  0:41:30 }
2024-06-05 15:24:53,743 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  544/ 3581], loss: 2.838, per_step_time: 819ms, lr: 4.2608932e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:53,744 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.2% |                                           | 9.76611 samples/s/p  0:41:27 }
2024-06-05 15:24:57,025 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  548/ 3581], loss: 2.863, per_step_time: 819ms, lr: 4.2554188e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:24:57,026 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.3% |                                           | 9.76643 samples/s/p  0:41:24 }
2024-06-05 15:25:00,301 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  552/ 3581], loss: 2.882, per_step_time: 817ms, lr: 4.2499443e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:00,302 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.4% |                                           | 9.78411 samples/s/p  0:41:16 }
2024-06-05 15:25:03,585 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  556/ 3581], loss: 2.854, per_step_time: 819ms, lr: 4.244469e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:03,586 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.5% |                                           | 9.75928 samples/s/p  0:41:19 }
2024-06-05 15:25:06,880 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  560/ 3581], loss: 2.840, per_step_time: 821ms, lr: 4.238994e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:06,880 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.6% |                                           | 9.74215 samples/s/p  0:41:20 }
2024-06-05 15:25:10,168 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  564/ 3581], loss: 2.912, per_step_time: 820ms, lr: 4.2335192e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:10,168 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.7% |                                           | 9.74833 samples/s/p  0:41:15 }
2024-06-05 15:25:13,450 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  568/ 3581], loss: 2.746, per_step_time: 819ms, lr: 4.2280448e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:13,450 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   15.9% |                                           | 9.76508 samples/s/p  0:41:08 }
2024-06-05 15:25:16,732 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  572/ 3581], loss: 2.725, per_step_time: 819ms, lr: 4.2225696e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:16,733 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.0% |                                           | 9.76472 samples/s/p  0:41:05 }
2024-06-05 15:25:20,007 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  576/ 3581], loss: 2.882, per_step_time: 817ms, lr: 4.217095e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:20,007 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.1% |                                          | 9.78888 samples/s/p  0:40:55 }
2024-06-05 15:25:23,297 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  580/ 3581], loss: 2.899, per_step_time: 821ms, lr: 4.21162e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:23,297 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.2% |                                          | 9.74178 samples/s/p  0:41:04 }
2024-06-05 15:25:26,572 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  584/ 3581], loss: 2.962, per_step_time: 817ms, lr: 4.206145e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:26,573 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.3% |                                          | 9.78452 samples/s/p  0:40:50 }
2024-06-05 15:25:29,862 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  588/ 3581], loss: 2.758, per_step_time: 820ms, lr: 4.2006704e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:29,862 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.4% |                                          | 9.74654 samples/s/p  0:40:56 }
2024-06-05 15:25:33,140 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  592/ 3581], loss: 2.994, per_step_time: 818ms, lr: 4.1951957e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:33,140 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.5% |                                          | 9.77804 samples/s/p  0:40:45 }
2024-06-05 15:25:36,417 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  596/ 3581], loss: 3.018, per_step_time: 818ms, lr: 4.1897205e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:36,418 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.6% |                                          | 9.77964 samples/s/p  0:40:41 }
2024-06-05 15:25:39,693 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  600/ 3581], loss: 2.806, per_step_time: 817ms, lr: 4.1842457e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:39,693 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.8% |                                          | 9.78562 samples/s/p  0:40:37 }
2024-06-05 15:25:42,977 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  604/ 3581], loss: 2.919, per_step_time: 819ms, lr: 4.1787705e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:42,978 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   16.9% |                                          | 9.75953 samples/s/p  0:40:40 }
2024-06-05 15:25:46,258 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  608/ 3581], loss: 2.841, per_step_time: 818ms, lr: 4.173296e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:46,258 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.0% |                                          | 9.77087 samples/s/p  0:40:34 }
2024-06-05 15:25:49,551 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  612/ 3581], loss: 2.713, per_step_time: 821ms, lr: 4.1678206e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:49,551 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.1% |                                          | 9.73275 samples/s/p  0:40:40 }
2024-06-05 15:25:52,835 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  616/ 3581], loss: 2.810, per_step_time: 819ms, lr: 4.162346e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:52,835 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.2% |                                          | 9.76066 samples/s/p  0:40:30 }
2024-06-05 15:25:56,121 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  620/ 3581], loss: 2.837, per_step_time: 820ms, lr: 4.1568714e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:56,121 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.3% |                                          | 9.75252 samples/s/p  0:40:28 }
2024-06-05 15:25:59,400 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  624/ 3581], loss: 2.867, per_step_time: 818ms, lr: 4.1513962e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:25:59,400 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.4% |                                          | 9.77545 samples/s/p  0:40:19 }
2024-06-05 15:26:02,677 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  628/ 3581], loss: 3.055, per_step_time: 817ms, lr: 4.1459218e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:02,677 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.5% |                                          | 9.78099 samples/s/p  0:40:15 }
2024-06-05 15:26:05,953 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  632/ 3581], loss: 2.785, per_step_time: 817ms, lr: 4.140447e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:05,953 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.6% |                                          | 9.78366 samples/s/p  0:40:11 }
2024-06-05 15:26:09,234 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  636/ 3581], loss: 2.692, per_step_time: 818ms, lr: 4.134972e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:09,235 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.8% |                                          | 9.76950 samples/s/p  0:40:11 }
2024-06-05 15:26:12,514 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  640/ 3581], loss: 2.709, per_step_time: 818ms, lr: 4.129497e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:12,515 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   17.9% |                                          | 9.77306 samples/s/p  0:40:07 }
2024-06-05 15:26:15,791 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  644/ 3581], loss: 2.809, per_step_time: 817ms, lr: 4.124022e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:15,791 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.0% |                                          | 9.78222 samples/s/p  0:40:01 }
2024-06-05 15:26:19,072 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  648/ 3581], loss: 2.901, per_step_time: 818ms, lr: 4.1185474e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:19,072 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.1% |                                         | 9.76864 samples/s/p  0:40:01 }
2024-06-05 15:26:22,358 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  652/ 3581], loss: 2.965, per_step_time: 820ms, lr: 4.1130726e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:22,358 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.2% |                                         | 9.75371 samples/s/p  0:40:02 }
2024-06-05 15:26:25,643 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  656/ 3581], loss: 2.871, per_step_time: 819ms, lr: 4.1075975e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:25,643 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.3% |                                         | 9.75719 samples/s/p  0:39:58 }
2024-06-05 15:26:28,936 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  660/ 3581], loss: 2.678, per_step_time: 822ms, lr: 4.1021227e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:28,937 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.4% |                                         | 9.73220 samples/s/p  0:40:01 }
2024-06-05 15:26:32,223 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  664/ 3581], loss: 2.919, per_step_time: 820ms, lr: 4.0966475e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:32,223 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.5% |                                         | 9.75092 samples/s/p  0:39:53 }
2024-06-05 15:26:35,496 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  668/ 3581], loss: 2.831, per_step_time: 816ms, lr: 4.091173e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:35,496 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.7% |                                         | 9.79270 samples/s/p  0:39:39 }
2024-06-05 15:26:38,782 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  672/ 3581], loss: 2.732, per_step_time: 820ms, lr: 4.0856983e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:38,783 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.8% |                                         | 9.75317 samples/s/p  0:39:46 }
2024-06-05 15:26:42,073 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  676/ 3581], loss: 2.770, per_step_time: 821ms, lr: 4.080223e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:42,073 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   18.9% |                                         | 9.73914 samples/s/p  0:39:46 }
2024-06-05 15:26:45,353 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  680/ 3581], loss: 2.811, per_step_time: 818ms, lr: 4.0747487e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:45,353 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.0% |                                         | 9.77161 samples/s/p  0:39:35 }
2024-06-05 15:26:48,630 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  684/ 3581], loss: 2.756, per_step_time: 817ms, lr: 4.0692732e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:48,630 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.1% |                                         | 9.78008 samples/s/p  0:39:29 }
2024-06-05 15:26:51,909 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  688/ 3581], loss: 2.844, per_step_time: 818ms, lr: 4.0637988e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:51,910 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.2% |                                         | 9.77469 samples/s/p  0:39:27 }
2024-06-05 15:26:55,191 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  692/ 3581], loss: 2.860, per_step_time: 818ms, lr: 4.058324e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:55,191 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.3% |                                         | 9.76910 samples/s/p  0:39:25 }
2024-06-05 15:26:58,474 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  696/ 3581], loss: 2.784, per_step_time: 819ms, lr: 4.052849e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:26:58,474 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.4% |                                         | 9.76253 samples/s/p  0:39:24 }
2024-06-05 15:27:01,749 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  700/ 3581], loss: 2.811, per_step_time: 817ms, lr: 4.047374e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:01,750 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.5% |                                         | 9.78553 samples/s/p  0:39:15 }
2024-06-05 15:27:05,035 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  704/ 3581], loss: 2.853, per_step_time: 820ms, lr: 4.0418996e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:05,036 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.7% |                                         | 9.75498 samples/s/p  0:39:19 }
2024-06-05 15:27:08,317 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  708/ 3581], loss: 2.796, per_step_time: 819ms, lr: 4.0364248e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:08,317 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.8% |                                         | 9.76616 samples/s/p  0:39:13 }
2024-06-05 15:27:11,592 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  712/ 3581], loss: 2.697, per_step_time: 817ms, lr: 4.0309496e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:11,593 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   19.9% |                                         | 9.78529 samples/s/p  0:39:05 }
2024-06-05 15:27:14,879 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  716/ 3581], loss: 2.949, per_step_time: 820ms, lr: 4.025475e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:14,880 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.0% |                                         | 9.75239 samples/s/p  0:39:10 }
2024-06-05 15:27:18,164 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  720/ 3581], loss: 2.839, per_step_time: 819ms, lr: 4.02e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:18,164 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.1% |                                        | 9.75790 samples/s/p  0:39:05 }
2024-06-05 15:27:21,456 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  724/ 3581], loss: 2.813, per_step_time: 821ms, lr: 4.014525e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:21,456 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.2% |                                        | 9.73575 samples/s/p  0:39:07 }
2024-06-05 15:27:24,722 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  728/ 3581], loss: 2.964, per_step_time: 815ms, lr: 4.00905e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:24,723 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.3% |                                        | 9.81238 samples/s/p  0:38:46 }
2024-06-05 15:27:28,006 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  732/ 3581], loss: 2.891, per_step_time: 819ms, lr: 4.0035753e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:28,006 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.4% |                                        | 9.76041 samples/s/p  0:38:55 }
2024-06-05 15:27:31,278 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  736/ 3581], loss: 2.715, per_step_time: 816ms, lr: 3.9981005e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:31,278 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.6% |                                        | 9.79681 samples/s/p  0:38:43 }
2024-06-05 15:27:34,556 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  740/ 3581], loss: 2.727, per_step_time: 818ms, lr: 3.9926257e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:34,557 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.7% |                                        | 9.77670 samples/s/p  0:38:44 }
2024-06-05 15:27:37,846 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  744/ 3581], loss: 2.919, per_step_time: 820ms, lr: 3.9871506e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:37,846 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.8% |                                        | 9.74468 samples/s/p  0:38:49 }
2024-06-05 15:27:41,134 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  748/ 3581], loss: 2.909, per_step_time: 820ms, lr: 3.9816758e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:41,135 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   20.9% |                                        | 9.74671 samples/s/p  0:38:45 }
2024-06-05 15:27:44,415 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  752/ 3581], loss: 2.872, per_step_time: 818ms, lr: 3.976201e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:44,415 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.0% |                                        | 9.77134 samples/s/p  0:38:36 }
2024-06-05 15:27:47,700 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  756/ 3581], loss: 2.921, per_step_time: 819ms, lr: 3.970726e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:47,700 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.1% |                                        | 9.75696 samples/s/p  0:38:36 }
2024-06-05 15:27:50,971 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  760/ 3581], loss: 2.842, per_step_time: 816ms, lr: 3.9652514e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:50,972 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.2% |                                        | 9.79696 samples/s/p  0:38:23 }
2024-06-05 15:27:54,260 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  764/ 3581], loss: 2.896, per_step_time: 820ms, lr: 3.9597762e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:54,260 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.3% |                                        | 9.74518 samples/s/p  0:38:32 }
2024-06-05 15:27:57,525 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  768/ 3581], loss: 2.939, per_step_time: 814ms, lr: 3.9543018e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:27:57,525 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.4% |                                        | 9.81775 samples/s/p  0:38:12 }
2024-06-05 15:28:00,807 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  772/ 3581], loss: 2.865, per_step_time: 819ms, lr: 3.948827e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:00,808 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.6% |                                        | 9.76421 samples/s/p  0:38:21 }
2024-06-05 15:28:04,099 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  776/ 3581], loss: 2.846, per_step_time: 821ms, lr: 3.943352e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:04,100 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.7% |                                        | 9.73754 samples/s/p  0:38:24 }
2024-06-05 15:28:07,386 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  780/ 3581], loss: 2.771, per_step_time: 820ms, lr: 3.937877e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:07,387 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.8% |                                        | 9.75028 samples/s/p  0:38:18 }
2024-06-05 15:28:10,674 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  784/ 3581], loss: 2.766, per_step_time: 820ms, lr: 3.932402e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:10,674 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   21.9% |                                        | 9.74969 samples/s/p  0:38:15 }
2024-06-05 15:28:13,955 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  788/ 3581], loss: 2.733, per_step_time: 819ms, lr: 3.9269275e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:13,956 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.0% |                                       | 9.76752 samples/s/p  0:38:07 }
2024-06-05 15:28:17,229 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  792/ 3581], loss: 2.720, per_step_time: 817ms, lr: 3.921452e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:17,230 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.1% |                                       | 9.78891 samples/s/p  0:37:59 }
2024-06-05 15:28:20,509 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  796/ 3581], loss: 2.744, per_step_time: 818ms, lr: 3.9159775e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:20,509 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.2% |                                       | 9.77203 samples/s/p  0:37:59 }
2024-06-05 15:28:23,787 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  800/ 3581], loss: 2.717, per_step_time: 818ms, lr: 3.9105027e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:23,788 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.3% |                                       | 9.77706 samples/s/p  0:37:55 }
2024-06-05 15:28:27,065 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  804/ 3581], loss: 2.803, per_step_time: 817ms, lr: 3.9050276e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:27,065 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.5% |                                       | 9.78092 samples/s/p  0:37:51 }
2024-06-05 15:28:30,352 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  808/ 3581], loss: 2.845, per_step_time: 820ms, lr: 3.899553e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:30,352 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.6% |                                       | 9.75143 samples/s/p  0:37:54 }
2024-06-05 15:28:33,628 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  812/ 3581], loss: 2.822, per_step_time: 817ms, lr: 3.8940776e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:33,629 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.7% |                                       | 9.78214 samples/s/p  0:37:44 }
2024-06-05 15:28:36,911 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  816/ 3581], loss: 2.856, per_step_time: 819ms, lr: 3.888603e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:36,912 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.8% |                                       | 9.76368 samples/s/p  0:37:45 }
2024-06-05 15:28:40,190 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  820/ 3581], loss: 2.807, per_step_time: 818ms, lr: 3.8831284e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:40,191 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   22.9% |                                       | 9.77465 samples/s/p  0:37:39 }
2024-06-05 15:28:43,478 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  824/ 3581], loss: 2.536, per_step_time: 820ms, lr: 3.8776532e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:43,478 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.0% |                                       | 9.74958 samples/s/p  0:37:42 }
2024-06-05 15:28:46,761 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  828/ 3581], loss: 2.861, per_step_time: 819ms, lr: 3.8721784e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:46,761 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.1% |                                       | 9.76397 samples/s/p  0:37:35 }
2024-06-05 15:28:50,045 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  832/ 3581], loss: 2.721, per_step_time: 819ms, lr: 3.866704e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:50,046 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.2% |                                       | 9.75833 samples/s/p  0:37:33 }
2024-06-05 15:28:53,325 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  836/ 3581], loss: 2.870, per_step_time: 818ms, lr: 3.8612292e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:53,325 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.3% |                                       | 9.77265 samples/s/p  0:37:27 }
2024-06-05 15:28:56,627 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  840/ 3581], loss: 2.805, per_step_time: 824ms, lr: 3.855754e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:56,627 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.5% |                                       | 9.70585 samples/s/p  0:37:39 }
2024-06-05 15:28:59,904 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  844/ 3581], loss: 2.780, per_step_time: 817ms, lr: 3.850279e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:28:59,904 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.6% |                                       | 9.78352 samples/s/p  0:37:18 }
2024-06-05 15:29:03,185 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  848/ 3581], loss: 2.666, per_step_time: 818ms, lr: 3.8448045e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:03,185 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.7% |                                       | 9.76997 samples/s/p  0:37:17 }
2024-06-05 15:29:06,465 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  852/ 3581], loss: 2.587, per_step_time: 818ms, lr: 3.8393297e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:06,465 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.8% |                                       | 9.77139 samples/s/p  0:37:14 }
2024-06-05 15:29:09,749 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  856/ 3581], loss: 2.778, per_step_time: 819ms, lr: 3.8338545e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:09,750 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   23.9% |                                       | 9.75806 samples/s/p  0:37:14 }
2024-06-05 15:29:13,031 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  860/ 3581], loss: 2.665, per_step_time: 819ms, lr: 3.82838e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:13,031 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.0% |                                      | 9.76649 samples/s/p  0:37:08 }
2024-06-05 15:29:16,311 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  864/ 3581], loss: 2.850, per_step_time: 818ms, lr: 3.822905e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:16,312 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.1% |                                      | 9.77221 samples/s/p  0:37:04 }
2024-06-05 15:29:19,594 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  868/ 3581], loss: 2.543, per_step_time: 819ms, lr: 3.81743e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:19,594 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.2% |                                      | 9.76399 samples/s/p  0:37:02 }
2024-06-05 15:29:22,877 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  872/ 3581], loss: 2.817, per_step_time: 819ms, lr: 3.8119553e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:22,878 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.4% |                                      | 9.76209 samples/s/p  0:37:00 }
2024-06-05 15:29:26,155 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  876/ 3581], loss: 3.024, per_step_time: 818ms, lr: 3.8064805e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:26,156 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.5% |                                      | 9.77701 samples/s/p  0:36:53 }
2024-06-05 15:29:29,449 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  880/ 3581], loss: 2.785, per_step_time: 822ms, lr: 3.8010054e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:29,450 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.6% |                                      | 9.73059 samples/s/p  0:37:00 }
2024-06-05 15:29:32,733 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  884/ 3581], loss: 2.775, per_step_time: 819ms, lr: 3.7955306e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:32,734 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.7% |                                      | 9.75999 samples/s/p  0:36:50 }
2024-06-05 15:29:36,017 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  888/ 3581], loss: 2.589, per_step_time: 819ms, lr: 3.7900558e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:36,018 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.8% |                                      | 9.75934 samples/s/p  0:36:47 }
2024-06-05 15:29:39,314 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  892/ 3581], loss: 2.758, per_step_time: 822ms, lr: 3.784581e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:39,314 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   24.9% |                                      | 9.72254 samples/s/p  0:36:52 }
2024-06-05 15:29:42,598 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  896/ 3581], loss: 2.858, per_step_time: 819ms, lr: 3.7791062e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:42,599 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.0% |                                      | 9.75818 samples/s/p  0:36:41 }
2024-06-05 15:29:45,887 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  900/ 3581], loss: 2.707, per_step_time: 821ms, lr: 3.7736314e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:45,888 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.1% |                                      | 9.74400 samples/s/p  0:36:41 }
2024-06-05 15:29:49,164 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  904/ 3581], loss: 2.617, per_step_time: 817ms, lr: 3.7681562e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:49,165 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.2% |                                      | 9.78134 samples/s/p  0:36:29 }
2024-06-05 15:29:52,452 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  908/ 3581], loss: 2.834, per_step_time: 820ms, lr: 3.7626814e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:52,452 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.4% |                                      | 9.74879 samples/s/p  0:36:33 }
2024-06-05 15:29:55,733 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  912/ 3581], loss: 2.784, per_step_time: 818ms, lr: 3.757207e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:55,734 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.5% |                                      | 9.76930 samples/s/p  0:36:25 }
2024-06-05 15:29:59,013 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  916/ 3581], loss: 2.794, per_step_time: 818ms, lr: 3.751732e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:29:59,013 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.6% |                                      | 9.77291 samples/s/p  0:36:21 }
2024-06-05 15:30:02,297 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  920/ 3581], loss: 2.735, per_step_time: 819ms, lr: 3.7462567e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:02,297 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.7% |                                      | 9.76060 samples/s/p  0:36:21 }
2024-06-05 15:30:05,573 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  924/ 3581], loss: 2.971, per_step_time: 817ms, lr: 3.740782e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:05,573 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.8% |                                      | 9.78371 samples/s/p  0:36:12 }
2024-06-05 15:30:08,854 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  928/ 3581], loss: 2.806, per_step_time: 818ms, lr: 3.7353075e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:08,854 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   25.9% |                                      | 9.76865 samples/s/p  0:36:12 }
2024-06-05 15:30:12,131 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  932/ 3581], loss: 2.905, per_step_time: 817ms, lr: 3.729832e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:12,132 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.0% |                                     | 9.78010 samples/s/p  0:36:06 }
2024-06-05 15:30:15,419 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  936/ 3581], loss: 2.823, per_step_time: 820ms, lr: 3.7243575e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:15,419 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.1% |                                     | 9.74820 samples/s/p  0:36:10 }
2024-06-05 15:30:18,703 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  940/ 3581], loss: 2.863, per_step_time: 819ms, lr: 3.7188827e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:18,704 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.2% |                                     | 9.75956 samples/s/p  0:36:04 }
2024-06-05 15:30:21,995 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  944/ 3581], loss: 2.938, per_step_time: 821ms, lr: 3.7134076e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:21,996 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.4% |                                     | 9.73728 samples/s/p  0:36:06 }
2024-06-05 15:30:25,278 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  948/ 3581], loss: 2.790, per_step_time: 819ms, lr: 3.707933e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:25,278 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.5% |                                     | 9.76350 samples/s/p  0:35:57 }
2024-06-05 15:30:28,554 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  952/ 3581], loss: 2.803, per_step_time: 817ms, lr: 3.7024576e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:28,554 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.6% |                                     | 9.78374 samples/s/p  0:35:49 }
2024-06-05 15:30:31,831 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  956/ 3581], loss: 2.809, per_step_time: 818ms, lr: 3.6969832e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:31,832 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.7% |                                     | 9.77887 samples/s/p  0:35:47 }
2024-06-05 15:30:35,113 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  960/ 3581], loss: 2.870, per_step_time: 819ms, lr: 3.6915084e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:35,113 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.8% |                                     | 9.76701 samples/s/p  0:35:46 }
2024-06-05 15:30:38,391 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  964/ 3581], loss: 2.663, per_step_time: 818ms, lr: 3.6860332e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:38,392 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   26.9% |                                     | 9.77546 samples/s/p  0:35:41 }
2024-06-05 15:30:41,684 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  968/ 3581], loss: 2.816, per_step_time: 821ms, lr: 3.6805584e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:41,684 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.0% |                                     | 9.73404 samples/s/p  0:35:47 }
2024-06-05 15:30:44,959 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  972/ 3581], loss: 2.697, per_step_time: 817ms, lr: 3.6750833e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:44,959 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.1% |                                     | 9.78682 samples/s/p  0:35:32 }
2024-06-05 15:30:48,240 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  976/ 3581], loss: 2.668, per_step_time: 818ms, lr: 3.6696092e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:48,241 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.3% |                                     | 9.76856 samples/s/p  0:35:33 }
2024-06-05 15:30:51,514 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  980/ 3581], loss: 2.837, per_step_time: 817ms, lr: 3.664134e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:51,515 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.4% |                                     | 9.79081 samples/s/p  0:35:25 }
2024-06-05 15:30:54,792 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  984/ 3581], loss: 2.816, per_step_time: 818ms, lr: 3.658659e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:54,793 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.5% |                                     | 9.77814 samples/s/p  0:35:24 }
2024-06-05 15:30:58,078 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  988/ 3581], loss: 2.703, per_step_time: 820ms, lr: 3.6531845e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:30:58,078 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.6% |                                     | 9.75577 samples/s/p  0:35:26 }
2024-06-05 15:31:01,353 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  992/ 3581], loss: 2.680, per_step_time: 817ms, lr: 3.6477097e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:31:01,354 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.7% |                                     | 9.78552 samples/s/p  0:35:16 }
2024-06-05 15:31:04,636 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[  996/ 3581], loss: 2.795, per_step_time: 819ms, lr: 3.6422345e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:31:04,637 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.8% |                                     | 9.76186 samples/s/p  0:35:18 }
2024-06-05 15:31:07,921 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1000/ 3581], loss: 2.615, per_step_time: 819ms, lr: 3.6367597e-05, overflow cond: False, loss_scale: 16384.0
2024-06-05 15:31:07,921 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   27.9% |                                     | 9.76045 samples/s/p  0:35:15 }
2024-06-05 15:31:07,922 - mindformers[mindformers/core/callback/callback.py:561] - INFO - ......Saving ckpt......
2024-06-05 15:32:39,236 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1004/ 3581], loss: 2.903, per_step_time: 3727ms, lr: 3.6312846e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:39,237 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.0% |                                    | 2.14644 samples/s/p  2:40:04 }
2024-06-05 15:32:42,524 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1008/ 3581], loss: 2.876, per_step_time: 820ms, lr: 3.62581e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:42,525 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.1% |                                    | 9.74853 samples/s/p  0:35:11 }
2024-06-05 15:32:45,798 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1012/ 3581], loss: 2.662, per_step_time: 817ms, lr: 3.6203353e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:45,799 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.3% |                                    | 9.78869 samples/s/p  0:34:59 }
2024-06-05 15:32:49,086 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1016/ 3581], loss: 2.649, per_step_time: 820ms, lr: 3.61486e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:49,087 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.4% |                                    | 9.74777 samples/s/p  0:35:05 }
2024-06-05 15:32:52,381 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1020/ 3581], loss: 2.623, per_step_time: 822ms, lr: 3.6093854e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:52,381 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.5% |                                    | 9.72891 samples/s/p  0:35:05 }
2024-06-05 15:32:55,655 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1024/ 3581], loss: 2.524, per_step_time: 817ms, lr: 3.6039106e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:55,656 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.6% |                                    | 9.78769 samples/s/p  0:34:49 }
2024-06-05 15:32:58,921 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1028/ 3581], loss: 2.730, per_step_time: 815ms, lr: 3.5984358e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:32:58,922 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.7% |                                    | 9.81294 samples/s/p  0:34:41 }
2024-06-05 15:33:02,209 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1032/ 3581], loss: 2.766, per_step_time: 820ms, lr: 3.5929603e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:02,209 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.8% |                                    | 9.74896 samples/s/p  0:34:51 }
2024-06-05 15:33:05,494 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1036/ 3581], loss: 2.808, per_step_time: 820ms, lr: 3.587486e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:05,495 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   28.9% |                                    | 9.75493 samples/s/p  0:34:47 }
2024-06-05 15:33:08,783 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1040/ 3581], loss: 2.728, per_step_time: 820ms, lr: 3.5820114e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:08,783 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.0% |                                    | 9.74567 samples/s/p  0:34:45 }
2024-06-05 15:33:12,064 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1044/ 3581], loss: 2.930, per_step_time: 819ms, lr: 3.5765363e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:12,065 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.2% |                                    | 9.76719 samples/s/p  0:34:37 }
2024-06-05 15:33:15,345 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1048/ 3581], loss: 2.703, per_step_time: 818ms, lr: 3.571061e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:15,346 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.3% |                                    | 9.76884 samples/s/p  0:34:34 }
2024-06-05 15:33:18,632 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1052/ 3581], loss: 2.598, per_step_time: 820ms, lr: 3.5655867e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:18,632 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.4% |                                    | 9.75225 samples/s/p  0:34:34 }
2024-06-05 15:33:21,922 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1056/ 3581], loss: 2.689, per_step_time: 821ms, lr: 3.560112e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:21,923 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.5% |                                    | 9.74006 samples/s/p  0:34:33 }
2024-06-05 15:33:25,215 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1060/ 3581], loss: 2.830, per_step_time: 821ms, lr: 3.5546367e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:25,215 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.6% |                                    | 9.73543 samples/s/p  0:34:31 }
2024-06-05 15:33:28,498 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1064/ 3581], loss: 2.804, per_step_time: 819ms, lr: 3.549162e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:28,499 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.7% |                                    | 9.76054 samples/s/p  0:34:23 }
2024-06-05 15:33:31,782 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1068/ 3581], loss: 2.699, per_step_time: 819ms, lr: 3.543687e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:31,782 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.8% |                                    | 9.76112 samples/s/p  0:34:19 }
2024-06-05 15:33:35,064 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1072/ 3581], loss: 2.712, per_step_time: 819ms, lr: 3.5382123e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:35,064 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   29.9% |                                    | 9.76549 samples/s/p  0:34:15 }
2024-06-05 15:33:38,339 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1076/ 3581], loss: 2.635, per_step_time: 817ms, lr: 3.5327375e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:38,340 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.0% |                                   | 9.78689 samples/s/p  0:34:07 }
2024-06-05 15:33:41,618 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1080/ 3581], loss: 2.673, per_step_time: 818ms, lr: 3.5272624e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:41,618 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.2% |                                   | 9.77597 samples/s/p  0:34:06 }
2024-06-05 15:33:44,894 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1084/ 3581], loss: 2.917, per_step_time: 817ms, lr: 3.5217876e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:44,894 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.3% |                                   | 9.78411 samples/s/p  0:34:01 }
2024-06-05 15:33:48,177 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1088/ 3581], loss: 2.580, per_step_time: 819ms, lr: 3.5163128e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:48,177 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.4% |                                   | 9.76246 samples/s/p  0:34:02 }
2024-06-05 15:33:51,460 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1092/ 3581], loss: 2.743, per_step_time: 819ms, lr: 3.5108376e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:51,460 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.5% |                                   | 9.76431 samples/s/p  0:33:59 }
2024-06-05 15:33:54,740 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1096/ 3581], loss: 2.789, per_step_time: 818ms, lr: 3.505363e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:54,741 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.6% |                                   | 9.76992 samples/s/p  0:33:54 }
2024-06-05 15:33:58,035 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1100/ 3581], loss: 2.786, per_step_time: 822ms, lr: 3.499888e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:33:58,035 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.7% |                                   | 9.72847 samples/s/p  0:34:00 }
2024-06-05 15:34:01,314 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1104/ 3581], loss: 2.720, per_step_time: 818ms, lr: 3.4944132e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:01,314 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.8% |                                   | 9.77616 samples/s/p  0:33:46 }
2024-06-05 15:34:04,604 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1108/ 3581], loss: 2.615, per_step_time: 821ms, lr: 3.4889385e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:04,605 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   30.9% |                                   | 9.74031 samples/s/p  0:33:51 }
2024-06-05 15:34:07,890 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1112/ 3581], loss: 2.843, per_step_time: 820ms, lr: 3.4834633e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:07,890 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.1% |                                   | 9.75529 samples/s/p  0:33:44 }
2024-06-05 15:34:11,170 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1116/ 3581], loss: 2.788, per_step_time: 818ms, lr: 3.477989e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:11,170 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.2% |                                   | 9.77154 samples/s/p  0:33:38 }
2024-06-05 15:34:14,441 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1120/ 3581], loss: 2.865, per_step_time: 816ms, lr: 3.472514e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:14,441 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.3% |                                   | 9.79766 samples/s/p  0:33:29 }
2024-06-05 15:34:17,721 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1124/ 3581], loss: 2.731, per_step_time: 818ms, lr: 3.467039e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:17,721 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.4% |                                   | 9.77244 samples/s/p  0:33:31 }
2024-06-05 15:34:21,000 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1128/ 3581], loss: 2.759, per_step_time: 818ms, lr: 3.461564e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:21,000 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.5% |                                   | 9.77374 samples/s/p  0:33:27 }
2024-06-05 15:34:24,283 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1132/ 3581], loss: 2.538, per_step_time: 819ms, lr: 3.456089e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:24,284 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.6% |                                   | 9.76109 samples/s/p  0:33:27 }
2024-06-05 15:34:27,565 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1136/ 3581], loss: 2.724, per_step_time: 819ms, lr: 3.4506145e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:27,565 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.7% |                                   | 9.76719 samples/s/p  0:33:22 }
2024-06-05 15:34:30,838 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1140/ 3581], loss: 2.466, per_step_time: 816ms, lr: 3.4451397e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:30,838 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.8% |                                   | 9.79411 samples/s/p  0:33:13 }
2024-06-05 15:34:34,119 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1144/ 3581], loss: 2.786, per_step_time: 818ms, lr: 3.4396646e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:34,120 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   31.9% |                                   | 9.76927 samples/s/p  0:33:15 }
2024-06-05 15:34:37,403 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1148/ 3581], loss: 2.496, per_step_time: 819ms, lr: 3.4341898e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:37,404 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.1% |                                  | 9.75867 samples/s/p  0:33:14 }
2024-06-05 15:34:40,701 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1152/ 3581], loss: 2.721, per_step_time: 823ms, lr: 3.4287146e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:40,702 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.2% |                                  | 9.71917 samples/s/p  0:33:19 }
2024-06-05 15:34:43,987 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1156/ 3581], loss: 2.509, per_step_time: 820ms, lr: 3.4232402e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:43,988 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.3% |                                  | 9.75502 samples/s/p  0:33:08 }
2024-06-05 15:34:47,262 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1160/ 3581], loss: 2.818, per_step_time: 817ms, lr: 3.4177654e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:47,262 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.4% |                                  | 9.78689 samples/s/p  0:32:58 }
2024-06-05 15:34:50,540 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1164/ 3581], loss: 2.667, per_step_time: 818ms, lr: 3.4122906e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:50,541 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.5% |                                  | 9.77721 samples/s/p  0:32:57 }
2024-06-05 15:34:53,814 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1168/ 3581], loss: 2.663, per_step_time: 816ms, lr: 3.4068158e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:53,814 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.6% |                                  | 9.79330 samples/s/p  0:32:51 }
2024-06-05 15:34:57,096 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1172/ 3581], loss: 2.756, per_step_time: 819ms, lr: 3.4013403e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:34:57,097 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.7% |                                  | 9.76288 samples/s/p  0:32:54 }
2024-06-05 15:35:00,374 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1176/ 3581], loss: 2.866, per_step_time: 818ms, lr: 3.395866e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:00,375 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   32.8% |                                  | 9.77773 samples/s/p  0:32:47 }
2024-06-05 15:35:03,661 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1180/ 3581], loss: 2.667, per_step_time: 820ms, lr: 3.390391e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:03,661 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.0% |                                  | 9.75321 samples/s/p  0:32:49 }
2024-06-05 15:35:06,942 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1184/ 3581], loss: 2.696, per_step_time: 819ms, lr: 3.3849163e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:06,943 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.1% |                                  | 9.76787 samples/s/p  0:32:43 }
2024-06-05 15:35:10,228 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1188/ 3581], loss: 2.793, per_step_time: 820ms, lr: 3.379441e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:10,228 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.2% |                                  | 9.75461 samples/s/p  0:32:42 }
2024-06-05 15:35:13,527 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1192/ 3581], loss: 2.735, per_step_time: 823ms, lr: 3.3739667e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:13,527 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.3% |                                  | 9.71572 samples/s/p  0:32:47 }
2024-06-05 15:35:16,809 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1196/ 3581], loss: 2.877, per_step_time: 819ms, lr: 3.368492e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:16,809 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.4% |                                  | 9.76516 samples/s/p  0:32:33 }
2024-06-05 15:35:20,089 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1200/ 3581], loss: 2.585, per_step_time: 818ms, lr: 3.3630167e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:20,090 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.5% |                                  | 9.77081 samples/s/p  0:32:29 }
2024-06-05 15:35:23,373 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1204/ 3581], loss: 2.564, per_step_time: 819ms, lr: 3.357542e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:23,373 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.6% |                                  | 9.76156 samples/s/p  0:32:28 }
2024-06-05 15:35:26,689 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1208/ 3581], loss: 2.791, per_step_time: 818ms, lr: 3.352067e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:26,690 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.7% |                                  | 9.77725 samples/s/p  0:32:21 }
2024-06-05 15:35:29,971 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1212/ 3581], loss: 2.421, per_step_time: 819ms, lr: 3.3465923e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:29,971 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   33.8% |                                  | 9.76708 samples/s/p  0:32:20 }
2024-06-05 15:35:33,248 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1216/ 3581], loss: 2.743, per_step_time: 817ms, lr: 3.3411172e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:33,248 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.0% |                                  | 9.78017 samples/s/p  0:32:14 }
2024-06-05 15:35:36,527 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1220/ 3581], loss: 2.566, per_step_time: 818ms, lr: 3.3356424e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:36,527 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.1% |                                 | 9.77537 samples/s/p  0:32:12 }
2024-06-05 15:35:39,811 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1224/ 3581], loss: 2.637, per_step_time: 819ms, lr: 3.3301676e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:39,811 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.2% |                                 | 9.75922 samples/s/p  0:32:12 }
2024-06-05 15:35:43,083 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1228/ 3581], loss: 2.719, per_step_time: 816ms, lr: 3.3246928e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:43,084 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.3% |                                 | 9.79436 samples/s/p  0:32:01 }
2024-06-05 15:35:46,361 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1232/ 3581], loss: 2.599, per_step_time: 818ms, lr: 3.319218e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:46,361 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.4% |                                 | 9.77990 samples/s/p  0:32:01 }
2024-06-05 15:35:49,650 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1236/ 3581], loss: 2.618, per_step_time: 820ms, lr: 3.313743e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:49,650 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.5% |                                 | 9.74552 samples/s/p  0:32:04 }
2024-06-05 15:35:52,933 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1240/ 3581], loss: 2.761, per_step_time: 819ms, lr: 3.308268e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:52,933 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.6% |                                 | 9.76289 samples/s/p  0:31:58 }
2024-06-05 15:35:56,217 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1244/ 3581], loss: 2.656, per_step_time: 819ms, lr: 3.3027933e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:56,217 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.7% |                                 | 9.75984 samples/s/p  0:31:55 }
2024-06-05 15:35:59,503 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1248/ 3581], loss: 2.642, per_step_time: 820ms, lr: 3.2973185e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:35:59,503 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   34.9% |                                 | 9.75462 samples/s/p  0:31:53 }
2024-06-05 15:36:02,776 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1252/ 3581], loss: 2.936, per_step_time: 817ms, lr: 3.2918433e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:02,776 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.0% |                                 | 9.79189 samples/s/p  0:31:42 }
2024-06-05 15:36:06,058 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1256/ 3581], loss: 2.447, per_step_time: 819ms, lr: 3.286369e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:06,058 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.1% |                                 | 9.76637 samples/s/p  0:31:44 }
2024-06-05 15:36:09,343 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1260/ 3581], loss: 2.681, per_step_time: 820ms, lr: 3.280894e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:09,343 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.2% |                                 | 9.75532 samples/s/p  0:31:43 }
2024-06-05 15:36:12,623 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1264/ 3581], loss: 2.770, per_step_time: 818ms, lr: 3.275419e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:12,623 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.3% |                                 | 9.77501 samples/s/p  0:31:36 }
2024-06-05 15:36:15,905 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1268/ 3581], loss: 2.709, per_step_time: 819ms, lr: 3.269944e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:15,905 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.4% |                                 | 9.76563 samples/s/p  0:31:34 }
2024-06-05 15:36:19,188 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1272/ 3581], loss: 2.720, per_step_time: 819ms, lr: 3.264469e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:19,188 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.5% |                                 | 9.76116 samples/s/p  0:31:32 }
2024-06-05 15:36:22,473 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1276/ 3581], loss: 2.652, per_step_time: 819ms, lr: 3.2589945e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:22,473 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.6% |                                 | 9.75714 samples/s/p  0:31:29 }
2024-06-05 15:36:25,760 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1280/ 3581], loss: 2.772, per_step_time: 820ms, lr: 3.2535194e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:25,761 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.7% |                                 | 9.74973 samples/s/p  0:31:28 }
2024-06-05 15:36:29,054 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1284/ 3581], loss: 2.718, per_step_time: 821ms, lr: 3.2480446e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:29,054 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   35.9% |                                 | 9.73277 samples/s/p  0:31:28 }
2024-06-05 15:36:32,345 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1288/ 3581], loss: 2.779, per_step_time: 821ms, lr: 3.2425698e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:32,345 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.0% |                                 | 9.73903 samples/s/p  0:31:23 }
2024-06-05 15:36:35,627 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1292/ 3581], loss: 2.617, per_step_time: 819ms, lr: 3.2370946e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:35,627 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.1% |                                | 9.76433 samples/s/p  0:31:15 }
2024-06-05 15:36:38,911 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1296/ 3581], loss: 2.804, per_step_time: 819ms, lr: 3.2316202e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:38,911 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.2% |                                | 9.76095 samples/s/p  0:31:12 }
2024-06-05 15:36:42,188 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1300/ 3581], loss: 2.818, per_step_time: 818ms, lr: 3.2261447e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:42,189 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.3% |                                | 9.77875 samples/s/p  0:31:06 }
2024-06-05 15:36:45,467 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1304/ 3581], loss: 2.544, per_step_time: 818ms, lr: 3.2206703e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:45,467 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.4% |                                | 9.77503 samples/s/p  0:31:03 }
2024-06-05 15:36:48,766 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1308/ 3581], loss: 2.759, per_step_time: 823ms, lr: 3.2151955e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:48,766 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.5% |                                | 9.71536 samples/s/p  0:31:11 }
2024-06-05 15:36:52,038 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1312/ 3581], loss: 2.802, per_step_time: 816ms, lr: 3.2097203e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:52,039 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.6% |                                | 9.79432 samples/s/p  0:30:53 }
2024-06-05 15:36:55,318 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1316/ 3581], loss: 2.703, per_step_time: 818ms, lr: 3.2042455e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:55,318 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.7% |                                | 9.77326 samples/s/p  0:30:54 }
2024-06-05 15:36:58,591 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1320/ 3581], loss: 2.694, per_step_time: 817ms, lr: 3.198771e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:36:58,591 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   36.9% |                                | 9.79182 samples/s/p  0:30:47 }
2024-06-05 15:37:01,869 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1324/ 3581], loss: 2.633, per_step_time: 818ms, lr: 3.1932963e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:01,870 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.0% |                                | 9.77523 samples/s/p  0:30:47 }
2024-06-05 15:37:05,144 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1328/ 3581], loss: 2.727, per_step_time: 817ms, lr: 3.187821e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:05,145 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.1% |                                | 9.78759 samples/s/p  0:30:41 }
2024-06-05 15:37:08,421 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1332/ 3581], loss: 2.727, per_step_time: 817ms, lr: 3.182346e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:08,422 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.2% |                                | 9.78183 samples/s/p  0:30:39 }
2024-06-05 15:37:11,705 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1336/ 3581], loss: 2.490, per_step_time: 819ms, lr: 3.1768715e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:11,705 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.3% |                                | 9.76113 samples/s/p  0:30:39 }
2024-06-05 15:37:14,991 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1340/ 3581], loss: 2.519, per_step_time: 820ms, lr: 3.1713967e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:14,992 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.4% |                                | 9.75283 samples/s/p  0:30:38 }
2024-06-05 15:37:18,275 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1344/ 3581], loss: 2.735, per_step_time: 819ms, lr: 3.1659216e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:18,275 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.5% |                                | 9.76058 samples/s/p  0:30:33 }
2024-06-05 15:37:21,557 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1348/ 3581], loss: 2.713, per_step_time: 819ms, lr: 3.1604468e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:21,558 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.6% |                                | 9.76528 samples/s/p  0:30:29 }
2024-06-05 15:37:24,838 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1352/ 3581], loss: 2.862, per_step_time: 818ms, lr: 3.1549716e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:24,838 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.8% |                                | 9.76925 samples/s/p  0:30:25 }
2024-06-05 15:37:28,124 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1356/ 3581], loss: 2.656, per_step_time: 820ms, lr: 3.1494972e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:28,124 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   37.9% |                                | 9.75372 samples/s/p  0:30:24 }
2024-06-05 15:37:31,406 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1360/ 3581], loss: 2.331, per_step_time: 819ms, lr: 3.1440217e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:31,407 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.0% |                                | 9.76465 samples/s/p  0:30:19 }
2024-06-05 15:37:34,688 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1364/ 3581], loss: 2.708, per_step_time: 819ms, lr: 3.1385473e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:34,688 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.1% |                               | 9.76727 samples/s/p  0:30:15 }
2024-06-05 15:37:37,968 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1368/ 3581], loss: 2.672, per_step_time: 818ms, lr: 3.1330725e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:37,969 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.2% |                               | 9.77030 samples/s/p  0:30:12 }
2024-06-05 15:37:41,241 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1372/ 3581], loss: 2.593, per_step_time: 816ms, lr: 3.1275977e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:41,241 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.3% |                               | 9.79572 samples/s/p  0:30:04 }
2024-06-05 15:37:44,526 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1376/ 3581], loss: 2.522, per_step_time: 819ms, lr: 3.122123e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:44,526 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.4% |                               | 9.75716 samples/s/p  0:30:07 }
2024-06-05 15:37:47,798 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1380/ 3581], loss: 2.649, per_step_time: 816ms, lr: 3.1166473e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:47,798 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.5% |                               | 9.79540 samples/s/p  0:29:57 }
2024-06-05 15:37:51,084 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1384/ 3581], loss: 2.860, per_step_time: 820ms, lr: 3.111173e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:51,085 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.6% |                               | 9.75169 samples/s/p  0:30:02 }
2024-06-05 15:37:54,376 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1388/ 3581], loss: 2.650, per_step_time: 821ms, lr: 3.1056985e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:54,376 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.8% |                               | 9.73803 samples/s/p  0:30:01 }
2024-06-05 15:37:57,664 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1392/ 3581], loss: 2.671, per_step_time: 820ms, lr: 3.1002233e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:37:57,665 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   38.9% |                               | 9.74592 samples/s/p  0:29:56 }
2024-06-05 15:38:00,952 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1396/ 3581], loss: 2.491, per_step_time: 820ms, lr: 3.094748e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:00,953 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.0% |                               | 9.74881 samples/s/p  0:29:53 }
2024-06-05 15:38:04,244 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1400/ 3581], loss: 2.708, per_step_time: 821ms, lr: 3.0892737e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:04,244 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.1% |                               | 9.73643 samples/s/p  0:29:52 }
2024-06-05 15:38:07,523 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1404/ 3581], loss: 2.642, per_step_time: 818ms, lr: 3.083799e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:07,524 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.2% |                               | 9.77322 samples/s/p  0:29:42 }
2024-06-05 15:38:10,801 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1408/ 3581], loss: 2.807, per_step_time: 818ms, lr: 3.0783238e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:10,802 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.3% |                               | 9.77831 samples/s/p  0:29:37 }
2024-06-05 15:38:14,085 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1412/ 3581], loss: 2.691, per_step_time: 819ms, lr: 3.072849e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:14,085 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.4% |                               | 9.76105 samples/s/p  0:29:37 }
2024-06-05 15:38:17,356 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1416/ 3581], loss: 2.807, per_step_time: 816ms, lr: 3.0673746e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:17,357 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.5% |                               | 9.79739 samples/s/p  0:29:27 }
2024-06-05 15:38:20,639 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1420/ 3581], loss: 2.548, per_step_time: 819ms, lr: 3.0618994e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:20,640 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.7% |                               | 9.76344 samples/s/p  0:29:30 }
2024-06-05 15:38:23,921 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1424/ 3581], loss: 2.688, per_step_time: 818ms, lr: 3.0564242e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:23,921 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.8% |                               | 9.76838 samples/s/p  0:29:26 }
2024-06-05 15:38:27,194 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1428/ 3581], loss: 2.643, per_step_time: 817ms, lr: 3.0509498e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:27,195 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   39.9% |                               | 9.79108 samples/s/p  0:29:19 }
2024-06-05 15:38:30,472 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1432/ 3581], loss: 2.616, per_step_time: 818ms, lr: 3.0454748e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:30,472 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.0% |                               | 9.77815 samples/s/p  0:29:18 }
2024-06-05 15:38:33,753 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1436/ 3581], loss: 2.535, per_step_time: 819ms, lr: 3.0399999e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:33,754 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.1% |                              | 9.76761 samples/s/p  0:29:16 }
2024-06-05 15:38:37,030 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1440/ 3581], loss: 2.664, per_step_time: 817ms, lr: 3.034525e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:37,030 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.2% |                              | 9.78313 samples/s/p  0:29:10 }
2024-06-05 15:38:40,312 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1444/ 3581], loss: 2.630, per_step_time: 819ms, lr: 3.0290501e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:40,313 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.3% |                              | 9.76461 samples/s/p  0:29:10 }
2024-06-05 15:38:43,598 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1448/ 3581], loss: 2.762, per_step_time: 820ms, lr: 3.0235755e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:43,599 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.4% |                              | 9.75342 samples/s/p  0:29:09 }
2024-06-05 15:38:46,886 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1452/ 3581], loss: 2.688, per_step_time: 820ms, lr: 3.0181005e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:46,887 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.5% |                              | 9.74768 samples/s/p  0:29:07 }
2024-06-05 15:38:50,169 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1456/ 3581], loss: 2.617, per_step_time: 819ms, lr: 3.0126255e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:50,170 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.7% |                              | 9.76341 samples/s/p  0:29:01 }
2024-06-05 15:38:53,454 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1460/ 3581], loss: 2.549, per_step_time: 819ms, lr: 3.0071507e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:53,455 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.8% |                              | 9.75667 samples/s/p  0:28:59 }
2024-06-05 15:38:56,733 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1464/ 3581], loss: 2.707, per_step_time: 818ms, lr: 3.0016761e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:38:56,733 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   40.9% |                              | 9.77529 samples/s/p  0:28:52 }
2024-06-05 15:39:00,023 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1468/ 3581], loss: 2.937, per_step_time: 821ms, lr: 2.9962011e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:00,024 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.0% |                              | 9.74123 samples/s/p  0:28:55 }
2024-06-05 15:39:03,303 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1472/ 3581], loss: 2.576, per_step_time: 818ms, lr: 2.9907262e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:03,303 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.1% |                              | 9.77273 samples/s/p  0:28:46 }
2024-06-05 15:39:06,587 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1476/ 3581], loss: 2.635, per_step_time: 819ms, lr: 2.9852512e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:06,588 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.2% |                              | 9.75850 samples/s/p  0:28:45 }
2024-06-05 15:39:09,863 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1480/ 3581], loss: 2.538, per_step_time: 817ms, lr: 2.9797768e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:09,863 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.3% |                              | 9.78468 samples/s/p  0:28:37 }
2024-06-05 15:39:13,146 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1484/ 3581], loss: 2.744, per_step_time: 819ms, lr: 2.9743018e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:13,146 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.4% |                              | 9.76138 samples/s/p  0:28:38 }
2024-06-05 15:39:16,425 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1488/ 3581], loss: 2.603, per_step_time: 818ms, lr: 2.9688264e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:16,426 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.6% |                              | 9.77419 samples/s/p  0:28:33 }
2024-06-05 15:39:19,708 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1492/ 3581], loss: 2.564, per_step_time: 819ms, lr: 2.9633518e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:19,708 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.7% |                              | 9.76678 samples/s/p  0:28:31 }
2024-06-05 15:39:22,994 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1496/ 3581], loss: 2.732, per_step_time: 820ms, lr: 2.9578772e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:22,994 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.8% |                              | 9.75370 samples/s/p  0:28:30 }
2024-06-05 15:39:26,271 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1500/ 3581], loss: 2.490, per_step_time: 817ms, lr: 2.9524022e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:26,271 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   41.9% |                              | 9.78026 samples/s/p  0:28:22 }
2024-06-05 15:39:29,555 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1504/ 3581], loss: 2.775, per_step_time: 819ms, lr: 2.946927e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:29,556 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.0% |                              | 9.75830 samples/s/p  0:28:22 }
2024-06-05 15:39:32,838 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1508/ 3581], loss: 2.626, per_step_time: 819ms, lr: 2.9414525e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:32,838 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.1% |                             | 9.76626 samples/s/p  0:28:18 }
2024-06-05 15:39:36,119 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1512/ 3581], loss: 2.626, per_step_time: 818ms, lr: 2.9359779e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:36,119 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.2% |                             | 9.76905 samples/s/p  0:28:14 }
2024-06-05 15:39:39,407 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1516/ 3581], loss: 2.603, per_step_time: 820ms, lr: 2.9305029e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:39,407 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.3% |                             | 9.74673 samples/s/p  0:28:14 }
2024-06-05 15:39:42,691 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1520/ 3581], loss: 2.713, per_step_time: 819ms, lr: 2.9250275e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:42,692 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.4% |                             | 9.75952 samples/s/p  0:28:09 }
2024-06-05 15:39:45,976 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1524/ 3581], loss: 2.674, per_step_time: 819ms, lr: 2.9195531e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:45,976 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.6% |                             | 9.75725 samples/s/p  0:28:06 }
2024-06-05 15:39:49,258 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1528/ 3581], loss: 2.515, per_step_time: 819ms, lr: 2.9140781e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:49,259 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.7% |                             | 9.76474 samples/s/p  0:28:01 }
2024-06-05 15:39:52,546 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1532/ 3581], loss: 2.601, per_step_time: 820ms, lr: 2.9086032e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:52,546 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.8% |                             | 9.74933 samples/s/p  0:28:01 }
2024-06-05 15:39:55,827 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1536/ 3581], loss: 2.743, per_step_time: 819ms, lr: 2.9031282e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:55,827 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   42.9% |                             | 9.76770 samples/s/p  0:27:54 }
2024-06-05 15:39:59,108 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1540/ 3581], loss: 2.683, per_step_time: 819ms, lr: 2.8976536e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:39:59,109 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.0% |                             | 9.76713 samples/s/p  0:27:51 }
2024-06-05 15:40:02,386 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1544/ 3581], loss: 2.634, per_step_time: 818ms, lr: 2.8921788e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:02,387 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.1% |                             | 9.77739 samples/s/p  0:27:46 }
2024-06-05 15:40:05,664 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1548/ 3581], loss: 2.774, per_step_time: 818ms, lr: 2.8867038e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:05,665 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.2% |                             | 9.77981 samples/s/p  0:27:43 }
2024-06-05 15:40:08,948 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1552/ 3581], loss: 2.731, per_step_time: 819ms, lr: 2.8812288e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:08,948 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.3% |                             | 9.76594 samples/s/p  0:27:42 }
2024-06-05 15:40:12,226 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1556/ 3581], loss: 2.726, per_step_time: 818ms, lr: 2.8757542e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:12,227 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.5% |                             | 9.77577 samples/s/p  0:27:37 }
2024-06-05 15:40:15,497 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1560/ 3581], loss: 2.674, per_step_time: 816ms, lr: 2.8702794e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:15,497 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.6% |                             | 9.80079 samples/s/p  0:27:29 }
2024-06-05 15:40:18,772 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1564/ 3581], loss: 2.762, per_step_time: 817ms, lr: 2.8648044e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:18,773 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.7% |                             | 9.78513 samples/s/p  0:27:29 }
2024-06-05 15:40:22,052 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1568/ 3581], loss: 2.612, per_step_time: 818ms, lr: 2.8593295e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:22,052 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.8% |                             | 9.77538 samples/s/p  0:27:27 }
2024-06-05 15:40:25,336 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1572/ 3581], loss: 2.562, per_step_time: 819ms, lr: 2.8538545e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:25,336 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   43.9% |                             | 9.76015 samples/s/p  0:27:26 }
2024-06-05 15:40:28,616 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1576/ 3581], loss: 2.674, per_step_time: 818ms, lr: 2.84838e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:28,616 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.0% |                            | 9.77124 samples/s/p  0:27:21 }
2024-06-05 15:40:31,896 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1580/ 3581], loss: 2.586, per_step_time: 818ms, lr: 2.842905e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:31,897 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.1% |                            | 9.77174 samples/s/p  0:27:18 }
2024-06-05 15:40:35,173 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1584/ 3581], loss: 2.614, per_step_time: 817ms, lr: 2.83743e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:35,173 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.2% |                            | 9.78358 samples/s/p  0:27:12 }
2024-06-05 15:40:38,457 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1588/ 3581], loss: 2.721, per_step_time: 819ms, lr: 2.8319551e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:38,458 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.3% |                            | 9.75746 samples/s/p  0:27:14 }
2024-06-05 15:40:41,747 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1592/ 3581], loss: 2.620, per_step_time: 821ms, lr: 2.8264805e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:41,747 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.5% |                            | 9.74308 samples/s/p  0:27:13 }
2024-06-05 15:40:45,034 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1596/ 3581], loss: 2.532, per_step_time: 820ms, lr: 2.8210055e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:45,034 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.6% |                            | 9.75127 samples/s/p  0:27:08 }
2024-06-05 15:40:48,320 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1600/ 3581], loss: 2.591, per_step_time: 820ms, lr: 2.8155306e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:48,321 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.7% |                            | 9.75204 samples/s/p  0:27:05 }
2024-06-05 15:40:51,605 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1604/ 3581], loss: 2.576, per_step_time: 819ms, lr: 2.8100558e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:51,606 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.8% |                            | 9.75673 samples/s/p  0:27:01 }
2024-06-05 15:40:54,894 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1608/ 3581], loss: 2.627, per_step_time: 820ms, lr: 2.8045812e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:54,894 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   44.9% |                            | 9.74561 samples/s/p  0:26:59 }
2024-06-05 15:40:58,180 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1612/ 3581], loss: 2.778, per_step_time: 820ms, lr: 2.7991062e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:40:58,181 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.0% |                            | 9.75303 samples/s/p  0:26:55 }
2024-06-05 15:41:01,465 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1616/ 3581], loss: 2.851, per_step_time: 819ms, lr: 2.7936308e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:01,465 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.1% |                            | 9.75794 samples/s/p  0:26:50 }
2024-06-05 15:41:04,748 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1620/ 3581], loss: 2.592, per_step_time: 819ms, lr: 2.7881562e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:04,748 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.2% |                            | 9.76264 samples/s/p  0:26:46 }
2024-06-05 15:41:08,031 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1624/ 3581], loss: 2.519, per_step_time: 819ms, lr: 2.7826814e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:08,032 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.4% |                            | 9.76154 samples/s/p  0:26:43 }
2024-06-05 15:41:11,321 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1628/ 3581], loss: 2.642, per_step_time: 821ms, lr: 2.7772065e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:11,322 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.5% |                            | 9.74372 samples/s/p  0:26:43 }
2024-06-05 15:41:14,592 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1632/ 3581], loss: 2.694, per_step_time: 816ms, lr: 2.7717315e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:14,593 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.6% |                            | 9.79944 samples/s/p  0:26:31 }
2024-06-05 15:41:17,866 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1636/ 3581], loss: 2.570, per_step_time: 817ms, lr: 2.7662569e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:17,866 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.7% |                            | 9.79170 samples/s/p  0:26:29 }
2024-06-05 15:41:21,141 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1640/ 3581], loss: 2.724, per_step_time: 817ms, lr: 2.760782e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:21,141 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.8% |                            | 9.78586 samples/s/p  0:26:26 }
2024-06-05 15:41:24,421 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1644/ 3581], loss: 2.781, per_step_time: 818ms, lr: 2.7553071e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:24,422 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   45.9% |                            | 9.77023 samples/s/p  0:26:26 }
2024-06-05 15:41:27,704 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1648/ 3581], loss: 2.622, per_step_time: 819ms, lr: 2.7498321e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:27,704 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.0% |                           | 9.76588 samples/s/p  0:26:23 }
2024-06-05 15:41:30,987 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1652/ 3581], loss: 2.605, per_step_time: 819ms, lr: 2.7443575e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:30,987 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.1% |                           | 9.76281 samples/s/p  0:26:20 }
2024-06-05 15:41:34,271 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1656/ 3581], loss: 2.590, per_step_time: 819ms, lr: 2.7388825e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:34,272 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.2% |                           | 9.75788 samples/s/p  0:26:18 }
2024-06-05 15:41:37,551 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1660/ 3581], loss: 2.672, per_step_time: 818ms, lr: 2.7334076e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:37,552 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.4% |                           | 9.77117 samples/s/p  0:26:12 }
2024-06-05 15:41:40,832 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1664/ 3581], loss: 2.538, per_step_time: 818ms, lr: 2.7279326e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:40,833 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.5% |                           | 9.76922 samples/s/p  0:26:09 }
2024-06-05 15:41:44,114 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1668/ 3581], loss: 2.720, per_step_time: 819ms, lr: 2.7224578e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:44,114 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.6% |                           | 9.76790 samples/s/p  0:26:06 }
2024-06-05 15:41:47,403 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1672/ 3581], loss: 2.498, per_step_time: 821ms, lr: 2.7169832e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:47,403 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.7% |                           | 9.74388 samples/s/p  0:26:07 }
2024-06-05 15:41:50,685 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1676/ 3581], loss: 2.569, per_step_time: 819ms, lr: 2.7115082e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:50,685 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.8% |                           | 9.76620 samples/s/p  0:26:00 }
2024-06-05 15:41:53,962 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1680/ 3581], loss: 2.643, per_step_time: 818ms, lr: 2.7060336e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:53,963 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   46.9% |                           | 9.77958 samples/s/p  0:25:55 }
2024-06-05 15:41:57,245 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1684/ 3581], loss: 2.697, per_step_time: 819ms, lr: 2.7005588e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:41:57,246 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.0% |                           | 9.76239 samples/s/p  0:25:54 }
2024-06-05 15:42:00,532 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1688/ 3581], loss: 2.478, per_step_time: 820ms, lr: 2.6950838e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:00,532 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.1% |                           | 9.75177 samples/s/p  0:25:52 }
2024-06-05 15:42:03,814 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1692/ 3581], loss: 2.602, per_step_time: 819ms, lr: 2.6896088e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:03,814 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.2% |                           | 9.76518 samples/s/p  0:25:47 }
2024-06-05 15:42:07,102 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1696/ 3581], loss: 2.694, per_step_time: 820ms, lr: 2.6841342e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:07,102 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.4% |                           | 9.74842 samples/s/p  0:25:46 }
2024-06-05 15:42:10,392 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1700/ 3581], loss: 2.738, per_step_time: 821ms, lr: 2.6786594e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:10,392 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.5% |                           | 9.74203 samples/s/p  0:25:44 }
2024-06-05 15:42:13,682 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1704/ 3581], loss: 2.721, per_step_time: 821ms, lr: 2.6731845e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:13,683 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.6% |                           | 9.73896 samples/s/p  0:25:41 }
2024-06-05 15:42:16,972 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1708/ 3581], loss: 2.460, per_step_time: 821ms, lr: 2.6677095e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:16,973 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.7% |                           | 9.74262 samples/s/p  0:25:37 }
2024-06-05 15:42:20,251 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1712/ 3581], loss: 2.694, per_step_time: 818ms, lr: 2.6622345e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:20,252 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.8% |                           | 9.77515 samples/s/p  0:25:29 }
2024-06-05 15:42:23,537 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1716/ 3581], loss: 2.682, per_step_time: 820ms, lr: 2.6567599e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:23,538 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   47.9% |                           | 9.75458 samples/s/p  0:25:29 }
2024-06-05 15:42:26,824 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1720/ 3581], loss: 2.571, per_step_time: 820ms, lr: 2.651285e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:26,824 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.0% |                          | 9.75294 samples/s/p  0:25:26 }
2024-06-05 15:42:30,106 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1724/ 3581], loss: 2.674, per_step_time: 819ms, lr: 2.64581e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:30,106 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.1% |                          | 9.76444 samples/s/p  0:25:21 }
2024-06-05 15:42:33,390 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1728/ 3581], loss: 2.530, per_step_time: 819ms, lr: 2.6403352e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:33,391 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.3% |                          | 9.76024 samples/s/p  0:25:18 }
2024-06-05 15:42:36,681 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1732/ 3581], loss: 2.599, per_step_time: 821ms, lr: 2.6348605e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:36,681 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.4% |                          | 9.73909 samples/s/p  0:25:18 }
2024-06-05 15:42:39,966 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1736/ 3581], loss: 2.608, per_step_time: 820ms, lr: 2.6293856e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:39,967 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.5% |                          | 9.75580 samples/s/p  0:25:12 }
2024-06-05 15:42:43,253 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1740/ 3581], loss: 2.601, per_step_time: 820ms, lr: 2.6239106e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:43,254 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.6% |                          | 9.75099 samples/s/p  0:25:10 }
2024-06-05 15:42:46,533 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1744/ 3581], loss: 2.563, per_step_time: 818ms, lr: 2.6184358e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:46,534 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.7% |                          | 9.77239 samples/s/p  0:25:03 }
2024-06-05 15:42:49,824 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1748/ 3581], loss: 2.562, per_step_time: 821ms, lr: 2.6129612e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:49,824 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.8% |                          | 9.74056 samples/s/p  0:25:05 }
2024-06-05 15:42:53,106 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1752/ 3581], loss: 2.607, per_step_time: 819ms, lr: 2.6074858e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:53,107 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   48.9% |                          | 9.76332 samples/s/p  0:24:58 }
2024-06-05 15:42:56,390 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1756/ 3581], loss: 2.649, per_step_time: 819ms, lr: 2.6020109e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:56,390 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.0% |                          | 9.76224 samples/s/p  0:24:55 }
2024-06-05 15:42:59,674 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1760/ 3581], loss: 2.550, per_step_time: 819ms, lr: 2.5965364e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:42:59,675 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.1% |                          | 9.75932 samples/s/p  0:24:52 }
2024-06-05 15:43:02,957 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1764/ 3581], loss: 2.629, per_step_time: 819ms, lr: 2.5910615e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:02,958 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.3% |                          | 9.76155 samples/s/p  0:24:49 }
2024-06-05 15:43:06,240 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1768/ 3581], loss: 2.570, per_step_time: 819ms, lr: 2.5855865e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:06,240 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.4% |                          | 9.76421 samples/s/p  0:24:45 }
2024-06-05 15:43:09,519 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1772/ 3581], loss: 2.619, per_step_time: 818ms, lr: 2.5801115e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:09,520 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.5% |                          | 9.77368 samples/s/p  0:24:40 }
2024-06-05 15:43:12,805 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1776/ 3581], loss: 2.548, per_step_time: 820ms, lr: 2.5746369e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:12,805 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.6% |                          | 9.75571 samples/s/p  0:24:40 }
2024-06-05 15:43:16,095 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1780/ 3581], loss: 2.615, per_step_time: 821ms, lr: 2.5691621e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:16,096 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.7% |                          | 9.74147 samples/s/p  0:24:39 }
2024-06-05 15:43:19,375 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1784/ 3581], loss: 2.628, per_step_time: 818ms, lr: 2.5636871e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:19,375 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.8% |                          | 9.77161 samples/s/p  0:24:31 }
2024-06-05 15:43:22,661 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1788/ 3581], loss: 2.522, per_step_time: 820ms, lr: 2.5582121e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:22,662 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   49.9% |                          | 9.75299 samples/s/p  0:24:30 }
2024-06-05 15:43:25,950 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1792/ 3581], loss: 2.611, per_step_time: 820ms, lr: 2.5527375e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:25,951 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.0% |                         | 9.74530 samples/s/p  0:24:28 }
2024-06-05 15:43:29,241 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1796/ 3581], loss: 2.615, per_step_time: 821ms, lr: 2.547263e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:29,241 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.2% |                         | 9.73934 samples/s/p  0:24:26 }
2024-06-05 15:43:32,533 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1800/ 3581], loss: 2.579, per_step_time: 821ms, lr: 2.5417876e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:32,534 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.3% |                         | 9.73410 samples/s/p  0:24:23 }
2024-06-05 15:43:35,817 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1804/ 3581], loss: 2.567, per_step_time: 819ms, lr: 2.5363128e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:35,817 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.4% |                         | 9.76199 samples/s/p  0:24:16 }
2024-06-05 15:43:39,091 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1808/ 3581], loss: 2.647, per_step_time: 817ms, lr: 2.5308378e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:39,092 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.5% |                         | 9.78856 samples/s/p  0:24:09 }
2024-06-05 15:43:42,376 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1812/ 3581], loss: 2.597, per_step_time: 819ms, lr: 2.5253632e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:42,377 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.6% |                         | 9.75995 samples/s/p  0:24:10 }
2024-06-05 15:43:45,653 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1816/ 3581], loss: 2.652, per_step_time: 817ms, lr: 2.5198882e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:45,653 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.7% |                         | 9.78133 samples/s/p  0:24:03 }
2024-06-05 15:43:48,941 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1820/ 3581], loss: 2.592, per_step_time: 820ms, lr: 2.5144136e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:48,942 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.8% |                         | 9.74669 samples/s/p  0:24:05 }
2024-06-05 15:43:52,222 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1824/ 3581], loss: 2.700, per_step_time: 818ms, lr: 2.5089386e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:52,222 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   50.9% |                         | 9.77017 samples/s/p  0:23:58 }
2024-06-05 15:43:55,510 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1828/ 3581], loss: 2.662, per_step_time: 820ms, lr: 2.5034638e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:55,511 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.0% |                         | 9.74600 samples/s/p  0:23:58 }
2024-06-05 15:43:58,795 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1832/ 3581], loss: 2.372, per_step_time: 819ms, lr: 2.4979887e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:43:58,795 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.2% |                         | 9.75850 samples/s/p  0:23:53 }
2024-06-05 15:44:02,083 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1836/ 3581], loss: 2.656, per_step_time: 820ms, lr: 2.492514e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:02,084 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.3% |                         | 9.74604 samples/s/p  0:23:52 }
2024-06-05 15:44:05,364 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1840/ 3581], loss: 2.759, per_step_time: 818ms, lr: 2.4870391e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:05,365 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.4% |                         | 9.76955 samples/s/p  0:23:45 }
2024-06-05 15:44:08,660 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1844/ 3581], loss: 2.534, per_step_time: 822ms, lr: 2.4815643e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:08,661 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.5% |                         | 9.72383 samples/s/p  0:23:49 }
2024-06-05 15:44:11,941 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1848/ 3581], loss: 2.444, per_step_time: 818ms, lr: 2.4760893e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:11,942 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.6% |                         | 9.77033 samples/s/p  0:23:38 }
2024-06-05 15:44:15,227 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1852/ 3581], loss: 2.542, per_step_time: 820ms, lr: 2.4706147e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:15,228 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.7% |                         | 9.75382 samples/s/p  0:23:38 }
2024-06-05 15:44:18,516 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1856/ 3581], loss: 2.599, per_step_time: 820ms, lr: 2.4651397e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:18,517 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.8% |                         | 9.74540 samples/s/p  0:23:36 }
2024-06-05 15:44:21,803 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1860/ 3581], loss: 2.586, per_step_time: 820ms, lr: 2.459665e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:21,803 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   51.9% |                         | 9.75195 samples/s/p  0:23:31 }
2024-06-05 15:44:25,092 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1864/ 3581], loss: 2.579, per_step_time: 820ms, lr: 2.45419e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:25,092 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.1% |                        | 9.74487 samples/s/p  0:23:29 }
2024-06-05 15:44:28,372 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1868/ 3581], loss: 2.789, per_step_time: 818ms, lr: 2.448715e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:28,373 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.2% |                        | 9.76925 samples/s/p  0:23:22 }
2024-06-05 15:44:31,662 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1872/ 3581], loss: 2.739, per_step_time: 821ms, lr: 2.44324e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:31,662 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.3% |                        | 9.74352 samples/s/p  0:23:23 }
2024-06-05 15:44:34,940 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1876/ 3581], loss: 2.356, per_step_time: 818ms, lr: 2.4377656e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:34,940 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.4% |                        | 9.77766 samples/s/p  0:23:15 }
2024-06-05 15:44:38,224 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1880/ 3581], loss: 2.560, per_step_time: 819ms, lr: 2.4322904e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:38,225 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.5% |                        | 9.75811 samples/s/p  0:23:14 }
2024-06-05 15:44:41,500 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1884/ 3581], loss: 2.850, per_step_time: 817ms, lr: 2.4268156e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:41,500 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.6% |                        | 9.78513 samples/s/p  0:23:07 }
2024-06-05 15:44:44,786 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1888/ 3581], loss: 2.594, per_step_time: 820ms, lr: 2.4213407e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:44,786 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.7% |                        | 9.75435 samples/s/p  0:23:08 }
2024-06-05 15:44:48,063 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1892/ 3581], loss: 2.687, per_step_time: 818ms, lr: 2.415866e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:48,064 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.8% |                        | 9.77823 samples/s/p  0:23:01 }
2024-06-05 15:44:51,339 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1896/ 3581], loss: 2.662, per_step_time: 817ms, lr: 2.410391e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:51,339 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   52.9% |                        | 9.78467 samples/s/p  0:22:57 }
2024-06-05 15:44:54,638 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1900/ 3581], loss: 2.390, per_step_time: 820ms, lr: 2.4049163e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:54,638 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.1% |                        | 9.75111 samples/s/p  0:22:59 }
2024-06-05 15:44:57,915 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1904/ 3581], loss: 2.512, per_step_time: 817ms, lr: 2.3994413e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:44:57,916 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.2% |                        | 9.78018 samples/s/p  0:22:51 }
2024-06-05 15:45:01,188 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1908/ 3581], loss: 2.522, per_step_time: 816ms, lr: 2.3939665e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:01,189 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.3% |                        | 9.79290 samples/s/p  0:22:46 }
2024-06-05 15:45:04,471 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1912/ 3581], loss: 2.535, per_step_time: 819ms, lr: 2.3884913e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:04,473 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.4% |                        | 9.76228 samples/s/p  0:22:47 }
2024-06-05 15:45:07,761 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1916/ 3581], loss: 2.573, per_step_time: 820ms, lr: 2.3830169e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:07,761 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.5% |                        | 9.74871 samples/s/p  0:22:46 }
2024-06-05 15:45:11,044 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1920/ 3581], loss: 2.687, per_step_time: 819ms, lr: 2.377542e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:11,044 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.6% |                        | 9.76404 samples/s/p  0:22:40 }
2024-06-05 15:45:14,333 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1924/ 3581], loss: 2.619, per_step_time: 821ms, lr: 2.3720671e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:14,334 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.7% |                        | 9.74283 samples/s/p  0:22:40 }
2024-06-05 15:45:17,626 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1928/ 3581], loss: 2.653, per_step_time: 821ms, lr: 2.3665922e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:17,626 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   53.8% |                        | 9.73560 samples/s/p  0:22:38 }
2024-06-05 15:45:20,910 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1932/ 3581], loss: 2.430, per_step_time: 819ms, lr: 2.3611172e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:20,910 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.0% |                        | 9.75836 samples/s/p  0:22:31 }
2024-06-05 15:45:24,187 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1936/ 3581], loss: 2.417, per_step_time: 817ms, lr: 2.3556422e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:24,188 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.1% |                       | 9.78084 samples/s/p  0:22:25 }
2024-06-05 15:45:27,471 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1940/ 3581], loss: 2.528, per_step_time: 819ms, lr: 2.3501678e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:27,471 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.2% |                       | 9.76229 samples/s/p  0:22:24 }
2024-06-05 15:45:30,751 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1944/ 3581], loss: 2.473, per_step_time: 818ms, lr: 2.3446926e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:30,752 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.3% |                       | 9.77069 samples/s/p  0:22:20 }
2024-06-05 15:45:34,035 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1948/ 3581], loss: 2.325, per_step_time: 819ms, lr: 2.3392182e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:34,036 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.4% |                       | 9.75977 samples/s/p  0:22:18 }
2024-06-05 15:45:37,312 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1952/ 3581], loss: 2.645, per_step_time: 817ms, lr: 2.3337429e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:37,312 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.5% |                       | 9.78228 samples/s/p  0:22:12 }
2024-06-05 15:45:40,590 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1956/ 3581], loss: 2.543, per_step_time: 818ms, lr: 2.3282682e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:40,591 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.6% |                       | 9.77686 samples/s/p  0:22:09 }
2024-06-05 15:45:43,870 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1960/ 3581], loss: 2.590, per_step_time: 818ms, lr: 2.3227934e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:43,870 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.7% |                       | 9.77353 samples/s/p  0:22:06 }
2024-06-05 15:45:47,161 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1964/ 3581], loss: 2.668, per_step_time: 821ms, lr: 2.3173185e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:47,162 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   54.8% |                       | 9.73726 samples/s/p  0:22:08 }
2024-06-05 15:45:50,443 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1968/ 3581], loss: 2.569, per_step_time: 819ms, lr: 2.3118435e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:50,443 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.0% |                       | 9.76736 samples/s/p  0:22:01 }
2024-06-05 15:45:53,720 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1972/ 3581], loss: 2.453, per_step_time: 818ms, lr: 2.3063689e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:53,721 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.1% |                       | 9.77936 samples/s/p  0:21:56 }
2024-06-05 15:45:57,002 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1976/ 3581], loss: 2.621, per_step_time: 819ms, lr: 2.3008935e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:45:57,003 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.2% |                       | 9.76500 samples/s/p  0:21:54 }
2024-06-05 15:46:00,284 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1980/ 3581], loss: 2.288, per_step_time: 819ms, lr: 2.2954191e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:46:00,284 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.3% |                       | 9.76785 samples/s/p  0:21:51 }
2024-06-05 15:46:03,560 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1984/ 3581], loss: 2.637, per_step_time: 817ms, lr: 2.2899441e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:46:03,561 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.4% |                       | 9.78170 samples/s/p  0:21:46 }
2024-06-05 15:46:06,836 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1988/ 3581], loss: 2.574, per_step_time: 817ms, lr: 2.2844693e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:46:06,837 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.5% |                       | 9.78478 samples/s/p  0:21:42 }
2024-06-05 15:46:10,118 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1992/ 3581], loss: 2.713, per_step_time: 819ms, lr: 2.2789942e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:46:10,118 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.6% |                       | 9.76673 samples/s/p  0:21:41 }
2024-06-05 15:46:13,401 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 1996/ 3581], loss: 2.427, per_step_time: 819ms, lr: 2.2735196e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:46:13,401 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.7% |                       | 9.76495 samples/s/p  0:21:38 }
2024-06-05 15:46:16,684 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2000/ 3581], loss: 2.566, per_step_time: 819ms, lr: 2.2680446e-05, overflow cond: False, loss_scale: 32768.0
2024-06-05 15:46:16,685 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   55.9% |                       | 9.76327 samples/s/p  0:21:35 }
2024-06-05 15:46:16,686 - mindformers[mindformers/core/callback/callback.py:561] - INFO - ......Saving ckpt......
2024-06-05 15:47:40,589 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2004/ 3581], loss: 2.731, per_step_time: 825ms, lr: 2.26257e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:47:40,590 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.0% |                       | 9.69655 samples/s/p  0:21:41 }
2024-06-05 15:47:43,870 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2008/ 3581], loss: 2.661, per_step_time: 818ms, lr: 2.2570948e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:47:43,870 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.1% |                      | 9.77046 samples/s/p  0:21:27 }
2024-06-05 15:47:47,139 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2012/ 3581], loss: 2.734, per_step_time: 815ms, lr: 2.25162e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:47:47,139 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.2% |                      | 9.80414 samples/s/p  0:21:20 }
2024-06-05 15:47:50,426 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2016/ 3581], loss: 2.569, per_step_time: 820ms, lr: 2.246145e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:47:50,426 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.3% |                      | 9.75107 samples/s/p  0:21:23 }
2024-06-05 15:47:53,710 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2020/ 3581], loss: 2.614, per_step_time: 819ms, lr: 2.2406704e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:47:53,710 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.4% |                      | 9.76097 samples/s/p  0:21:19 }
2024-06-05 15:47:57,000 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2024/ 3581], loss: 2.618, per_step_time: 821ms, lr: 2.2351955e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:47:57,000 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.5% |                      | 9.74257 samples/s/p  0:21:18 }
2024-06-05 15:48:00,278 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2028/ 3581], loss: 2.692, per_step_time: 818ms, lr: 2.2297207e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:00,279 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.6% |                      | 9.77694 samples/s/p  0:21:10 }
2024-06-05 15:48:03,563 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2032/ 3581], loss: 2.632, per_step_time: 819ms, lr: 2.2242457e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:03,563 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.7% |                      | 9.75756 samples/s/p  0:21:09 }
2024-06-05 15:48:06,844 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2036/ 3581], loss: 2.627, per_step_time: 818ms, lr: 2.218771e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:06,844 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   56.9% |                      | 9.77091 samples/s/p  0:21:04 }
2024-06-05 15:48:10,117 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2040/ 3581], loss: 2.582, per_step_time: 816ms, lr: 2.2132957e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:10,118 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.0% |                      | 9.79198 samples/s/p  0:20:58 }
2024-06-05 15:48:13,401 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2044/ 3581], loss: 2.510, per_step_time: 818ms, lr: 2.2078213e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:13,402 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.1% |                      | 9.77658 samples/s/p  0:20:57 }
2024-06-05 15:48:16,685 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2048/ 3581], loss: 2.539, per_step_time: 819ms, lr: 2.2023463e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:16,685 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.2% |                      | 9.76627 samples/s/p  0:20:55 }
2024-06-05 15:48:19,975 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2052/ 3581], loss: 2.553, per_step_time: 821ms, lr: 2.1968714e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:19,975 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.3% |                      | 9.74330 samples/s/p  0:20:55 }
2024-06-05 15:48:23,268 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2056/ 3581], loss: 2.618, per_step_time: 821ms, lr: 2.191397e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:23,268 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.4% |                      | 9.73309 samples/s/p  0:20:53 }
2024-06-05 15:48:26,559 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2060/ 3581], loss: 2.527, per_step_time: 821ms, lr: 2.1859218e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:26,560 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.5% |                      | 9.73923 samples/s/p  0:20:49 }
2024-06-05 15:48:29,846 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2064/ 3581], loss: 2.510, per_step_time: 820ms, lr: 2.1804472e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:29,846 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.6% |                      | 9.75135 samples/s/p  0:20:44 }
2024-06-05 15:48:33,129 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2068/ 3581], loss: 2.605, per_step_time: 819ms, lr: 2.1749722e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:33,130 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.7% |                      | 9.76329 samples/s/p  0:20:39 }
2024-06-05 15:48:36,408 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2072/ 3581], loss: 2.571, per_step_time: 818ms, lr: 2.1694972e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:36,409 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   57.9% |                      | 9.77392 samples/s/p  0:20:35 }
2024-06-05 15:48:39,682 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2076/ 3581], loss: 2.521, per_step_time: 817ms, lr: 2.1640224e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:39,683 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.0% |                      | 9.78962 samples/s/p  0:20:29 }
2024-06-05 15:48:42,959 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2080/ 3581], loss: 2.745, per_step_time: 817ms, lr: 2.1585476e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:42,959 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.1% |                     | 9.78243 samples/s/p  0:20:27 }
2024-06-05 15:48:46,233 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2084/ 3581], loss: 2.462, per_step_time: 817ms, lr: 2.1530726e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:46,233 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.2% |                     | 9.79125 samples/s/p  0:20:23 }
2024-06-05 15:48:49,499 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2088/ 3581], loss: 2.560, per_step_time: 815ms, lr: 2.1475978e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:49,500 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.3% |                     | 9.81235 samples/s/p  0:20:17 }
2024-06-05 15:48:52,776 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2092/ 3581], loss: 2.596, per_step_time: 817ms, lr: 2.1421229e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:52,777 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.4% |                     | 9.78283 samples/s/p  0:20:17 }
2024-06-05 15:48:56,058 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2096/ 3581], loss: 2.517, per_step_time: 818ms, lr: 2.1366483e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:56,058 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.5% |                     | 9.76867 samples/s/p  0:20:16 }
2024-06-05 15:48:59,343 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2100/ 3581], loss: 2.519, per_step_time: 820ms, lr: 2.1311733e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:48:59,344 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.6% |                     | 9.75546 samples/s/p  0:20:14 }
2024-06-05 15:49:02,634 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2104/ 3581], loss: 2.569, per_step_time: 821ms, lr: 2.1256985e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:02,635 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.8% |                     | 9.74039 samples/s/p  0:20:13 }
2024-06-05 15:49:05,925 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2108/ 3581], loss: 2.781, per_step_time: 820ms, lr: 2.1202235e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:05,925 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   58.9% |                     | 9.75124 samples/s/p  0:20:08 }
2024-06-05 15:49:09,223 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2112/ 3581], loss: 2.639, per_step_time: 823ms, lr: 2.1147485e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:09,223 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.0% |                     | 9.71808 samples/s/p  0:20:09 }
2024-06-05 15:49:12,513 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2116/ 3581], loss: 2.815, per_step_time: 821ms, lr: 2.1092736e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:12,514 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.1% |                     | 9.74271 samples/s/p  0:20:02 }
2024-06-05 15:49:15,803 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2120/ 3581], loss: 2.648, per_step_time: 821ms, lr: 2.1037991e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:15,803 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.2% |                     | 9.74340 samples/s/p  0:19:59 }
2024-06-05 15:49:19,084 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2124/ 3581], loss: 2.626, per_step_time: 819ms, lr: 2.098324e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:19,085 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.3% |                     | 9.76608 samples/s/p  0:19:53 }
2024-06-05 15:49:22,367 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2128/ 3581], loss: 2.603, per_step_time: 819ms, lr: 2.0928492e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:22,367 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.4% |                     | 9.76541 samples/s/p  0:19:50 }
2024-06-05 15:49:25,655 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2132/ 3581], loss: 2.870, per_step_time: 820ms, lr: 2.0873742e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:25,655 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.5% |                     | 9.74760 samples/s/p  0:19:49 }
2024-06-05 15:49:28,938 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2136/ 3581], loss: 2.475, per_step_time: 819ms, lr: 2.0818996e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:28,938 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.6% |                     | 9.76317 samples/s/p  0:19:44 }
2024-06-05 15:49:32,231 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2140/ 3581], loss: 2.692, per_step_time: 820ms, lr: 2.0764246e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:32,232 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.8% |                     | 9.75055 samples/s/p  0:19:42 }
2024-06-05 15:49:35,518 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2144/ 3581], loss: 2.683, per_step_time: 820ms, lr: 2.0709498e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:35,519 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   59.9% |                     | 9.75295 samples/s/p  0:19:38 }
2024-06-05 15:49:38,798 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2148/ 3581], loss: 2.726, per_step_time: 818ms, lr: 2.0654748e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:38,799 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.0% |                     | 9.77259 samples/s/p  0:19:33 }
2024-06-05 15:49:42,082 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2152/ 3581], loss: 2.358, per_step_time: 819ms, lr: 2.06e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:42,082 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.1% |                    | 9.76092 samples/s/p  0:19:31 }
2024-06-05 15:49:45,364 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2156/ 3581], loss: 2.496, per_step_time: 819ms, lr: 2.0545249e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:45,365 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.2% |                    | 9.76550 samples/s/p  0:19:27 }
2024-06-05 15:49:48,646 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2160/ 3581], loss: 2.461, per_step_time: 819ms, lr: 2.0490505e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:48,647 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.3% |                    | 9.76571 samples/s/p  0:19:24 }
2024-06-05 15:49:51,928 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2164/ 3581], loss: 2.774, per_step_time: 819ms, lr: 2.0435755e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:51,929 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.4% |                    | 9.76670 samples/s/p  0:19:20 }
2024-06-05 15:49:55,208 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2168/ 3581], loss: 2.638, per_step_time: 818ms, lr: 2.0381007e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:55,208 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.5% |                    | 9.77233 samples/s/p  0:19:16 }
2024-06-05 15:49:58,482 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2172/ 3581], loss: 2.578, per_step_time: 817ms, lr: 2.0326257e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:49:58,483 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.7% |                    | 9.78803 samples/s/p  0:19:11 }
2024-06-05 15:50:01,763 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2176/ 3581], loss: 2.656, per_step_time: 818ms, lr: 2.0271507e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:01,763 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.8% |                    | 9.77087 samples/s/p  0:19:10 }
2024-06-05 15:50:05,034 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2180/ 3581], loss: 2.610, per_step_time: 816ms, lr: 2.021676e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:05,035 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   60.9% |                    | 9.79771 samples/s/p  0:19:03 }
2024-06-05 15:50:08,315 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2184/ 3581], loss: 2.461, per_step_time: 818ms, lr: 2.0162013e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:08,315 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.0% |                    | 9.76875 samples/s/p  0:19:04 }
2024-06-05 15:50:11,597 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2188/ 3581], loss: 2.497, per_step_time: 819ms, lr: 2.0107262e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:11,597 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.1% |                    | 9.76573 samples/s/p  0:19:01 }
2024-06-05 15:50:14,884 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2192/ 3581], loss: 2.470, per_step_time: 820ms, lr: 2.0052514e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:14,885 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.2% |                    | 9.75084 samples/s/p  0:18:59 }
2024-06-05 15:50:18,162 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2196/ 3581], loss: 2.550, per_step_time: 817ms, lr: 1.9997764e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:18,162 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.3% |                    | 9.78042 samples/s/p  0:18:52 }
2024-06-05 15:50:21,446 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2200/ 3581], loss: 2.474, per_step_time: 819ms, lr: 1.9943018e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:21,447 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.4% |                    | 9.75872 samples/s/p  0:18:52 }
2024-06-05 15:50:24,719 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2204/ 3581], loss: 2.650, per_step_time: 816ms, lr: 1.9888268e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:24,720 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.5% |                    | 9.79540 samples/s/p  0:18:44 }
2024-06-05 15:50:28,010 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2208/ 3581], loss: 2.593, per_step_time: 821ms, lr: 1.983352e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:28,010 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.7% |                    | 9.74048 samples/s/p  0:18:47 }
2024-06-05 15:50:31,296 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2212/ 3581], loss: 2.543, per_step_time: 820ms, lr: 1.977877e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:31,296 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.8% |                    | 9.75437 samples/s/p  0:18:42 }
2024-06-05 15:50:34,584 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2216/ 3581], loss: 2.762, per_step_time: 820ms, lr: 1.9724024e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:34,584 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   61.9% |                    | 9.74953 samples/s/p  0:18:40 }
2024-06-05 15:50:37,867 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2220/ 3581], loss: 2.612, per_step_time: 819ms, lr: 1.966927e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:37,875 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.0% |                    | 9.76102 samples/s/p  0:18:35 }
2024-06-05 15:50:41,158 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2224/ 3581], loss: 2.438, per_step_time: 819ms, lr: 1.9614527e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:41,159 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.1% |                   | 9.76354 samples/s/p  0:18:31 }
2024-06-05 15:50:44,449 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2228/ 3581], loss: 2.584, per_step_time: 821ms, lr: 1.9559777e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:44,449 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.2% |                   | 9.74167 samples/s/p  0:18:31 }
2024-06-05 15:50:47,728 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2232/ 3581], loss: 2.515, per_step_time: 818ms, lr: 1.9505029e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:47,729 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.3% |                   | 9.77193 samples/s/p  0:18:24 }
2024-06-05 15:50:51,007 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2236/ 3581], loss: 2.353, per_step_time: 818ms, lr: 1.9450277e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:51,007 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.4% |                   | 9.77703 samples/s/p  0:18:20 }
2024-06-05 15:50:54,288 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2240/ 3581], loss: 2.530, per_step_time: 818ms, lr: 1.9395531e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:54,288 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.6% |                   | 9.76807 samples/s/p  0:18:18 }
2024-06-05 15:50:57,577 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2244/ 3581], loss: 2.573, per_step_time: 821ms, lr: 1.9340781e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:50:57,577 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.7% |                   | 9.74417 samples/s/p  0:18:17 }
2024-06-05 15:51:00,859 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2248/ 3581], loss: 2.482, per_step_time: 819ms, lr: 1.9286035e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:00,859 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.8% |                   | 9.76589 samples/s/p  0:18:11 }
2024-06-05 15:51:04,146 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2252/ 3581], loss: 2.433, per_step_time: 820ms, lr: 1.9231284e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:04,146 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   62.9% |                   | 9.75121 samples/s/p  0:18:10 }
2024-06-05 15:51:07,430 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2256/ 3581], loss: 2.756, per_step_time: 819ms, lr: 1.9176536e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:07,430 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.0% |                   | 9.76008 samples/s/p  0:18:06 }
2024-06-05 15:51:10,719 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2260/ 3581], loss: 2.630, per_step_time: 820ms, lr: 1.9121788e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:10,720 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.1% |                   | 9.74601 samples/s/p  0:18:04 }
2024-06-05 15:51:13,996 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2264/ 3581], loss: 2.499, per_step_time: 817ms, lr: 1.906704e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:13,997 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.2% |                   | 9.78024 samples/s/p  0:17:57 }
2024-06-05 15:51:17,278 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2268/ 3581], loss: 2.605, per_step_time: 819ms, lr: 1.9012288e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:17,278 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.3% |                   | 9.76712 samples/s/p  0:17:55 }
2024-06-05 15:51:20,559 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2272/ 3581], loss: 2.462, per_step_time: 819ms, lr: 1.8957542e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:20,559 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.4% |                   | 9.76795 samples/s/p  0:17:52 }
2024-06-05 15:51:23,835 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2276/ 3581], loss: 2.266, per_step_time: 817ms, lr: 1.8902792e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:23,836 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.6% |                   | 9.78482 samples/s/p  0:17:46 }
2024-06-05 15:51:27,115 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2280/ 3581], loss: 2.458, per_step_time: 818ms, lr: 1.8848046e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:27,115 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.7% |                   | 9.77176 samples/s/p  0:17:45 }
2024-06-05 15:51:30,404 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2284/ 3581], loss: 2.404, per_step_time: 820ms, lr: 1.8793295e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:30,405 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.8% |                   | 9.74423 samples/s/p  0:17:44 }
2024-06-05 15:51:33,681 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2288/ 3581], loss: 2.511, per_step_time: 818ms, lr: 1.8738549e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:33,682 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   63.9% |                   | 9.77945 samples/s/p  0:17:37 }
2024-06-05 15:51:36,973 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2292/ 3581], loss: 2.639, per_step_time: 821ms, lr: 1.8683797e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:36,973 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.0% |                  | 9.73835 samples/s/p  0:17:38 }
2024-06-05 15:51:40,250 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2296/ 3581], loss: 2.537, per_step_time: 818ms, lr: 1.8629049e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:40,251 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.1% |                  | 9.77870 samples/s/p  0:17:31 }
2024-06-05 15:51:43,531 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2300/ 3581], loss: 2.629, per_step_time: 818ms, lr: 1.85743e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:43,531 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.2% |                  | 9.76853 samples/s/p  0:17:29 }
2024-06-05 15:51:46,818 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2304/ 3581], loss: 2.696, per_step_time: 820ms, lr: 1.8519553e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:46,819 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.3% |                  | 9.74975 samples/s/p  0:17:27 }
2024-06-05 15:51:50,101 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2308/ 3581], loss: 2.638, per_step_time: 819ms, lr: 1.8464803e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:50,101 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.5% |                  | 9.76533 samples/s/p  0:17:22 }
2024-06-05 15:51:53,375 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2312/ 3581], loss: 2.825, per_step_time: 817ms, lr: 1.8410057e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:53,375 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.6% |                  | 9.78852 samples/s/p  0:17:17 }
2024-06-05 15:51:56,669 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2316/ 3581], loss: 2.548, per_step_time: 822ms, lr: 1.835531e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:56,669 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.7% |                  | 9.73027 samples/s/p  0:17:20 }
2024-06-05 15:51:59,948 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2320/ 3581], loss: 2.684, per_step_time: 818ms, lr: 1.830056e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:51:59,949 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.8% |                  | 9.77323 samples/s/p  0:17:12 }
2024-06-05 15:52:03,232 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2324/ 3581], loss: 2.481, per_step_time: 819ms, lr: 1.8245812e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:03,233 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   64.9% |                  | 9.76318 samples/s/p  0:17:09 }
2024-06-05 15:52:06,530 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2328/ 3581], loss: 2.526, per_step_time: 823ms, lr: 1.8191064e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:06,531 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.0% |                  | 9.71855 samples/s/p  0:17:11 }
2024-06-05 15:52:09,812 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2332/ 3581], loss: 2.503, per_step_time: 818ms, lr: 1.8136314e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:09,812 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.1% |                  | 9.76867 samples/s/p  0:17:02 }
2024-06-05 15:52:13,097 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2336/ 3581], loss: 2.452, per_step_time: 820ms, lr: 1.8081564e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:13,097 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.2% |                  | 9.75576 samples/s/p  0:17:00 }
2024-06-05 15:52:16,378 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2340/ 3581], loss: 2.344, per_step_time: 818ms, lr: 1.8026818e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:16,378 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.3% |                  | 9.76978 samples/s/p  0:16:56 }
2024-06-05 15:52:19,663 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2344/ 3581], loss: 2.715, per_step_time: 820ms, lr: 1.7972068e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:19,664 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.5% |                  | 9.75584 samples/s/p  0:16:54 }
2024-06-05 15:52:22,942 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2348/ 3581], loss: 2.434, per_step_time: 818ms, lr: 1.791732e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:22,942 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.6% |                  | 9.77610 samples/s/p  0:16:48 }
2024-06-05 15:52:26,226 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2352/ 3581], loss: 2.628, per_step_time: 819ms, lr: 1.7862569e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:26,226 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.7% |                  | 9.76051 samples/s/p  0:16:47 }
2024-06-05 15:52:29,515 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2356/ 3581], loss: 2.546, per_step_time: 820ms, lr: 1.780782e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:29,515 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.8% |                  | 9.74521 samples/s/p  0:16:45 }
2024-06-05 15:52:32,807 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2360/ 3581], loss: 2.556, per_step_time: 821ms, lr: 1.7753071e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:32,807 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   65.9% |                  | 9.73481 samples/s/p  0:16:43 }
2024-06-05 15:52:36,080 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2364/ 3581], loss: 2.754, per_step_time: 816ms, lr: 1.7698327e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:36,080 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.0% |                 | 9.79357 samples/s/p  0:16:34 }
2024-06-05 15:52:39,364 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2368/ 3581], loss: 2.665, per_step_time: 819ms, lr: 1.7643575e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:39,364 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.1% |                 | 9.75898 samples/s/p  0:16:34 }
2024-06-05 15:52:42,646 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2372/ 3581], loss: 2.577, per_step_time: 819ms, lr: 1.7588827e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:42,646 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.2% |                 | 9.76635 samples/s/p  0:16:30 }
2024-06-05 15:52:45,932 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2376/ 3581], loss: 2.572, per_step_time: 820ms, lr: 1.7534077e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:45,933 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.4% |                 | 9.75179 samples/s/p  0:16:28 }
2024-06-05 15:52:49,207 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2380/ 3581], loss: 2.622, per_step_time: 817ms, lr: 1.7479331e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:49,207 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.5% |                 | 9.78720 samples/s/p  0:16:21 }
2024-06-05 15:52:52,488 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2384/ 3581], loss: 2.582, per_step_time: 818ms, lr: 1.7424582e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:52,488 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.6% |                 | 9.77026 samples/s/p  0:16:20 }
2024-06-05 15:52:55,771 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2388/ 3581], loss: 2.395, per_step_time: 819ms, lr: 1.7369834e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:55,771 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.7% |                 | 9.76508 samples/s/p  0:16:17 }
2024-06-05 15:52:59,062 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2392/ 3581], loss: 2.539, per_step_time: 821ms, lr: 1.7315082e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:52:59,062 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.8% |                 | 9.73873 samples/s/p  0:16:16 }
2024-06-05 15:53:02,340 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2396/ 3581], loss: 2.583, per_step_time: 818ms, lr: 1.7260338e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:02,340 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   66.9% |                 | 9.77723 samples/s/p  0:16:09 }
2024-06-05 15:53:05,629 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2400/ 3581], loss: 2.461, per_step_time: 820ms, lr: 1.7205584e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:05,630 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.0% |                 | 9.74422 samples/s/p  0:16:09 }
2024-06-05 15:53:08,919 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2404/ 3581], loss: 2.427, per_step_time: 820ms, lr: 1.715084e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:08,919 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.1% |                 | 9.74434 samples/s/p  0:16:06 }
2024-06-05 15:53:12,212 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2408/ 3581], loss: 2.421, per_step_time: 822ms, lr: 1.709609e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:12,213 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.2% |                 | 9.73163 samples/s/p  0:16:04 }
2024-06-05 15:53:15,503 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2412/ 3581], loss: 2.481, per_step_time: 821ms, lr: 1.704134e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:15,504 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.4% |                 | 9.73938 samples/s/p  0:16:00 }
2024-06-05 15:53:18,786 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2416/ 3581], loss: 2.510, per_step_time: 819ms, lr: 1.6986593e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:18,786 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.5% |                 | 9.76411 samples/s/p  0:15:54 }
2024-06-05 15:53:22,064 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2420/ 3581], loss: 2.636, per_step_time: 818ms, lr: 1.6931845e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:22,065 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.6% |                 | 9.77539 samples/s/p  0:15:50 }
2024-06-05 15:53:25,347 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2424/ 3581], loss: 2.631, per_step_time: 819ms, lr: 1.6877095e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:25,347 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.7% |                 | 9.76487 samples/s/p  0:15:47 }
2024-06-05 15:53:28,622 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2428/ 3581], loss: 2.470, per_step_time: 817ms, lr: 1.6822349e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:28,622 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.8% |                 | 9.78473 samples/s/p  0:15:42 }
2024-06-05 15:53:31,906 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2432/ 3581], loss: 2.481, per_step_time: 819ms, lr: 1.6767597e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:31,906 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   67.9% |                 | 9.76037 samples/s/p  0:15:41 }
2024-06-05 15:53:35,189 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2436/ 3581], loss: 2.533, per_step_time: 819ms, lr: 1.671285e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:35,189 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.0% |                | 9.76343 samples/s/p  0:15:38 }
2024-06-05 15:53:38,478 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2440/ 3581], loss: 2.598, per_step_time: 820ms, lr: 1.66581e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:38,478 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.1% |                | 9.74574 samples/s/p  0:15:36 }
2024-06-05 15:53:41,758 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2444/ 3581], loss: 2.565, per_step_time: 818ms, lr: 1.6603353e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:41,759 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.2% |                | 9.77090 samples/s/p  0:15:30 }
2024-06-05 15:53:45,039 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2448/ 3581], loss: 2.505, per_step_time: 818ms, lr: 1.6548604e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:45,039 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.4% |                | 9.77132 samples/s/p  0:15:27 }
2024-06-05 15:53:48,321 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2452/ 3581], loss: 2.577, per_step_time: 819ms, lr: 1.6493856e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:48,321 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.5% |                | 9.76659 samples/s/p  0:15:24 }
2024-06-05 15:53:51,607 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2456/ 3581], loss: 2.586, per_step_time: 820ms, lr: 1.6439106e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:51,607 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.6% |                | 9.75509 samples/s/p  0:15:22 }
2024-06-05 15:53:54,902 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2460/ 3581], loss: 2.617, per_step_time: 822ms, lr: 1.638436e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:54,903 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.7% |                | 9.72991 samples/s/p  0:15:21 }
2024-06-05 15:53:58,191 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2464/ 3581], loss: 2.520, per_step_time: 820ms, lr: 1.6329608e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:53:58,192 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.8% |                | 9.74589 samples/s/p  0:15:16 }
2024-06-05 15:54:01,473 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2468/ 3581], loss: 2.397, per_step_time: 819ms, lr: 1.6274862e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:01,473 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   68.9% |                | 9.76732 samples/s/p  0:15:11 }
2024-06-05 15:54:04,752 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2472/ 3581], loss: 2.475, per_step_time: 818ms, lr: 1.622011e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:04,753 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.0% |                | 9.77320 samples/s/p  0:15:07 }
2024-06-05 15:54:08,042 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2476/ 3581], loss: 2.467, per_step_time: 821ms, lr: 1.6165364e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:08,042 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.1% |                | 9.74308 samples/s/p  0:15:07 }
2024-06-05 15:54:11,317 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2480/ 3581], loss: 2.502, per_step_time: 817ms, lr: 1.6110613e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:11,317 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.3% |                | 9.78637 samples/s/p  0:15:00 }
2024-06-05 15:54:14,604 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2484/ 3581], loss: 2.396, per_step_time: 820ms, lr: 1.6055867e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:14,604 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.4% |                | 9.75164 samples/s/p  0:14:59 }
2024-06-05 15:54:17,884 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2488/ 3581], loss: 2.408, per_step_time: 818ms, lr: 1.6001115e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:17,885 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.5% |                | 9.76915 samples/s/p  0:14:55 }
2024-06-05 15:54:21,174 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2492/ 3581], loss: 2.445, per_step_time: 821ms, lr: 1.5946369e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:21,175 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.6% |                | 9.74186 samples/s/p  0:14:54 }
2024-06-05 15:54:24,456 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2496/ 3581], loss: 2.567, per_step_time: 818ms, lr: 1.589162e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:24,456 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.7% |                | 9.76913 samples/s/p  0:14:48 }
2024-06-05 15:54:27,741 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2500/ 3581], loss: 2.603, per_step_time: 820ms, lr: 1.5836873e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:27,742 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.8% |                | 9.75607 samples/s/p  0:14:46 }
2024-06-05 15:54:31,023 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2504/ 3581], loss: 2.564, per_step_time: 819ms, lr: 1.578212e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:31,023 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   69.9% |                | 9.76751 samples/s/p  0:14:42 }
2024-06-05 15:54:34,301 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2508/ 3581], loss: 2.664, per_step_time: 818ms, lr: 1.5727377e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:34,301 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.0% |               | 9.77820 samples/s/p  0:14:37 }
2024-06-05 15:54:37,579 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2512/ 3581], loss: 2.553, per_step_time: 818ms, lr: 1.5672626e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:37,579 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.1% |               | 9.77817 samples/s/p  0:14:34 }
2024-06-05 15:54:40,866 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2516/ 3581], loss: 2.279, per_step_time: 820ms, lr: 1.5617878e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:40,866 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.3% |               | 9.75193 samples/s/p  0:14:33 }
2024-06-05 15:54:44,152 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2520/ 3581], loss: 2.362, per_step_time: 820ms, lr: 1.5563128e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:44,153 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.4% |               | 9.75245 samples/s/p  0:14:30 }
2024-06-05 15:54:47,440 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2524/ 3581], loss: 2.667, per_step_time: 820ms, lr: 1.550838e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:47,441 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.5% |               | 9.74736 samples/s/p  0:14:27 }
2024-06-05 15:54:50,725 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2528/ 3581], loss: 2.352, per_step_time: 819ms, lr: 1.5453626e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:50,725 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.6% |               | 9.75814 samples/s/p  0:14:23 }
2024-06-05 15:54:53,998 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2532/ 3581], loss: 2.619, per_step_time: 816ms, lr: 1.5398884e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:53,998 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.7% |               | 9.79234 samples/s/p  0:14:16 }
2024-06-05 15:54:57,271 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2536/ 3581], loss: 2.522, per_step_time: 816ms, lr: 1.5344132e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:54:57,271 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.8% |               | 9.79236 samples/s/p  0:14:13 }
2024-06-05 15:55:00,541 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2540/ 3581], loss: 2.502, per_step_time: 816ms, lr: 1.5289384e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:00,542 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   70.9% |               | 9.79979 samples/s/p  0:14:09 }
2024-06-05 15:55:03,816 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2544/ 3581], loss: 2.403, per_step_time: 817ms, lr: 1.52346365e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:03,816 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.0% |               | 9.78863 samples/s/p  0:14:07 }
2024-06-05 15:55:07,093 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2548/ 3581], loss: 2.431, per_step_time: 817ms, lr: 1.5179889e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:07,094 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.2% |               | 9.78104 samples/s/p  0:14:04 }
2024-06-05 15:55:10,367 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2552/ 3581], loss: 2.733, per_step_time: 817ms, lr: 1.5125139e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:10,367 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.3% |               | 9.79177 samples/s/p  0:14:00 }
2024-06-05 15:55:13,653 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2556/ 3581], loss: 2.270, per_step_time: 820ms, lr: 1.5070392e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:13,653 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.4% |               | 9.75408 samples/s/p  0:14:00 }
2024-06-05 15:55:16,937 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2560/ 3581], loss: 2.685, per_step_time: 819ms, lr: 1.5015642e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:16,937 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.5% |               | 9.76088 samples/s/p  0:13:56 }
2024-06-05 15:55:20,225 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2564/ 3581], loss: 2.624, per_step_time: 820ms, lr: 1.4960892e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:20,226 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.6% |               | 9.74717 samples/s/p  0:13:54 }
2024-06-05 15:55:23,508 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2568/ 3581], loss: 2.520, per_step_time: 819ms, lr: 1.4906148e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:23,509 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.7% |               | 9.76203 samples/s/p  0:13:50 }
2024-06-05 15:55:26,794 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2572/ 3581], loss: 2.673, per_step_time: 820ms, lr: 1.4851397e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:26,795 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.8% |               | 9.75353 samples/s/p  0:13:47 }
2024-06-05 15:55:30,085 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2576/ 3581], loss: 2.385, per_step_time: 821ms, lr: 1.479665e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:30,085 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   71.9% |               | 9.74100 samples/s/p  0:13:45 }
2024-06-05 15:55:33,365 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2580/ 3581], loss: 2.630, per_step_time: 818ms, lr: 1.47419005e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:33,366 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.0% |              | 9.77149 samples/s/p  0:13:39 }
2024-06-05 15:55:36,645 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2584/ 3581], loss: 2.545, per_step_time: 818ms, lr: 1.4687153e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:36,646 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.2% |              | 9.77181 samples/s/p  0:13:36 }
2024-06-05 15:55:39,942 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2588/ 3581], loss: 2.409, per_step_time: 822ms, lr: 1.4632402e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:39,942 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.3% |              | 9.72306 samples/s/p  0:13:37 }
2024-06-05 15:55:43,227 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2592/ 3581], loss: 2.431, per_step_time: 820ms, lr: 1.4577655e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:43,228 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.4% |              | 9.75384 samples/s/p  0:13:31 }
2024-06-05 15:55:46,519 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2596/ 3581], loss: 2.542, per_step_time: 821ms, lr: 1.4522905e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:46,519 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.5% |              | 9.73882 samples/s/p  0:13:29 }
2024-06-05 15:55:49,801 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2600/ 3581], loss: 2.604, per_step_time: 819ms, lr: 1.4468158e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:49,802 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.6% |              | 9.76397 samples/s/p  0:13:23 }
2024-06-05 15:55:53,076 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2604/ 3581], loss: 2.544, per_step_time: 817ms, lr: 1.4413408e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:53,076 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.7% |              | 9.78813 samples/s/p  0:13:18 }
2024-06-05 15:55:56,362 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2608/ 3581], loss: 2.608, per_step_time: 820ms, lr: 1.435866e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:56,362 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.8% |              | 9.75340 samples/s/p  0:13:18 }
2024-06-05 15:55:59,645 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2612/ 3581], loss: 2.636, per_step_time: 819ms, lr: 1.43039115e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:55:59,645 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   72.9% |              | 9.76327 samples/s/p  0:13:13 }
2024-06-05 15:56:02,924 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2616/ 3581], loss: 2.459, per_step_time: 818ms, lr: 1.4249162e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:02,925 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.1% |              | 9.77187 samples/s/p  0:13:10 }
2024-06-05 15:56:06,205 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2620/ 3581], loss: 2.564, per_step_time: 818ms, lr: 1.4194414e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:06,205 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.2% |              | 9.77124 samples/s/p  0:13:06 }
2024-06-05 15:56:09,489 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2624/ 3581], loss: 2.505, per_step_time: 819ms, lr: 1.4139667e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:09,489 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.3% |              | 9.75940 samples/s/p  0:13:04 }
2024-06-05 15:56:12,768 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2628/ 3581], loss: 2.461, per_step_time: 818ms, lr: 1.4084917e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:12,769 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.4% |              | 9.77491 samples/s/p  0:12:59 }
2024-06-05 15:56:16,042 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2632/ 3581], loss: 2.487, per_step_time: 817ms, lr: 1.403017e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:16,042 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.5% |              | 9.79130 samples/s/p  0:12:55 }
2024-06-05 15:56:19,324 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2636/ 3581], loss: 2.575, per_step_time: 819ms, lr: 1.3975418e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:19,324 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.6% |              | 9.76588 samples/s/p  0:12:54 }
2024-06-05 15:56:22,601 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2640/ 3581], loss: 2.568, per_step_time: 817ms, lr: 1.3920672e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:22,601 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.7% |              | 9.78027 samples/s/p  0:12:49 }
2024-06-05 15:56:25,885 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2644/ 3581], loss: 2.488, per_step_time: 819ms, lr: 1.38659225e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:25,885 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.8% |              | 9.76136 samples/s/p  0:12:47 }
2024-06-05 15:56:29,160 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2648/ 3581], loss: 2.528, per_step_time: 817ms, lr: 1.3811175e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:29,160 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   73.9% |              | 9.78739 samples/s/p  0:12:42 }
2024-06-05 15:56:32,446 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2652/ 3581], loss: 2.758, per_step_time: 820ms, lr: 1.3756424e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:32,447 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.1% |             | 9.75110 samples/s/p  0:12:42 }
2024-06-05 15:56:35,729 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2656/ 3581], loss: 2.609, per_step_time: 819ms, lr: 1.3701677e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:35,729 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.2% |             | 9.76378 samples/s/p  0:12:37 }
2024-06-05 15:56:39,007 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2660/ 3581], loss: 2.561, per_step_time: 818ms, lr: 1.3646927e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:39,007 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.3% |             | 9.77789 samples/s/p  0:12:33 }
2024-06-05 15:56:42,301 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2664/ 3581], loss: 2.466, per_step_time: 822ms, lr: 1.359218e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:42,301 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.4% |             | 9.73110 samples/s/p  0:12:33 }
2024-06-05 15:56:45,585 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2668/ 3581], loss: 2.517, per_step_time: 819ms, lr: 1.353743e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:45,586 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.5% |             | 9.75792 samples/s/p  0:12:28 }
2024-06-05 15:56:48,860 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2672/ 3581], loss: 2.393, per_step_time: 817ms, lr: 1.3482683e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:48,861 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.6% |             | 9.78565 samples/s/p  0:12:23 }
2024-06-05 15:56:52,141 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2676/ 3581], loss: 2.433, per_step_time: 818ms, lr: 1.34279335e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:52,142 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.7% |             | 9.76964 samples/s/p  0:12:21 }
2024-06-05 15:56:55,427 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2680/ 3581], loss: 2.297, per_step_time: 820ms, lr: 1.3373186e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:55,427 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   74.8% |             | 9.75456 samples/s/p  0:12:18 }
2024-06-05 15:56:58,715 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2684/ 3581], loss: 2.470, per_step_time: 820ms, lr: 1.3318436e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:56:58,715 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.0% |             | 9.74819 samples/s/p  0:12:16 }
2024-06-05 15:57:01,997 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2688/ 3581], loss: 2.457, per_step_time: 819ms, lr: 1.3263689e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:01,997 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.1% |             | 9.76598 samples/s/p  0:12:11 }
2024-06-05 15:57:05,279 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2692/ 3581], loss: 2.505, per_step_time: 819ms, lr: 1.320894e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:05,279 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.2% |             | 9.76491 samples/s/p  0:12:08 }
2024-06-05 15:57:08,559 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2696/ 3581], loss: 2.158, per_step_time: 818ms, lr: 1.3154192e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:08,559 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.3% |             | 9.77228 samples/s/p  0:12:04 }
2024-06-05 15:57:11,828 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2700/ 3581], loss: 2.505, per_step_time: 816ms, lr: 1.309944e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:11,829 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.4% |             | 9.80317 samples/s/p  0:11:58 }
2024-06-05 15:57:15,109 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2704/ 3581], loss: 2.624, per_step_time: 818ms, lr: 1.3044695e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:15,110 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.5% |             | 9.76987 samples/s/p  0:11:58 }
2024-06-05 15:57:18,387 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2708/ 3581], loss: 2.696, per_step_time: 818ms, lr: 1.2989945e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:18,388 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.6% |             | 9.77856 samples/s/p  0:11:54 }
2024-06-05 15:57:21,669 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2712/ 3581], loss: 2.487, per_step_time: 819ms, lr: 1.2935198e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:21,670 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.7% |             | 9.76526 samples/s/p  0:11:51 }
2024-06-05 15:57:24,952 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2716/ 3581], loss: 2.564, per_step_time: 819ms, lr: 1.2880447e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:24,952 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   75.8% |             | 9.76365 samples/s/p  0:11:48 }
2024-06-05 15:57:28,233 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2720/ 3581], loss: 2.510, per_step_time: 818ms, lr: 1.2825699e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:28,233 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.0% |             | 9.76866 samples/s/p  0:11:45 }
2024-06-05 15:57:31,508 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2724/ 3581], loss: 2.448, per_step_time: 817ms, lr: 1.2770949e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:31,509 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.1% |            | 9.78676 samples/s/p  0:11:40 }
2024-06-05 15:57:34,785 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2728/ 3581], loss: 2.541, per_step_time: 817ms, lr: 1.2716204e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:34,785 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.2% |            | 9.78128 samples/s/p  0:11:37 }
2024-06-05 15:57:38,065 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2732/ 3581], loss: 2.479, per_step_time: 818ms, lr: 1.2661452e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:38,066 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.3% |            | 9.77230 samples/s/p  0:11:35 }
2024-06-05 15:57:41,340 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2736/ 3581], loss: 2.222, per_step_time: 817ms, lr: 1.2606705e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:41,340 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.4% |            | 9.78801 samples/s/p  0:11:30 }
2024-06-05 15:57:44,626 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2740/ 3581], loss: 2.580, per_step_time: 820ms, lr: 1.25519555e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:44,627 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.5% |            | 9.75189 samples/s/p  0:11:29 }
2024-06-05 15:57:47,913 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2744/ 3581], loss: 2.621, per_step_time: 820ms, lr: 1.24972075e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:47,913 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.6% |            | 9.75175 samples/s/p  0:11:26 }
2024-06-05 15:57:51,197 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2748/ 3581], loss: 2.591, per_step_time: 819ms, lr: 1.2442458e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:51,198 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.7% |            | 9.75851 samples/s/p  0:11:22 }
2024-06-05 15:57:54,477 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2752/ 3581], loss: 2.429, per_step_time: 818ms, lr: 1.2387711e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:54,477 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   76.9% |            | 9.77242 samples/s/p  0:11:18 }
2024-06-05 15:57:57,758 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2756/ 3581], loss: 2.499, per_step_time: 818ms, lr: 1.2332961e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:57:57,759 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.0% |            | 9.76820 samples/s/p  0:11:15 }
2024-06-05 15:58:01,041 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2760/ 3581], loss: 2.606, per_step_time: 819ms, lr: 1.2278214e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:01,042 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.1% |            | 9.76235 samples/s/p  0:11:12 }
2024-06-05 15:58:04,325 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2764/ 3581], loss: 2.548, per_step_time: 819ms, lr: 1.2223463e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:04,326 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.2% |            | 9.75939 samples/s/p  0:11:09 }
2024-06-05 15:58:07,606 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2768/ 3581], loss: 2.656, per_step_time: 818ms, lr: 1.2168715e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:07,606 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.3% |            | 9.77003 samples/s/p  0:11:05 }
2024-06-05 15:58:10,892 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2772/ 3581], loss: 2.535, per_step_time: 820ms, lr: 1.21139665e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:10,892 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.4% |            | 9.75453 samples/s/p  0:11:03 }
2024-06-05 15:58:14,173 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2776/ 3581], loss: 2.440, per_step_time: 819ms, lr: 1.20592185e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:14,173 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.5% |            | 9.76767 samples/s/p  0:10:59 }
2024-06-05 15:58:17,456 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2780/ 3581], loss: 2.380, per_step_time: 819ms, lr: 1.2004468e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:17,456 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.6% |            | 9.76434 samples/s/p  0:10:56 }
2024-06-05 15:58:20,743 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2784/ 3581], loss: 2.559, per_step_time: 820ms, lr: 1.1949722e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:20,744 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.7% |            | 9.74837 samples/s/p  0:10:54 }
2024-06-05 15:58:24,023 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2788/ 3581], loss: 2.309, per_step_time: 818ms, lr: 1.1894971e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:24,023 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   77.9% |            | 9.77345 samples/s/p  0:10:49 }
2024-06-05 15:58:27,305 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2792/ 3581], loss: 2.569, per_step_time: 819ms, lr: 1.1840225e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:27,305 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.0% |            | 9.76708 samples/s/p  0:10:46 }
2024-06-05 15:58:30,583 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2796/ 3581], loss: 2.445, per_step_time: 818ms, lr: 1.1785474e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:30,583 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.1% |           | 9.77627 samples/s/p  0:10:42 }
2024-06-05 15:58:33,865 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2800/ 3581], loss: 2.603, per_step_time: 819ms, lr: 1.1730727e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:33,865 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.2% |           | 9.76709 samples/s/p  0:10:39 }
2024-06-05 15:58:37,150 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2804/ 3581], loss: 2.528, per_step_time: 819ms, lr: 1.16759775e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:37,150 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.3% |           | 9.75632 samples/s/p  0:10:37 }
2024-06-05 15:58:40,428 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2808/ 3581], loss: 2.387, per_step_time: 818ms, lr: 1.16212295e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:40,429 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.4% |           | 9.77722 samples/s/p  0:10:32 }
2024-06-05 15:58:43,703 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2812/ 3581], loss: 2.450, per_step_time: 817ms, lr: 1.1566479e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:43,703 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.5% |           | 9.78695 samples/s/p  0:10:28 }
2024-06-05 15:58:46,986 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2816/ 3581], loss: 2.505, per_step_time: 819ms, lr: 1.1511733e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:46,986 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.6% |           | 9.76472 samples/s/p  0:10:26 }
2024-06-05 15:58:50,258 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2820/ 3581], loss: 2.207, per_step_time: 816ms, lr: 1.1456986e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:50,258 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.7% |           | 9.79654 samples/s/p  0:10:21 }
2024-06-05 15:58:53,540 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2824/ 3581], loss: 2.598, per_step_time: 819ms, lr: 1.1402236e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:53,541 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   78.9% |           | 9.76398 samples/s/p  0:10:20 }
2024-06-05 15:58:56,821 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2828/ 3581], loss: 2.319, per_step_time: 819ms, lr: 1.1347489e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:58:56,822 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.0% |           | 9.76759 samples/s/p  0:10:16 }
2024-06-05 15:59:00,108 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2832/ 3581], loss: 2.493, per_step_time: 820ms, lr: 1.1292738e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:00,108 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.1% |           | 9.75287 samples/s/p  0:10:14 }
2024-06-05 15:59:03,400 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2836/ 3581], loss: 2.530, per_step_time: 821ms, lr: 1.123799e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:03,400 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.2% |           | 9.73667 samples/s/p  0:10:12 }
2024-06-05 15:59:06,688 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2840/ 3581], loss: 2.435, per_step_time: 820ms, lr: 1.118324e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:06,688 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.3% |           | 9.74772 samples/s/p  0:10:08 }
2024-06-05 15:59:09,987 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2844/ 3581], loss: 2.514, per_step_time: 823ms, lr: 1.11284935e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:09,987 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.4% |           | 9.71500 samples/s/p  0:10:06 }
2024-06-05 15:59:13,261 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2848/ 3581], loss: 2.508, per_step_time: 817ms, lr: 1.1073743e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:13,261 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.5% |           | 9.78878 samples/s/p  0:09:59 }
2024-06-05 15:59:16,533 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2852/ 3581], loss: 2.442, per_step_time: 816ms, lr: 1.1018996e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:16,533 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.6% |           | 9.79656 samples/s/p  0:09:55 }
2024-06-05 15:59:19,813 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2856/ 3581], loss: 2.101, per_step_time: 818ms, lr: 1.0964247e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:19,814 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.8% |           | 9.76925 samples/s/p  0:09:53 }
2024-06-05 15:59:23,100 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2860/ 3581], loss: 2.331, per_step_time: 820ms, lr: 1.09095e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:23,101 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   79.9% |           | 9.75020 samples/s/p  0:09:51 }
2024-06-05 15:59:26,380 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2864/ 3581], loss: 2.633, per_step_time: 818ms, lr: 1.0854749e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:26,380 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.0% |           | 9.77267 samples/s/p  0:09:46 }
2024-06-05 15:59:29,662 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2868/ 3581], loss: 2.417, per_step_time: 819ms, lr: 1.0800002e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:29,663 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.1% |          | 9.76522 samples/s/p  0:09:44 }
2024-06-05 15:59:32,941 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2872/ 3581], loss: 2.517, per_step_time: 818ms, lr: 1.0745252e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:32,941 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.2% |          | 9.77631 samples/s/p  0:09:40 }
2024-06-05 15:59:36,219 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2876/ 3581], loss: 2.712, per_step_time: 818ms, lr: 1.06905045e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:36,220 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.3% |          | 9.77535 samples/s/p  0:09:36 }
2024-06-05 15:59:39,510 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2880/ 3581], loss: 2.421, per_step_time: 821ms, lr: 1.0635754e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:39,511 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.4% |          | 9.73880 samples/s/p  0:09:35 }
2024-06-05 15:59:42,792 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2884/ 3581], loss: 2.597, per_step_time: 819ms, lr: 1.0581008e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:42,792 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.5% |          | 9.76792 samples/s/p  0:09:30 }
2024-06-05 15:59:46,067 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2888/ 3581], loss: 2.683, per_step_time: 817ms, lr: 1.0526257e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:46,067 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.6% |          | 9.78782 samples/s/p  0:09:26 }
2024-06-05 15:59:49,349 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2892/ 3581], loss: 2.480, per_step_time: 819ms, lr: 1.0471511e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:49,349 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.8% |          | 9.76459 samples/s/p  0:09:24 }
2024-06-05 15:59:52,630 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2896/ 3581], loss: 2.295, per_step_time: 818ms, lr: 1.041676e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:52,630 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   80.9% |          | 9.76875 samples/s/p  0:09:20 }
2024-06-05 15:59:55,910 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2900/ 3581], loss: 2.617, per_step_time: 818ms, lr: 1.0362013e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:55,911 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.0% |          | 9.77232 samples/s/p  0:09:17 }
2024-06-05 15:59:59,192 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2904/ 3581], loss: 2.580, per_step_time: 819ms, lr: 1.0307264e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 15:59:59,193 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.1% |          | 9.76567 samples/s/p  0:09:14 }
2024-06-05 16:00:02,472 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2908/ 3581], loss: 2.481, per_step_time: 818ms, lr: 1.0252515e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:02,472 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.2% |          | 9.77376 samples/s/p  0:09:10 }
2024-06-05 16:00:05,749 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2912/ 3581], loss: 2.437, per_step_time: 817ms, lr: 1.0197765e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:05,750 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.3% |          | 9.78078 samples/s/p  0:09:07 }
2024-06-05 16:00:09,034 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2916/ 3581], loss: 2.558, per_step_time: 819ms, lr: 1.0143019e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:09,034 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.4% |          | 9.75729 samples/s/p  0:09:05 }
2024-06-05 16:00:12,315 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2920/ 3581], loss: 2.556, per_step_time: 818ms, lr: 1.0088268e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:12,315 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.5% |          | 9.77076 samples/s/p  0:09:01 }
2024-06-05 16:00:15,600 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2924/ 3581], loss: 2.373, per_step_time: 820ms, lr: 1.0033522e-05, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:15,601 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.7% |          | 9.75443 samples/s/p  0:08:58 }
2024-06-05 16:00:18,884 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2928/ 3581], loss: 2.549, per_step_time: 819ms, lr: 9.978771e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:18,885 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.8% |          | 9.75911 samples/s/p  0:08:55 }
2024-06-05 16:00:22,169 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2932/ 3581], loss: 2.541, per_step_time: 819ms, lr: 9.924024e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:22,170 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   81.9% |          | 9.75689 samples/s/p  0:08:52 }
2024-06-05 16:00:25,451 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2936/ 3581], loss: 2.516, per_step_time: 819ms, lr: 9.869274e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:25,451 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.0% |          | 9.76732 samples/s/p  0:08:48 }
2024-06-05 16:00:28,733 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2940/ 3581], loss: 2.501, per_step_time: 819ms, lr: 9.814527e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:28,733 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.1% |         | 9.76579 samples/s/p  0:08:45 }
2024-06-05 16:00:32,018 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2944/ 3581], loss: 2.411, per_step_time: 820ms, lr: 9.759777e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:32,018 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.2% |         | 9.75595 samples/s/p  0:08:42 }
2024-06-05 16:00:35,298 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2948/ 3581], loss: 2.609, per_step_time: 818ms, lr: 9.705029e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:35,298 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.3% |         | 9.77129 samples/s/p  0:08:38 }
2024-06-05 16:00:38,581 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2952/ 3581], loss: 2.667, per_step_time: 819ms, lr: 9.650279e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:38,582 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.4% |         | 9.76156 samples/s/p  0:08:35 }
2024-06-05 16:00:41,863 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2956/ 3581], loss: 2.620, per_step_time: 819ms, lr: 9.595533e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:41,863 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.5% |         | 9.76773 samples/s/p  0:08:31 }
2024-06-05 16:00:45,145 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2960/ 3581], loss: 2.365, per_step_time: 819ms, lr: 9.540782e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:45,145 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.7% |         | 9.76539 samples/s/p  0:08:28 }
2024-06-05 16:00:48,426 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2964/ 3581], loss: 2.406, per_step_time: 819ms, lr: 9.486034e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:48,427 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.8% |         | 9.76751 samples/s/p  0:08:25 }
2024-06-05 16:00:51,712 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2968/ 3581], loss: 2.528, per_step_time: 820ms, lr: 9.4312845e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:51,713 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   82.9% |         | 9.75346 samples/s/p  0:08:22 }
2024-06-05 16:00:54,988 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2972/ 3581], loss: 2.667, per_step_time: 817ms, lr: 9.376538e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:54,989 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.0% |         | 9.78226 samples/s/p  0:08:18 }
2024-06-05 16:00:58,268 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2976/ 3581], loss: 2.554, per_step_time: 818ms, lr: 9.321788e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:00:58,269 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.1% |         | 9.77218 samples/s/p  0:08:15 }
2024-06-05 16:01:01,553 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2980/ 3581], loss: 2.307, per_step_time: 819ms, lr: 9.26704e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:01:01,554 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.2% |         | 9.75768 samples/s/p  0:08:12 }
2024-06-05 16:01:04,831 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2984/ 3581], loss: 2.444, per_step_time: 818ms, lr: 9.212291e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:01:04,831 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.3% |         | 9.77902 samples/s/p  0:08:08 }
2024-06-05 16:01:08,103 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2988/ 3581], loss: 2.600, per_step_time: 816ms, lr: 9.157543e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:01:08,104 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.4% |         | 9.79584 samples/s/p  0:08:04 }
2024-06-05 16:01:11,391 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2992/ 3581], loss: 2.660, per_step_time: 820ms, lr: 9.102793e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:01:11,391 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.6% |         | 9.74898 samples/s/p  0:08:03 }
2024-06-05 16:01:14,669 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 2996/ 3581], loss: 2.380, per_step_time: 818ms, lr: 9.048046e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:01:14,669 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.7% |         | 9.77795 samples/s/p  0:07:58 }
2024-06-05 16:01:17,949 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3000/ 3581], loss: 2.394, per_step_time: 818ms, lr: 8.993296e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:01:17,950 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.8% |         | 9.77039 samples/s/p  0:07:55 }
2024-06-05 16:01:17,950 - mindformers[mindformers/core/callback/callback.py:561] - INFO - ......Saving ckpt......
2024-06-05 16:02:38,765 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3004/ 3581], loss: 2.459, per_step_time: 823ms, lr: 8.938549e-06, overflow cond: False, loss_scale: 131072.0
2024-06-05 16:02:38,765 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   83.9% |         | 9.71658 samples/s/p  0:07:55 }
2024-06-05 16:02:42,037 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3008/ 3581], loss: 2.416, per_step_time: 816ms, lr: 8.883799e-06, overflow cond: False, loss_scale: 131072.0
2024-06-05 16:02:42,037 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.0% |         | 9.79534 samples/s/p  0:07:47 }
2024-06-05 16:02:45,322 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3012/ 3581], loss: 2.409, per_step_time: 819ms, lr: 8.829052e-06, overflow cond: False, loss_scale: 131072.0
2024-06-05 16:02:45,323 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.1% |        | 9.75639 samples/s/p  0:07:46 }
2024-06-05 16:02:48,593 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3016/ 3581], loss: 2.364, per_step_time: 816ms, lr: 8.774302e-06, overflow cond: False, loss_scale: 131072.0
2024-06-05 16:02:48,594 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.2% |        | 9.79830 samples/s/p  0:07:41 }
2024-06-05 16:02:51,876 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3020/ 3581], loss: 2.439, per_step_time: 819ms, lr: 8.719554e-06, overflow cond: False, loss_scale: 131072.0
2024-06-05 16:02:51,876 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.3% |        | 9.76580 samples/s/p  0:07:39 }
2024-06-05 16:02:55,053 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3024/ 3581], loss: 2.415, per_step_time: 792ms, lr: 8.678493e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:02:55,053 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.4% |        | 10.08990 samples/s/p  0:07:21 }
2024-06-05 16:02:58,340 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3028/ 3581], loss: 2.535, per_step_time: 820ms, lr: 8.623743e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:02:58,340 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.6% |        | 9.75155 samples/s/p  0:07:33 }
2024-06-05 16:03:01,629 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3032/ 3581], loss: 2.621, per_step_time: 820ms, lr: 8.568996e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:01,629 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.7% |        | 9.74712 samples/s/p  0:07:30 }
2024-06-05 16:03:04,910 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3036/ 3581], loss: 2.534, per_step_time: 817ms, lr: 8.5142465e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:04,911 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.8% |        | 9.78496 samples/s/p  0:07:25 }
2024-06-05 16:03:08,186 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3040/ 3581], loss: 2.339, per_step_time: 817ms, lr: 8.4594985e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:08,187 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   84.9% |        | 9.78432 samples/s/p  0:07:22 }
2024-06-05 16:03:11,469 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3044/ 3581], loss: 2.385, per_step_time: 819ms, lr: 8.404749e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:11,470 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.0% |        | 9.76568 samples/s/p  0:07:19 }
2024-06-05 16:03:14,747 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3048/ 3581], loss: 2.287, per_step_time: 817ms, lr: 8.350002e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:14,747 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.1% |        | 9.78213 samples/s/p  0:07:15 }
2024-06-05 16:03:18,032 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3052/ 3581], loss: 2.606, per_step_time: 819ms, lr: 8.295252e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:18,032 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.2% |        | 9.76108 samples/s/p  0:07:13 }
2024-06-05 16:03:21,313 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3056/ 3581], loss: 2.514, per_step_time: 818ms, lr: 8.240504e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:21,314 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.3% |        | 9.76806 samples/s/p  0:07:09 }
2024-06-05 16:03:24,598 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3060/ 3581], loss: 2.383, per_step_time: 819ms, lr: 8.185753e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:24,599 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.5% |        | 9.75769 samples/s/p  0:07:07 }
2024-06-05 16:03:27,892 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3064/ 3581], loss: 2.477, per_step_time: 822ms, lr: 8.131007e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:27,892 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.6% |        | 9.73145 samples/s/p  0:07:05 }
2024-06-05 16:03:31,175 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3068/ 3581], loss: 2.602, per_step_time: 819ms, lr: 8.0762575e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:31,175 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.7% |        | 9.76493 samples/s/p  0:07:00 }
2024-06-05 16:03:34,463 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3072/ 3581], loss: 2.533, per_step_time: 820ms, lr: 8.0215095e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:34,463 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.8% |        | 9.74752 samples/s/p  0:06:57 }
2024-06-05 16:03:37,750 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3076/ 3581], loss: 2.408, per_step_time: 820ms, lr: 7.96676e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:37,750 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   85.9% |        | 9.75124 samples/s/p  0:06:54 }
2024-06-05 16:03:41,031 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3080/ 3581], loss: 2.493, per_step_time: 818ms, lr: 7.912013e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:41,031 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.0% |       | 9.76906 samples/s/p  0:06:50 }
2024-06-05 16:03:44,306 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3084/ 3581], loss: 2.435, per_step_time: 817ms, lr: 7.857263e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:44,307 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.1% |       | 9.78570 samples/s/p  0:06:46 }
2024-06-05 16:03:47,592 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3088/ 3581], loss: 2.436, per_step_time: 820ms, lr: 7.802514e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:47,593 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.2% |       | 9.75365 samples/s/p  0:06:44 }
2024-06-05 16:03:50,875 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3092/ 3581], loss: 2.567, per_step_time: 819ms, lr: 7.747765e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:50,876 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.3% |       | 9.76285 samples/s/p  0:06:40 }
2024-06-05 16:03:54,151 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3096/ 3581], loss: 2.176, per_step_time: 817ms, lr: 7.693018e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:54,151 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.5% |       | 9.78441 samples/s/p  0:06:36 }
2024-06-05 16:03:57,436 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3100/ 3581], loss: 2.511, per_step_time: 819ms, lr: 7.638268e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:03:57,436 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.6% |       | 9.75705 samples/s/p  0:06:34 }
2024-06-05 16:04:00,721 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3104/ 3581], loss: 2.384, per_step_time: 819ms, lr: 7.5835205e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:00,721 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.7% |       | 9.75803 samples/s/p  0:06:31 }
2024-06-05 16:04:04,006 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3108/ 3581], loss: 2.495, per_step_time: 820ms, lr: 7.5287703e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:04,008 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.8% |       | 9.75435 samples/s/p  0:06:27 }
2024-06-05 16:04:07,297 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3112/ 3581], loss: 2.439, per_step_time: 820ms, lr: 7.474023e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:07,297 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   86.9% |       | 9.74490 samples/s/p  0:06:25 }
2024-06-05 16:04:10,583 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3116/ 3581], loss: 2.465, per_step_time: 820ms, lr: 7.419273e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:10,584 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.0% |       | 9.75558 samples/s/p  0:06:21 }
2024-06-05 16:04:13,866 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3120/ 3581], loss: 2.479, per_step_time: 819ms, lr: 7.364526e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:13,866 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.1% |       | 9.76561 samples/s/p  0:06:17 }
2024-06-05 16:04:17,144 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3124/ 3581], loss: 2.486, per_step_time: 818ms, lr: 7.3097763e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:17,145 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.2% |       | 9.77680 samples/s/p  0:06:13 }
2024-06-05 16:04:20,433 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3128/ 3581], loss: 2.713, per_step_time: 820ms, lr: 7.255029e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:20,434 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.3% |       | 9.74524 samples/s/p  0:06:11 }
2024-06-05 16:04:23,721 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3132/ 3581], loss: 2.505, per_step_time: 820ms, lr: 7.200279e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:23,721 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.5% |       | 9.75070 samples/s/p  0:06:08 }
2024-06-05 16:04:26,998 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3136/ 3581], loss: 2.150, per_step_time: 817ms, lr: 7.1455306e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:26,998 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.6% |       | 9.78039 samples/s/p  0:06:03 }
2024-06-05 16:04:30,277 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3140/ 3581], loss: 2.521, per_step_time: 818ms, lr: 7.0907813e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:30,278 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.7% |       | 9.77371 samples/s/p  0:06:00 }
2024-06-05 16:04:33,555 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3144/ 3581], loss: 2.455, per_step_time: 818ms, lr: 7.036034e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:33,555 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.8% |       | 9.77916 samples/s/p  0:05:57 }
2024-06-05 16:04:36,834 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3148/ 3581], loss: 2.447, per_step_time: 818ms, lr: 6.981287e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:36,835 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   87.9% |       | 9.77463 samples/s/p  0:05:54 }
2024-06-05 16:04:40,117 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3152/ 3581], loss: 2.377, per_step_time: 819ms, lr: 6.9265366e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:40,117 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.0% |      | 9.76390 samples/s/p  0:05:51 }
2024-06-05 16:04:43,396 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3156/ 3581], loss: 2.419, per_step_time: 818ms, lr: 6.8717895e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:43,397 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.1% |      | 9.77351 samples/s/p  0:05:47 }
2024-06-05 16:04:46,684 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3160/ 3581], loss: 2.552, per_step_time: 819ms, lr: 6.8170402e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:46,684 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.2% |      | 9.76342 samples/s/p  0:05:44 }
2024-06-05 16:04:49,971 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3164/ 3581], loss: 2.424, per_step_time: 820ms, lr: 6.7622927e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:49,972 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.4% |      | 9.75106 samples/s/p  0:05:42 }
2024-06-05 16:04:53,261 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3168/ 3581], loss: 2.196, per_step_time: 820ms, lr: 6.707543e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:53,262 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.5% |      | 9.74493 samples/s/p  0:05:39 }
2024-06-05 16:04:56,542 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3172/ 3581], loss: 2.558, per_step_time: 818ms, lr: 6.6527946e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:56,542 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.6% |      | 9.77564 samples/s/p  0:05:34 }
2024-06-05 16:04:59,815 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3176/ 3581], loss: 2.363, per_step_time: 817ms, lr: 6.598045e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:04:59,816 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.7% |      | 9.79152 samples/s/p  0:05:30 }
2024-06-05 16:05:03,105 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3180/ 3581], loss: 2.468, per_step_time: 821ms, lr: 6.5432987e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:03,106 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.8% |      | 9.74326 samples/s/p  0:05:29 }
2024-06-05 16:05:06,394 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3184/ 3581], loss: 2.358, per_step_time: 820ms, lr: 6.488548e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:06,395 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   88.9% |      | 9.74583 samples/s/p  0:05:25 }
2024-06-05 16:05:09,671 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3188/ 3581], loss: 2.455, per_step_time: 817ms, lr: 6.433801e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:09,671 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.0% |      | 9.78147 samples/s/p  0:05:21 }
2024-06-05 16:05:12,956 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3192/ 3581], loss: 2.561, per_step_time: 819ms, lr: 6.379051e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:12,956 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.1% |      | 9.75692 samples/s/p  0:05:18 }
2024-06-05 16:05:16,241 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3196/ 3581], loss: 2.407, per_step_time: 819ms, lr: 6.3243037e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:16,241 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.2% |      | 9.75761 samples/s/p  0:05:15 }
2024-06-05 16:05:19,527 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3200/ 3581], loss: 2.231, per_step_time: 820ms, lr: 6.269553e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:19,527 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.4% |      | 9.75234 samples/s/p  0:05:12 }
2024-06-05 16:05:22,816 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3204/ 3581], loss: 2.578, per_step_time: 820ms, lr: 6.214806e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:22,816 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.5% |      | 9.75292 samples/s/p  0:05:09 }
2024-06-05 16:05:26,078 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3208/ 3581], loss: 2.499, per_step_time: 814ms, lr: 6.1600563e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:26,078 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.6% |      | 9.82576 samples/s/p  0:05:03 }
2024-06-05 16:05:29,359 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3212/ 3581], loss: 2.430, per_step_time: 818ms, lr: 6.1053092e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:29,359 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.7% |      | 9.76818 samples/s/p  0:05:02 }
2024-06-05 16:05:32,636 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3216/ 3581], loss: 2.682, per_step_time: 817ms, lr: 6.0505595e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:32,636 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.8% |      | 9.78029 samples/s/p  0:04:58 }
2024-06-05 16:05:35,913 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3220/ 3581], loss: 2.593, per_step_time: 818ms, lr: 5.9958115e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:35,914 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   89.9% |      | 9.77972 samples/s/p  0:04:55 }
2024-06-05 16:05:39,200 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3224/ 3581], loss: 2.469, per_step_time: 820ms, lr: 5.9410613e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:39,200 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.0% |     | 9.75222 samples/s/p  0:04:52 }
2024-06-05 16:05:42,494 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3228/ 3581], loss: 2.368, per_step_time: 822ms, lr: 5.886315e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:42,495 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.1% |     | 9.72913 samples/s/p  0:04:50 }
2024-06-05 16:05:45,774 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3232/ 3581], loss: 2.574, per_step_time: 818ms, lr: 5.8315645e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:45,774 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.3% |     | 9.77437 samples/s/p  0:04:45 }
2024-06-05 16:05:49,060 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3236/ 3581], loss: 2.298, per_step_time: 820ms, lr: 5.776818e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:49,061 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.4% |     | 9.75333 samples/s/p  0:04:42 }
2024-06-05 16:05:52,353 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3240/ 3581], loss: 2.444, per_step_time: 821ms, lr: 5.722067e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:52,353 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.5% |     | 9.73404 samples/s/p  0:04:40 }
2024-06-05 16:05:55,648 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3244/ 3581], loss: 2.515, per_step_time: 822ms, lr: 5.6673202e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:55,648 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.6% |     | 9.72875 samples/s/p  0:04:37 }
2024-06-05 16:05:58,921 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3248/ 3581], loss: 2.569, per_step_time: 817ms, lr: 5.6125705e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:05:58,922 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.7% |     | 9.79136 samples/s/p  0:04:32 }
2024-06-05 16:06:02,223 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3252/ 3581], loss: 2.290, per_step_time: 824ms, lr: 5.557822e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:02,224 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.8% |     | 9.70629 samples/s/p  0:04:31 }
2024-06-05 16:06:05,507 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3256/ 3581], loss: 2.438, per_step_time: 819ms, lr: 5.503073e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:05,508 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   90.9% |     | 9.75966 samples/s/p  0:04:26 }
2024-06-05 16:06:08,780 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3260/ 3581], loss: 2.457, per_step_time: 816ms, lr: 5.4483253e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:08,780 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.0% |     | 9.79512 samples/s/p  0:04:22 }
2024-06-05 16:06:12,055 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3264/ 3581], loss: 2.470, per_step_time: 817ms, lr: 5.3935755e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:12,055 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.1% |     | 9.78564 samples/s/p  0:04:19 }
2024-06-05 16:06:15,342 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3268/ 3581], loss: 2.274, per_step_time: 820ms, lr: 5.3388285e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:15,343 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.3% |     | 9.74981 samples/s/p  0:04:16 }
2024-06-05 16:06:18,626 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3272/ 3581], loss: 2.270, per_step_time: 819ms, lr: 5.2840787e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:18,626 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.4% |     | 9.76111 samples/s/p  0:04:13 }
2024-06-05 16:06:21,907 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3276/ 3581], loss: 2.476, per_step_time: 818ms, lr: 5.229331e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:21,907 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.5% |     | 9.77005 samples/s/p  0:04:09 }
2024-06-05 16:06:25,193 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3280/ 3581], loss: 2.283, per_step_time: 820ms, lr: 5.174581e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:25,193 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.6% |     | 9.75439 samples/s/p  0:04:06 }
2024-06-05 16:06:28,481 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3284/ 3581], loss: 2.542, per_step_time: 820ms, lr: 5.119833e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:28,481 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.7% |     | 9.74775 samples/s/p  0:04:03 }
2024-06-05 16:06:31,769 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3288/ 3581], loss: 2.366, per_step_time: 820ms, lr: 5.065084e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:31,770 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.8% |     | 9.74693 samples/s/p  0:04:00 }
2024-06-05 16:06:35,054 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3292/ 3581], loss: 2.439, per_step_time: 819ms, lr: 5.0103367e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:35,054 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   91.9% |     | 9.75839 samples/s/p  0:03:56 }
2024-06-05 16:06:38,335 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3296/ 3581], loss: 2.631, per_step_time: 819ms, lr: 4.9555865e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:38,336 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.0% |    | 9.76793 samples/s/p  0:03:53 }
2024-06-05 16:06:41,612 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3300/ 3581], loss: 2.350, per_step_time: 817ms, lr: 4.9008395e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:41,613 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.2% |    | 9.78015 samples/s/p  0:03:49 }
2024-06-05 16:06:44,893 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3304/ 3581], loss: 2.466, per_step_time: 818ms, lr: 4.8460897e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:44,893 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.3% |    | 9.77151 samples/s/p  0:03:46 }
2024-06-05 16:06:48,173 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3308/ 3581], loss: 2.347, per_step_time: 818ms, lr: 4.791342e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:48,174 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.4% |    | 9.77041 samples/s/p  0:03:43 }
2024-06-05 16:06:51,451 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3312/ 3581], loss: 2.434, per_step_time: 818ms, lr: 4.7365916e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:51,451 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.5% |    | 9.77902 samples/s/p  0:03:40 }
2024-06-05 16:06:54,737 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3316/ 3581], loss: 2.592, per_step_time: 820ms, lr: 4.681845e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:54,738 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.6% |    | 9.75308 samples/s/p  0:03:37 }
2024-06-05 16:06:58,031 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3320/ 3581], loss: 2.478, per_step_time: 822ms, lr: 4.627095e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:06:58,031 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.7% |    | 9.73121 samples/s/p  0:03:34 }
2024-06-05 16:07:01,321 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3324/ 3581], loss: 2.462, per_step_time: 821ms, lr: 4.5723473e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:01,321 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.8% |    | 9.74222 samples/s/p  0:03:31 }
2024-06-05 16:07:04,600 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3328/ 3581], loss: 2.533, per_step_time: 818ms, lr: 4.517597e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:04,601 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   92.9% |    | 9.77228 samples/s/p  0:03:27 }
2024-06-05 16:07:07,886 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3332/ 3581], loss: 2.328, per_step_time: 820ms, lr: 4.462851e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:07,887 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.0% |    | 9.75412 samples/s/p  0:03:24 }
2024-06-05 16:07:11,162 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3336/ 3581], loss: 2.305, per_step_time: 817ms, lr: 4.4081007e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:11,162 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.2% |    | 9.78452 samples/s/p  0:03:20 }
2024-06-05 16:07:14,440 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3340/ 3581], loss: 2.379, per_step_time: 818ms, lr: 4.3533532e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:14,440 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.3% |    | 9.77914 samples/s/p  0:03:17 }
2024-06-05 16:07:17,722 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3344/ 3581], loss: 2.568, per_step_time: 819ms, lr: 4.2986035e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:17,723 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.4% |    | 9.76560 samples/s/p  0:03:14 }
2024-06-05 16:07:21,003 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3348/ 3581], loss: 2.722, per_step_time: 818ms, lr: 4.243856e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:21,003 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.5% |    | 9.76936 samples/s/p  0:03:10 }
2024-06-05 16:07:24,293 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3352/ 3581], loss: 2.432, per_step_time: 821ms, lr: 4.1891067e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:24,294 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.6% |    | 9.74082 samples/s/p  0:03:08 }
2024-06-05 16:07:27,577 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3356/ 3581], loss: 2.655, per_step_time: 819ms, lr: 4.134359e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:27,578 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.7% |    | 9.76239 samples/s/p  0:03:04 }
2024-06-05 16:07:30,865 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3360/ 3581], loss: 2.540, per_step_time: 820ms, lr: 4.079609e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:30,865 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.8% |    | 9.74932 samples/s/p  0:03:01 }
2024-06-05 16:07:34,161 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3364/ 3581], loss: 2.610, per_step_time: 822ms, lr: 4.0248615e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:34,161 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   93.9% |    | 9.72389 samples/s/p  0:02:58 }
2024-06-05 16:07:37,459 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3368/ 3581], loss: 2.426, per_step_time: 823ms, lr: 3.9701117e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:37,459 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.1% |   | 9.71875 samples/s/p  0:02:55 }
2024-06-05 16:07:40,734 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3372/ 3581], loss: 2.359, per_step_time: 817ms, lr: 3.9153642e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:40,735 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.2% |   | 9.78487 samples/s/p  0:02:50 }
2024-06-05 16:07:44,011 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3376/ 3581], loss: 2.555, per_step_time: 817ms, lr: 3.8606145e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:44,011 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.3% |   | 9.78229 samples/s/p  0:02:47 }
2024-06-05 16:07:47,281 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3380/ 3581], loss: 2.595, per_step_time: 816ms, lr: 3.8058668e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:47,281 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.4% |   | 9.80062 samples/s/p  0:02:44 }
2024-06-05 16:07:50,555 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3384/ 3581], loss: 2.665, per_step_time: 817ms, lr: 3.7511172e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:50,556 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.5% |   | 9.78878 samples/s/p  0:02:41 }
2024-06-05 16:07:53,842 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3388/ 3581], loss: 2.340, per_step_time: 820ms, lr: 3.69637e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:53,842 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.6% |   | 9.75261 samples/s/p  0:02:38 }
2024-06-05 16:07:57,122 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3392/ 3581], loss: 2.366, per_step_time: 818ms, lr: 3.6416195e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:07:57,122 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.7% |   | 9.77111 samples/s/p  0:02:34 }
2024-06-05 16:08:00,410 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3396/ 3581], loss: 2.450, per_step_time: 820ms, lr: 3.586873e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:00,410 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.8% |   | 9.74948 samples/s/p  0:02:31 }
2024-06-05 16:08:03,697 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3400/ 3581], loss: 2.552, per_step_time: 820ms, lr: 3.5321254e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:03,698 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   94.9% |   | 9.74951 samples/s/p  0:02:28 }
2024-06-05 16:08:06,984 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3404/ 3581], loss: 2.466, per_step_time: 820ms, lr: 3.4773752e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:06,984 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.1% |   | 9.75206 samples/s/p  0:02:25 }
2024-06-05 16:08:10,275 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3408/ 3581], loss: 2.417, per_step_time: 821ms, lr: 3.4226282e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:10,275 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.2% |   | 9.73980 samples/s/p  0:02:22 }
2024-06-05 16:08:13,560 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3412/ 3581], loss: 2.368, per_step_time: 819ms, lr: 3.3678784e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:13,560 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.3% |   | 9.75611 samples/s/p  0:02:18 }
2024-06-05 16:08:16,845 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3416/ 3581], loss: 2.457, per_step_time: 819ms, lr: 3.3131312e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:16,845 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.4% |   | 9.75736 samples/s/p  0:02:15 }
2024-06-05 16:08:20,143 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3420/ 3581], loss: 2.514, per_step_time: 823ms, lr: 3.258381e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:20,143 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.5% |   | 9.71946 samples/s/p  0:02:12 }
2024-06-05 16:08:23,427 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3424/ 3581], loss: 2.528, per_step_time: 819ms, lr: 3.2036337e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:23,427 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.6% |   | 9.75852 samples/s/p  0:02:08 }
2024-06-05 16:08:26,713 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3428/ 3581], loss: 2.473, per_step_time: 820ms, lr: 3.1488835e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:26,714 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.7% |   | 9.75333 samples/s/p  0:02:05 }
2024-06-05 16:08:29,995 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3432/ 3581], loss: 2.505, per_step_time: 819ms, lr: 3.0941364e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:29,996 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   95.8% |   | 9.76543 samples/s/p  0:02:02 }
2024-06-05 16:08:33,276 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3436/ 3581], loss: 2.646, per_step_time: 818ms, lr: 3.0393862e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:33,276 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.0% |   | 9.76985 samples/s/p  0:01:58 }
2024-06-05 16:08:36,551 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3440/ 3581], loss: 2.555, per_step_time: 817ms, lr: 2.9846397e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:36,551 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.1% |  | 9.78699 samples/s/p  0:01:55 }
2024-06-05 16:08:39,834 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3444/ 3581], loss: 2.304, per_step_time: 819ms, lr: 2.9298894e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:39,835 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.2% |  | 9.76049 samples/s/p  0:01:52 }
2024-06-05 16:08:43,115 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3448/ 3581], loss: 2.434, per_step_time: 818ms, lr: 2.875142e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:43,115 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.3% |  | 9.77003 samples/s/p  0:01:48 }
2024-06-05 16:08:46,394 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3452/ 3581], loss: 2.394, per_step_time: 818ms, lr: 2.8203917e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:46,395 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.4% |  | 9.77410 samples/s/p  0:01:45 }
2024-06-05 16:08:49,679 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3456/ 3581], loss: 2.675, per_step_time: 819ms, lr: 2.765645e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:49,679 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.5% |  | 9.76024 samples/s/p  0:01:42 }
2024-06-05 16:08:52,958 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3460/ 3581], loss: 2.353, per_step_time: 818ms, lr: 2.7108945e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:52,959 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.6% |  | 9.77351 samples/s/p  0:01:39 }
2024-06-05 16:08:56,235 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3464/ 3581], loss: 2.503, per_step_time: 817ms, lr: 2.6561477e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:56,235 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.7% |  | 9.78221 samples/s/p  0:01:35 }
2024-06-05 16:08:59,513 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3468/ 3581], loss: 2.355, per_step_time: 818ms, lr: 2.6013975e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:08:59,513 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   96.8% |  | 9.77833 samples/s/p  0:01:32 }
2024-06-05 16:09:02,798 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3472/ 3581], loss: 2.621, per_step_time: 820ms, lr: 2.5466502e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:02,799 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.0% |  | 9.75570 samples/s/p  0:01:29 }
2024-06-05 16:09:06,084 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3476/ 3581], loss: 2.445, per_step_time: 820ms, lr: 2.4919004e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:06,085 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.1% |  | 9.75400 samples/s/p  0:01:26 }
2024-06-05 16:09:09,366 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3480/ 3581], loss: 2.608, per_step_time: 819ms, lr: 2.4371534e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:09,366 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.2% |  | 9.76762 samples/s/p  0:01:22 }
2024-06-05 16:09:12,653 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3484/ 3581], loss: 2.481, per_step_time: 820ms, lr: 2.3824027e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:12,653 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.3% |  | 9.74972 samples/s/p  0:01:19 }
2024-06-05 16:09:15,934 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3488/ 3581], loss: 2.444, per_step_time: 818ms, lr: 2.327656e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:15,935 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.4% |  | 9.76803 samples/s/p  0:01:16 }
2024-06-05 16:09:19,217 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3492/ 3581], loss: 2.482, per_step_time: 819ms, lr: 2.272906e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:19,217 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.5% |  | 9.76326 samples/s/p  0:01:12 }
2024-06-05 16:09:22,494 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3496/ 3581], loss: 2.236, per_step_time: 817ms, lr: 2.2181582e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:22,494 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.6% |  | 9.78031 samples/s/p  0:01:09 }
2024-06-05 16:09:25,772 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3500/ 3581], loss: 2.488, per_step_time: 818ms, lr: 2.1634087e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:25,772 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.7% |  | 9.77795 samples/s/p  0:01:06 }
2024-06-05 16:09:29,057 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3504/ 3581], loss: 2.394, per_step_time: 819ms, lr: 2.1086612e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:29,057 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   97.8% |  | 9.75679 samples/s/p  0:01:03 }
2024-06-05 16:09:32,346 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3508/ 3581], loss: 2.470, per_step_time: 821ms, lr: 2.0539114e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:32,347 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.0% |  | 9.74302 samples/s/p  0:00:59 }
2024-06-05 16:09:35,628 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3512/ 3581], loss: 2.401, per_step_time: 819ms, lr: 1.9991644e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:35,628 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.1% | | 9.76751 samples/s/p  0:00:56 }
2024-06-05 16:09:38,900 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3516/ 3581], loss: 2.489, per_step_time: 816ms, lr: 1.9444142e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:38,900 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.2% | | 9.79612 samples/s/p  0:00:53 }
2024-06-05 16:09:42,182 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3520/ 3581], loss: 2.328, per_step_time: 819ms, lr: 1.8896669e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:42,182 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.3% | | 9.76703 samples/s/p  0:00:49 }
2024-06-05 16:09:45,459 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3524/ 3581], loss: 2.430, per_step_time: 818ms, lr: 1.834917e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:45,460 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.4% | | 9.77968 samples/s/p  0:00:46 }
2024-06-05 16:09:48,737 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3528/ 3581], loss: 2.508, per_step_time: 818ms, lr: 1.7801696e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:48,738 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.5% | | 9.77725 samples/s/p  0:00:43 }
2024-06-05 16:09:52,025 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3532/ 3581], loss: 2.652, per_step_time: 820ms, lr: 1.7254196e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:52,025 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.6% | | 9.75064 samples/s/p  0:00:40 }
2024-06-05 16:09:55,298 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3536/ 3581], loss: 2.372, per_step_time: 817ms, lr: 1.6706725e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:55,299 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.7% | | 9.79071 samples/s/p  0:00:36 }
2024-06-05 16:09:58,580 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3540/ 3581], loss: 2.724, per_step_time: 819ms, lr: 1.6159221e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:09:58,581 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   98.9% | | 9.76694 samples/s/p  0:00:33 }
2024-06-05 16:10:01,860 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3544/ 3581], loss: 2.578, per_step_time: 818ms, lr: 1.5611752e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:01,860 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.0% | | 9.77246 samples/s/p  0:00:30 }
2024-06-05 16:10:05,144 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3548/ 3581], loss: 2.622, per_step_time: 819ms, lr: 1.5064252e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:05,144 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.1% | | 9.76147 samples/s/p  0:00:27 }
2024-06-05 16:10:08,430 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3552/ 3581], loss: 2.538, per_step_time: 820ms, lr: 1.451678e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:08,431 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.2% | | 9.75540 samples/s/p  0:00:23 }
2024-06-05 16:10:11,708 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3556/ 3581], loss: 2.536, per_step_time: 818ms, lr: 1.3969278e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:11,708 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.3% | | 9.77978 samples/s/p  0:00:20 }
2024-06-05 16:10:14,995 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3560/ 3581], loss: 2.553, per_step_time: 820ms, lr: 1.3421807e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:14,995 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.4% | | 9.74929 samples/s/p  0:00:17 }
2024-06-05 16:10:18,286 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3564/ 3581], loss: 2.400, per_step_time: 821ms, lr: 1.2874305e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:18,287 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.5% | | 9.73854 samples/s/p  0:00:13 }
2024-06-05 16:10:21,572 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3568/ 3581], loss: 2.542, per_step_time: 820ms, lr: 1.2326835e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:21,573 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.6% | | 9.75428 samples/s/p  0:00:10 }
2024-06-05 16:10:24,863 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3572/ 3581], loss: 2.541, per_step_time: 821ms, lr: 1.1779333e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:24,863 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.7% | | 9.73998 samples/s/p  0:00:07 }
2024-06-05 16:10:28,144 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3576/ 3581], loss: 2.462, per_step_time: 818ms, lr: 1.1231862e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:28,144 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   99.9% | | 9.76834 samples/s/p  0:00:04 }
2024-06-05 16:10:31,430 - mindformers[mindformers/core/callback/callback.py:314] - INFO - { Epoch:[  1/  1], step:[ 3580/ 3581], loss: 2.370, per_step_time: 820ms, lr: 1.0684362e-06, overflow cond: False, loss_scale: 65536.0
2024-06-05 16:10:31,430 - mindformers[mindformers/core/callback/callback.py:324] - INFO -   100.0% | | 9.75464 samples/s/p  0:00:00 }

2024-06-05 16:10:31,435 - mindformers[mindformers/core/callback/callback.py:561] - INFO - ......Saving ckpt......
2024-06-05 16:11:59,364 - mindformers[mindformers/trainer/base_trainer.py:774] - INFO - .........Training Over!.............
