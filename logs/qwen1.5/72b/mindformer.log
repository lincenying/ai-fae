Namespace(task='text_generation', config='qwen1_5/run_qwen1_5_72b_infer.yaml', run_mode='predict', load_checkpoint='/home/ma-user/work/mindformers/research/qwen1_5/72b/', auto_trans_ckpt=True, vocab_file=None, merges_file=None, predict_data='帮助我制定一份去杭州的旅游攻略', seq_length=None, predict_length=8192, use_parallel=True, device_id=-1, use_past=None, do_sample=None, top_k=None, top_p=None, train_dataset='', remote_save_url=None, batch_size=1)
[WARNING] DEVICE(1693966,ffffb183c010,python):2024-06-19-09:57:46.856.912 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:103] Initialize] Reserved memory size for other components(2147483648) is less than recommend size(4008273920), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory'
[WARNING] HCCL_ADPT(1693966,ffffb183c010,python):2024-06-19-09:58:14.431.906 [mindspore/ccsrc/plugin/device/ascend/hal/hccl_adapter/hccl_adapter.cc:63] GenHcclOptions] The environment variable DEPLOY_MODE is not set. Now set to default value 0
2024-06-19 09:58:14,471 - mindformers[mindformers/tools/utils.py:155] - INFO - set output path to '/home/ma-user/work/mindformers/research/output'
2024-06-19 09:58:14,471 - mindformers[mindformers/trainer/base_trainer.py:90] - INFO - Now Running Task is: text_generation, Model is: qwen2_72b
2024-06-19 09:58:14,472 - mindformers[mindformers/trainer/base_trainer.py:131] - WARNING - Input model name is not in the supported list or unspecified.
2024-06-19 09:58:14,472 - mindformers[mindformers/trainer/base_trainer.py:132] - WARNING - See the list of supported task and model name: OrderedDict([('general', OrderedDict([('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/general/run_general_task.yaml')])), ('masked_image_modeling', OrderedDict([('mae_vit_base_p16', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/mae/run_mae_vit_base_p16_224_800ep.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/mae/run_mae_vit_base_p16_224_800ep.yaml')])), ('image_classification', OrderedDict([('vit_base_p16', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/vit/run_vit_base_p16_224_100ep.yaml'), ('swin_base_p4w7', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/swin/run_swin_base_p4w7_224_100ep.yaml'), ('mindspore/vit_base_p16', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/vit/run_vit_base_p16_224_100ep.yaml'), ('mindspore/swin_base_p4w7', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/swin/run_swin_base_p4w7_224_100ep.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/vit/run_vit_base_p16_224_100ep.yaml')])), ('fill_mask', OrderedDict([('bert_base_uncased', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bert/run_bert_base_uncased.yaml'), ('bert_tiny_uncased', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bert/run_bert_tiny_uncased.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bert/run_bert_tiny_uncased.yaml')])), ('contrastive_language_image_pretrain', OrderedDict([('clip_vit_b_32', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_32_pretrain_flickr8k.yaml'), ('blip2_stage1_vit_g', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage1_vit_g_qformer_pretrain.yaml'), ('blip2_stage2_vit_g_baichuan_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage2_vit_g_baichuan_7b.yaml'), ('blip2_stage2_vit_g_llama_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage2_vit_g_llama_7b.yaml'), ('mindspore/clip_vit_b_32', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_32_pretrain_flickr8k.yaml'), ('clip_vit_b_16', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_16_pretrain_flickr8k.yaml'), ('clip_vit_l_14', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_l_14_pretrain_flickr8k.yaml'), ('clip_vit_l_14@336', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_l_14@336_pretrain_flickr8k.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_32_pretrain_flickr8k.yaml')])), ('image_to_text_retrieval', OrderedDict([('blip2_stage1_evaluator', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage1_vit_g_retrieval_flickr30k.yaml')])), ('zero_shot_image_classification', OrderedDict([('clip_vit_b_32', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_32_zero_shot_image_classification_cifar100.yaml'), ('mindspore/clip_vit_b_32', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_32_zero_shot_image_classification_cifar100.yaml'), ('clip_vit_b_16', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_16_zero_shot_image_classification_cifar100.yaml'), ('clip_vit_l_14', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_l_14_zero_shot_image_classification_cifar100.yaml'), ('clip_vit_l_14@336', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_l_14@336_zero_shot_image_classification_cifar100.yaml'), ('blip2_stage1_classification', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage1_vit_g_zero_shot_image_classification_cifar100.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_clip_vit_b_32_zero_shot_image_classification_cifar100.yaml')])), ('image_to_text_generation', OrderedDict([('itt_blip2_stage2_vit_g_baichuan_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage2_vit_g_baichuan_7b_image_to_text_generation.yaml'), ('itt_blip2_stage2_vit_g_llama_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/blip2/run_blip2_stage2_vit_g_llama_7b_image_to_text_generation.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/clip/run_blip2_stage2_vit_g_llama_7b_image_to_text_generation.yaml')])), ('translation', OrderedDict([('t5_small', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/t5/run_t5_small_on_wmt16.yaml'), ('t5_tiny', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/t5/run_t5_tiny_on_wmt16.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/t5/run_t5_small_on_wmt16.yaml')])), ('text_classification', OrderedDict([('txtcls_bert_base_uncased', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/txtcls/run_txtcls_bert_base_uncased.yaml'), ('txtcls_bert_base_uncased_mnli', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/txtcls/run_txtcls_bert_base_uncased_mnli.yaml'), ('mindspore/txtcls_bert_base_uncased_mnli', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/txtcls/run_txtcls_bert_base_uncased_mnli.yaml'), ('gpt2_txtcls', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2_txtcls.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/txtcls/run_txtcls_bert_base_uncased.yaml')])), ('token_classification', OrderedDict([('tokcls_bert_base_chinese', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/tokcls/run_tokcls_bert_base_chinese.yaml'), ('tokcls_bert_base_chinese_cluener', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/tokcls/run_tokcls_bert_base_chinese_cluener.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/tokcls/run_tokcls_bert_base_chinese.yaml')])), ('question_answering', OrderedDict([('qa_bert_base_uncased', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/qa/run_qa_bert_base_uncased.yaml'), ('qa_bert_base_uncased_squad', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/qa/run_qa_bert_base_uncased.yaml'), ('mindspore/qa_bert_base_uncased', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/qa/run_qa_bert_base_uncased.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/qa/run_qa_bert_base_uncased.yaml')])), ('text_generation', OrderedDict([('gpt2', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2.yaml'), ('gpt2_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2_lora.yaml'), ('gpt2_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2_13b.yaml'), ('gpt2_52b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2_52b.yaml'), ('gpt2_xl', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2_xl.yaml'), ('gpt2_xl_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2_xl_lora.yaml'), ('llama_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama/run_llama_7b.yaml'), ('llama_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama/run_llama_13b.yaml'), ('llama_65b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama/run_llama_65b.yaml'), ('llama2_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama2/run_llama2_7b.yaml'), ('llama2_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama2/run_llama2_13b.yaml'), ('llama2_70b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama2/run_llama2_70b.yaml'), ('codellama_34b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/codellama/run_codellama_34b_910b.yaml'), ('llama_7b_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/llama/run_llama_7b_lora.yaml'), ('pangualpha_2_6b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/pangualpha/run_pangualpha_2_6b.yaml'), ('pangualpha_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/pangualpha/run_pangualpha_13b.yaml'), ('glm_6b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm/run_glm_6b_finetune.yaml'), ('glm_6b_chat', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm/run_glm_6b_infer.yaml'), ('glm_6b_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm/run_glm_6b_lora.yaml'), ('glm_6b_lora_chat', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm/run_glm_6b_lora_infer.yaml'), ('glm2_6b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm2/run_glm2_6b.yaml'), ('glm2_6b_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm2/run_glm2_6b_lora.yaml'), ('glm2_6b_ptuning2', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm2/run_glm2_6b_ptuning2.yaml'), ('glm3_6b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/glm3/run_glm3_6b.yaml'), ('codegeex2_6b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/codegeex2/run_codegeex2_6b.yaml'), ('bloom_560m', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bloom/run_bloom_560m.yaml'), ('bloom_7.1b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bloom/run_bloom_7.1b.yaml'), ('bloom_65b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bloom/run_bloom_65b.yaml'), ('bloom_176b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/bloom/run_bloom_176b.yaml'), ('baichuan_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/baichuan/run_baichuan_7b.yaml'), ('baichuan2_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/baichuan2/run_baichuan2_7b.yaml'), ('baichuan2_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/baichuan2/run_baichuan2_13b.yaml'), ('ziya_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/ziya/run_ziya_13b.yaml'), ('skywork_13b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/skywork/run_skywork_13b.yaml'), ('internlm_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/internlm/run_internlm_7b.yaml'), ('internlm_7b_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/internlm/run_internlm_7b_lora.yaml'), ('qwen_7b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/qwen/run_qwen_7b.yaml'), ('qwen_7b_lora', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/research/qwen/run_qwen_7b_lora.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2.yaml')])), ('segment_anything', OrderedDict([('sam_vit_b', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/sam/run_sam_vit-b.yaml'), ('sam_vit_l', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/sam/run_sam_vit-l.yaml'), ('sam_vit_h', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/sam/run_sam_vit-h.yaml'), ('common', '/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/sam/run_sam_vit-h.yaml')]))])
2024-06-19 09:58:14,473 - mindformers[mindformers/trainer/base_trainer.py:133] - WARNING - The default model config: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/configs/gpt2/run_gpt2.yaml will now be used for the text_generation task 
2024-06-19 09:58:14,473 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': True, 'select_recompute': False, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}
2024-06-19 09:58:14,474 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 1, 'model_parallel': 8, 'pipeline_stage': 1, 'micro_batch_num': 1, 'vocab_emb_dp': False, 'gradient_aggregation_group': 4}
2024-06-19 09:58:14,474 - mindformers[mindformers/trainer/base_trainer.py:196] - INFO - The current parallel mode is semi_auto_parallel, full batch is True,so global batch size will be changed: global_batch_size = batch_size * data_parallel * micro_batch_interleave_num * gradient_accumulation_steps = 1 = 1 * 1 * 1 * 1
2024-06-19 09:58:14,475 - mindformers[mindformers/trainer/base_trainer.py:388] - INFO - .........Build Network From Config..........
2024-06-19 09:58:14,475 - mindformers[mindformers/models/llama/llama_config.py:185] - WARNING - Argument `compute_in_2d` is deprecated.
2024-06-19 09:58:14,476 - mindformers[mindformers/models/llama/llama_config.py:188] - WARNING - Argument `use_past_shard` is deprecated.
2024-06-19 09:58:14,476 - mindformers[mindformers/version_control.py:60] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1
2024-06-19 09:58:14,476 - mindformers[mindformers/version_control.py:64] - INFO - 
The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: 
export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.
2024-06-19 09:58:14,476 - mindformers[mindformers/version_control.py:73] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.
2024-06-19 09:58:16,494 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-09:58:16.495.792 [mindspore/common/parameter.py:786] This interface may be deleted in the future.
2024-06-19 09:58:17,528 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:18,558 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:19,592 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:20,621 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:21,651 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:22,685 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:23,723 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:24,757 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:58:25,895 - mindformers[mindformers/modules/layers.py:554] - WARNING - The user passed the custom defined activation function True. If the user want to enable shard for the activation cell, the user should set the shard for each primitives in the cell.
2024-06-19 09:59:38,775 - mindformers[mindformers/models/base_model.py:117] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
2024-06-19 09:59:38,812 - mindformers[mindformers/trainer/base_trainer.py:539] - INFO - Network Parameters: 72287 M.
2024-06-19 09:59:39,311 - mindformers[mindformers/trainer/utils.py:343] - INFO - .........Building model.........
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:01:33.681.709 [mindspore/ccsrc/frontend/parallel/pass/pass_utils.cc:119] ExtractBackwardMatMul] backward_matmul_dx_dw_map size:0
start compile Ascend C operator RmsNorm. kernel name is rms_norm
-[DEBUG]: RmsNorm_20 has not registed self tiling struct.
compile Ascend C operator: RmsNorm success!
\2024-06-19 10:04:39,702 - mindformers[mindformers/trainer/utils.py:356] - INFO - /home/ma-user/work/mindformers/research/output is_share_disk: False
2024-06-19 10:04:39,707 - mindformers[mindformers/trainer/utils.py:357] - INFO - world_size: 8
2024-06-19 10:04:39,719 - mindformers[mindformers/trainer/utils.py:538] - INFO - .........Collecting strategy.........
2024-06-19 10:04:39,724 - mindformers[mindformers/trainer/utils.py:545] - INFO - pipeline_stage = 1, strategy using ./output/strategy/ckpt_strategy_rank_0_rank_0.ckpt
2024-06-19 10:04:39,728 - mindformers[mindformers/trainer/utils.py:401] - INFO - Make soft link of checkpoint file from /home/ma-user/work/mindformers/research/qwen1_5/72b to ./output/softlink_ckpt/72b
2024-06-19 10:04:39,751 - mindformers[mindformers/trainer/utils.py:585] - INFO - .........Transforming ckpt.........
2024-06-19 10:04:39,752 - mindformers[mindformers/trainer/utils.py:586] - INFO - Src ckpt strategy: None
2024-06-19 10:04:39,752 - mindformers[mindformers/trainer/utils.py:587] - INFO - Src ckpt: ./output/softlink_ckpt/72b
2024-06-19 10:04:39,752 - mindformers[mindformers/trainer/utils.py:588] - INFO - Dst ckpt strategy: ./output/strategy/ckpt_strategy_rank_0_rank_0.ckpt
2024-06-19 10:04:39,752 - mindformers[mindformers/trainer/utils.py:589] - INFO - Dst ckpt: ./output/transformed_checkpoint/72b
2024-06-19 10:48:25,912 - mindformers[mindformers/trainer/utils.py:596] - INFO - .........Transform succeed!.........
2024-06-19 10:48:25,919 - mindformers[mindformers/trainer/utils.py:728] - INFO - Transforming checkpoint: |▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮|100%
2024-06-19 10:48:25,920 - mindformers[mindformers/trainer/utils.py:734] - INFO - .............Start load checkpoint from checkpoint..................
2024-06-19 10:48:25,922 - mindformers[mindformers/trainer/utils.py:251] - INFO - When distributed loads are sliced weights,load_checkpoint should be a checkpoint directory containing the directory of rank_{0-*},The directory structure is as follows: **checkpoint_root_dir/rank_{0-*}/**.ckpt
2024-06-19 10:54:36,765 - mindformers[mindformers/trainer/utils.py:264] - INFO - Distribute load is success.
2024-06-19 10:54:36,767 - mindformers[mindformers/trainer/utils.py:741] - INFO - loaded checkpoint: ./output/transformed_checkpoint/72b
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.157.940 [mindspore/train/serialization.py:183] The type of model.layers.0.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.159.359 [mindspore/train/serialization.py:183] The type of model.layers.0.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.398.731 [mindspore/train/serialization.py:183] The type of model.layers.1.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.399.950 [mindspore/train/serialization.py:183] The type of model.layers.1.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.643.556 [mindspore/train/serialization.py:183] The type of model.layers.2.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.644.656 [mindspore/train/serialization.py:183] The type of model.layers.2.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.922.972 [mindspore/train/serialization.py:183] The type of model.layers.3.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:37.924.179 [mindspore/train/serialization.py:183] The type of model.layers.3.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.162.391 [mindspore/train/serialization.py:183] The type of model.layers.4.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.163.523 [mindspore/train/serialization.py:183] The type of model.layers.4.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.389.544 [mindspore/train/serialization.py:183] The type of model.layers.5.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.390.645 [mindspore/train/serialization.py:183] The type of model.layers.5.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.620.508 [mindspore/train/serialization.py:183] The type of model.layers.6.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.621.666 [mindspore/train/serialization.py:183] The type of model.layers.6.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.855.322 [mindspore/train/serialization.py:183] The type of model.layers.7.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:38.856.421 [mindspore/train/serialization.py:183] The type of model.layers.7.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.107.490 [mindspore/train/serialization.py:183] The type of model.layers.8.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.108.677 [mindspore/train/serialization.py:183] The type of model.layers.8.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.341.597 [mindspore/train/serialization.py:183] The type of model.layers.9.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.342.773 [mindspore/train/serialization.py:183] The type of model.layers.9.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.573.152 [mindspore/train/serialization.py:183] The type of model.layers.10.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.574.345 [mindspore/train/serialization.py:183] The type of model.layers.10.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.806.761 [mindspore/train/serialization.py:183] The type of model.layers.11.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:39.807.844 [mindspore/train/serialization.py:183] The type of model.layers.11.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.529.46 [mindspore/train/serialization.py:183] The type of model.layers.12.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.541.90 [mindspore/train/serialization.py:183] The type of model.layers.12.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.284.172 [mindspore/train/serialization.py:183] The type of model.layers.13.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.285.438 [mindspore/train/serialization.py:183] The type of model.layers.13.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.519.204 [mindspore/train/serialization.py:183] The type of model.layers.14.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.520.418 [mindspore/train/serialization.py:183] The type of model.layers.14.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.757.573 [mindspore/train/serialization.py:183] The type of model.layers.15.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:40.758.657 [mindspore/train/serialization.py:183] The type of model.layers.15.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.168.88 [mindspore/train/serialization.py:183] The type of model.layers.16.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.180.25 [mindspore/train/serialization.py:183] The type of model.layers.16.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.272.036 [mindspore/train/serialization.py:183] The type of model.layers.17.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.273.248 [mindspore/train/serialization.py:183] The type of model.layers.17.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.550.755 [mindspore/train/serialization.py:183] The type of model.layers.18.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.551.897 [mindspore/train/serialization.py:183] The type of model.layers.18.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.806.540 [mindspore/train/serialization.py:183] The type of model.layers.19.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:41.807.642 [mindspore/train/serialization.py:183] The type of model.layers.19.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.622.53 [mindspore/train/serialization.py:183] The type of model.layers.20.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.634.94 [mindspore/train/serialization.py:183] The type of model.layers.20.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.320.572 [mindspore/train/serialization.py:183] The type of model.layers.21.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.321.691 [mindspore/train/serialization.py:183] The type of model.layers.21.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.577.615 [mindspore/train/serialization.py:183] The type of model.layers.22.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.578.693 [mindspore/train/serialization.py:183] The type of model.layers.22.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.845.829 [mindspore/train/serialization.py:183] The type of model.layers.23.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:42.847.023 [mindspore/train/serialization.py:183] The type of model.layers.23.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.104.656 [mindspore/train/serialization.py:183] The type of model.layers.24.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.105.782 [mindspore/train/serialization.py:183] The type of model.layers.24.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.360.882 [mindspore/train/serialization.py:183] The type of model.layers.25.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.361.957 [mindspore/train/serialization.py:183] The type of model.layers.25.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.627.640 [mindspore/train/serialization.py:183] The type of model.layers.26.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.628.738 [mindspore/train/serialization.py:183] The type of model.layers.26.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.883.654 [mindspore/train/serialization.py:183] The type of model.layers.27.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:43.884.821 [mindspore/train/serialization.py:183] The type of model.layers.27.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.141.591 [mindspore/train/serialization.py:183] The type of model.layers.28.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.142.666 [mindspore/train/serialization.py:183] The type of model.layers.28.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.403.587 [mindspore/train/serialization.py:183] The type of model.layers.29.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.404.822 [mindspore/train/serialization.py:183] The type of model.layers.29.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.667.376 [mindspore/train/serialization.py:183] The type of model.layers.30.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.668.496 [mindspore/train/serialization.py:183] The type of model.layers.30.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.949.198 [mindspore/train/serialization.py:183] The type of model.layers.31.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:44.950.356 [mindspore/train/serialization.py:183] The type of model.layers.31.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.209.833 [mindspore/train/serialization.py:183] The type of model.layers.32.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.210.960 [mindspore/train/serialization.py:183] The type of model.layers.32.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.472.403 [mindspore/train/serialization.py:183] The type of model.layers.33.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.473.573 [mindspore/train/serialization.py:183] The type of model.layers.33.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.735.818 [mindspore/train/serialization.py:183] The type of model.layers.34.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.736.830 [mindspore/train/serialization.py:183] The type of model.layers.34.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.991.724 [mindspore/train/serialization.py:183] The type of model.layers.35.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:45.992.921 [mindspore/train/serialization.py:183] The type of model.layers.35.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:46.249.958 [mindspore/train/serialization.py:183] The type of model.layers.36.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:46.251.004 [mindspore/train/serialization.py:183] The type of model.layers.36.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:46.527.633 [mindspore/train/serialization.py:183] The type of model.layers.37.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:46.528.840 [mindspore/train/serialization.py:183] The type of model.layers.37.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:46.813.900 [mindspore/train/serialization.py:183] The type of model.layers.38.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:46.814.986 [mindspore/train/serialization.py:183] The type of model.layers.38.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.945.65 [mindspore/train/serialization.py:183] The type of model.layers.39.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.956.78 [mindspore/train/serialization.py:183] The type of model.layers.39.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.386.856 [mindspore/train/serialization.py:183] The type of model.layers.40.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.387.922 [mindspore/train/serialization.py:183] The type of model.layers.40.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.676.857 [mindspore/train/serialization.py:183] The type of model.layers.41.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.678.086 [mindspore/train/serialization.py:183] The type of model.layers.41.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.968.185 [mindspore/train/serialization.py:183] The type of model.layers.42.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:47.969.287 [mindspore/train/serialization.py:183] The type of model.layers.42.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:48.242.442 [mindspore/train/serialization.py:183] The type of model.layers.43.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:48.243.434 [mindspore/train/serialization.py:183] The type of model.layers.43.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:48.522.011 [mindspore/train/serialization.py:183] The type of model.layers.44.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:48.523.069 [mindspore/train/serialization.py:183] The type of model.layers.44.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:48.799.546 [mindspore/train/serialization.py:183] The type of model.layers.45.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:48.800.558 [mindspore/train/serialization.py:183] The type of model.layers.45.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.737.05 [mindspore/train/serialization.py:183] The type of model.layers.46.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.746.94 [mindspore/train/serialization.py:183] The type of model.layers.46.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.341.908 [mindspore/train/serialization.py:183] The type of model.layers.47.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.342.948 [mindspore/train/serialization.py:183] The type of model.layers.47.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.608.413 [mindspore/train/serialization.py:183] The type of model.layers.48.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.609.432 [mindspore/train/serialization.py:183] The type of model.layers.48.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.875.458 [mindspore/train/serialization.py:183] The type of model.layers.49.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:49.876.533 [mindspore/train/serialization.py:183] The type of model.layers.49.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.141.035 [mindspore/train/serialization.py:183] The type of model.layers.50.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.142.078 [mindspore/train/serialization.py:183] The type of model.layers.50.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.412.262 [mindspore/train/serialization.py:183] The type of model.layers.51.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.413.367 [mindspore/train/serialization.py:183] The type of model.layers.51.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.674.797 [mindspore/train/serialization.py:183] The type of model.layers.52.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.675.871 [mindspore/train/serialization.py:183] The type of model.layers.52.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.941.179 [mindspore/train/serialization.py:183] The type of model.layers.53.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:50.942.232 [mindspore/train/serialization.py:183] The type of model.layers.53.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:51.209.824 [mindspore/train/serialization.py:183] The type of model.layers.54.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:51.210.752 [mindspore/train/serialization.py:183] The type of model.layers.54.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:51.477.592 [mindspore/train/serialization.py:183] The type of model.layers.55.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:51.478.532 [mindspore/train/serialization.py:183] The type of model.layers.55.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:51.753.754 [mindspore/train/serialization.py:183] The type of model.layers.56.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:51.754.690 [mindspore/train/serialization.py:183] The type of model.layers.56.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.284.01 [mindspore/train/serialization.py:183] The type of model.layers.57.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.293.64 [mindspore/train/serialization.py:183] The type of model.layers.57.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.310.495 [mindspore/train/serialization.py:183] The type of model.layers.58.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.311.437 [mindspore/train/serialization.py:183] The type of model.layers.58.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.586.537 [mindspore/train/serialization.py:183] The type of model.layers.59.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.587.493 [mindspore/train/serialization.py:183] The type of model.layers.59.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.864.916 [mindspore/train/serialization.py:183] The type of model.layers.60.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:52.865.908 [mindspore/train/serialization.py:183] The type of model.layers.60.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.138.016 [mindspore/train/serialization.py:183] The type of model.layers.61.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.138.972 [mindspore/train/serialization.py:183] The type of model.layers.61.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.414.728 [mindspore/train/serialization.py:183] The type of model.layers.62.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.415.732 [mindspore/train/serialization.py:183] The type of model.layers.62.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.692.366 [mindspore/train/serialization.py:183] The type of model.layers.63.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.693.396 [mindspore/train/serialization.py:183] The type of model.layers.63.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.968.318 [mindspore/train/serialization.py:183] The type of model.layers.64.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:53.969.329 [mindspore/train/serialization.py:183] The type of model.layers.64.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:54.243.811 [mindspore/train/serialization.py:183] The type of model.layers.65.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:54.244.763 [mindspore/train/serialization.py:183] The type of model.layers.65.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:54.524.675 [mindspore/train/serialization.py:183] The type of model.layers.66.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:54.525.690 [mindspore/train/serialization.py:183] The type of model.layers.66.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:54.804.444 [mindspore/train/serialization.py:183] The type of model.layers.67.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:54.805.505 [mindspore/train/serialization.py:183] The type of model.layers.67.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.787.85 [mindspore/train/serialization.py:183] The type of model.layers.68.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.798.30 [mindspore/train/serialization.py:183] The type of model.layers.68.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.366.328 [mindspore/train/serialization.py:183] The type of model.layers.69.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.367.312 [mindspore/train/serialization.py:183] The type of model.layers.69.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.639.423 [mindspore/train/serialization.py:183] The type of model.layers.70.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.640.467 [mindspore/train/serialization.py:183] The type of model.layers.70.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.913.935 [mindspore/train/serialization.py:183] The type of model.layers.71.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:55.914.910 [mindspore/train/serialization.py:183] The type of model.layers.71.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:56.188.746 [mindspore/train/serialization.py:183] The type of model.layers.72.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:56.189.758 [mindspore/train/serialization.py:183] The type of model.layers.72.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:56.461.673 [mindspore/train/serialization.py:183] The type of model.layers.73.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:56.462.629 [mindspore/train/serialization.py:183] The type of model.layers.73.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:56.736.182 [mindspore/train/serialization.py:183] The type of model.layers.74.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:56.737.148 [mindspore/train/serialization.py:183] The type of model.layers.74.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.988.5 [mindspore/train/serialization.py:183] The type of model.layers.75.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.108.61 [mindspore/train/serialization.py:183] The type of model.layers.75.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.285.480 [mindspore/train/serialization.py:183] The type of model.layers.76.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.286.441 [mindspore/train/serialization.py:183] The type of model.layers.76.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.585.729 [mindspore/train/serialization.py:183] The type of model.layers.77.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.586.726 [mindspore/train/serialization.py:183] The type of model.layers.77.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.858.550 [mindspore/train/serialization.py:183] The type of model.layers.78.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:57.859.515 [mindspore/train/serialization.py:183] The type of model.layers.78.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.132.645 [mindspore/train/serialization.py:183] The type of model.layers.79.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.133.628 [mindspore/train/serialization.py:183] The type of model.layers.79.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.431.248 [mindspore/train/serialization.py:183] The type of model.norm_out.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.848.658 [mindspore/train/serialization.py:1378] For 'load_param_into_net', 160 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.848.907 [mindspore/train/serialization.py:1383] model.layers.0.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.848.994 [mindspore/train/serialization.py:1383] model.layers.0.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.063 [mindspore/train/serialization.py:1383] model.layers.1.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.128 [mindspore/train/serialization.py:1383] model.layers.1.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.200 [mindspore/train/serialization.py:1383] model.layers.2.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.274 [mindspore/train/serialization.py:1383] model.layers.2.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.334 [mindspore/train/serialization.py:1383] model.layers.3.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.394 [mindspore/train/serialization.py:1383] model.layers.3.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.452 [mindspore/train/serialization.py:1383] model.layers.4.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.510 [mindspore/train/serialization.py:1383] model.layers.4.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.594 [mindspore/train/serialization.py:1383] model.layers.5.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.655 [mindspore/train/serialization.py:1383] model.layers.5.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.715 [mindspore/train/serialization.py:1383] model.layers.6.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.773 [mindspore/train/serialization.py:1383] model.layers.6.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.833 [mindspore/train/serialization.py:1383] model.layers.7.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.892 [mindspore/train/serialization.py:1383] model.layers.7.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.849.949 [mindspore/train/serialization.py:1383] model.layers.8.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.007 [mindspore/train/serialization.py:1383] model.layers.8.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.065 [mindspore/train/serialization.py:1383] model.layers.9.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.121 [mindspore/train/serialization.py:1383] model.layers.9.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.178 [mindspore/train/serialization.py:1383] model.layers.10.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.234 [mindspore/train/serialization.py:1383] model.layers.10.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.291 [mindspore/train/serialization.py:1383] model.layers.11.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.347 [mindspore/train/serialization.py:1383] model.layers.11.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.404 [mindspore/train/serialization.py:1383] model.layers.12.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.461 [mindspore/train/serialization.py:1383] model.layers.12.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.517 [mindspore/train/serialization.py:1383] model.layers.13.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.573 [mindspore/train/serialization.py:1383] model.layers.13.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.629 [mindspore/train/serialization.py:1383] model.layers.14.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.685 [mindspore/train/serialization.py:1383] model.layers.14.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.742 [mindspore/train/serialization.py:1383] model.layers.15.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.798 [mindspore/train/serialization.py:1383] model.layers.15.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.853 [mindspore/train/serialization.py:1383] model.layers.16.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.917 [mindspore/train/serialization.py:1383] model.layers.16.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.850.976 [mindspore/train/serialization.py:1383] model.layers.17.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.032 [mindspore/train/serialization.py:1383] model.layers.17.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.087 [mindspore/train/serialization.py:1383] model.layers.18.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.143 [mindspore/train/serialization.py:1383] model.layers.18.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.201 [mindspore/train/serialization.py:1383] model.layers.19.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.257 [mindspore/train/serialization.py:1383] model.layers.19.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.313 [mindspore/train/serialization.py:1383] model.layers.20.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.370 [mindspore/train/serialization.py:1383] model.layers.20.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.426 [mindspore/train/serialization.py:1383] model.layers.21.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.480 [mindspore/train/serialization.py:1383] model.layers.21.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.536 [mindspore/train/serialization.py:1383] model.layers.22.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.591 [mindspore/train/serialization.py:1383] model.layers.22.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.647 [mindspore/train/serialization.py:1383] model.layers.23.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.704 [mindspore/train/serialization.py:1383] model.layers.23.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.761 [mindspore/train/serialization.py:1383] model.layers.24.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.816 [mindspore/train/serialization.py:1383] model.layers.24.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.872 [mindspore/train/serialization.py:1383] model.layers.25.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.927 [mindspore/train/serialization.py:1383] model.layers.25.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.851.982 [mindspore/train/serialization.py:1383] model.layers.26.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.038 [mindspore/train/serialization.py:1383] model.layers.26.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.093 [mindspore/train/serialization.py:1383] model.layers.27.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.149 [mindspore/train/serialization.py:1383] model.layers.27.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.212 [mindspore/train/serialization.py:1383] model.layers.28.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.271 [mindspore/train/serialization.py:1383] model.layers.28.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.327 [mindspore/train/serialization.py:1383] model.layers.29.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.383 [mindspore/train/serialization.py:1383] model.layers.29.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.439 [mindspore/train/serialization.py:1383] model.layers.30.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.494 [mindspore/train/serialization.py:1383] model.layers.30.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.550 [mindspore/train/serialization.py:1383] model.layers.31.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.605 [mindspore/train/serialization.py:1383] model.layers.31.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.662 [mindspore/train/serialization.py:1383] model.layers.32.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.718 [mindspore/train/serialization.py:1383] model.layers.32.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.775 [mindspore/train/serialization.py:1383] model.layers.33.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.830 [mindspore/train/serialization.py:1383] model.layers.33.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.887 [mindspore/train/serialization.py:1383] model.layers.34.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.943 [mindspore/train/serialization.py:1383] model.layers.34.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.852.999 [mindspore/train/serialization.py:1383] model.layers.35.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.054 [mindspore/train/serialization.py:1383] model.layers.35.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.109 [mindspore/train/serialization.py:1383] model.layers.36.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.163 [mindspore/train/serialization.py:1383] model.layers.36.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.236 [mindspore/train/serialization.py:1383] model.layers.37.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.296 [mindspore/train/serialization.py:1383] model.layers.37.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.353 [mindspore/train/serialization.py:1383] model.layers.38.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.411 [mindspore/train/serialization.py:1383] model.layers.38.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.476 [mindspore/train/serialization.py:1383] model.layers.39.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.534 [mindspore/train/serialization.py:1383] model.layers.39.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.590 [mindspore/train/serialization.py:1383] model.layers.40.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.645 [mindspore/train/serialization.py:1383] model.layers.40.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.701 [mindspore/train/serialization.py:1383] model.layers.41.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.758 [mindspore/train/serialization.py:1383] model.layers.41.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.816 [mindspore/train/serialization.py:1383] model.layers.42.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.871 [mindspore/train/serialization.py:1383] model.layers.42.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.927 [mindspore/train/serialization.py:1383] model.layers.43.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.853.982 [mindspore/train/serialization.py:1383] model.layers.43.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.037 [mindspore/train/serialization.py:1383] model.layers.44.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.093 [mindspore/train/serialization.py:1383] model.layers.44.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.147 [mindspore/train/serialization.py:1383] model.layers.45.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.203 [mindspore/train/serialization.py:1383] model.layers.45.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.258 [mindspore/train/serialization.py:1383] model.layers.46.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.312 [mindspore/train/serialization.py:1383] model.layers.46.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.367 [mindspore/train/serialization.py:1383] model.layers.47.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.422 [mindspore/train/serialization.py:1383] model.layers.47.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.478 [mindspore/train/serialization.py:1383] model.layers.48.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.533 [mindspore/train/serialization.py:1383] model.layers.48.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.588 [mindspore/train/serialization.py:1383] model.layers.49.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.643 [mindspore/train/serialization.py:1383] model.layers.49.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.698 [mindspore/train/serialization.py:1383] model.layers.50.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.761 [mindspore/train/serialization.py:1383] model.layers.50.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.819 [mindspore/train/serialization.py:1383] model.layers.51.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.874 [mindspore/train/serialization.py:1383] model.layers.51.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.930 [mindspore/train/serialization.py:1383] model.layers.52.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.854.988 [mindspore/train/serialization.py:1383] model.layers.52.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.045 [mindspore/train/serialization.py:1383] model.layers.53.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.101 [mindspore/train/serialization.py:1383] model.layers.53.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.157 [mindspore/train/serialization.py:1383] model.layers.54.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.214 [mindspore/train/serialization.py:1383] model.layers.54.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.270 [mindspore/train/serialization.py:1383] model.layers.55.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.325 [mindspore/train/serialization.py:1383] model.layers.55.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.381 [mindspore/train/serialization.py:1383] model.layers.56.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.439 [mindspore/train/serialization.py:1383] model.layers.56.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.494 [mindspore/train/serialization.py:1383] model.layers.57.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.550 [mindspore/train/serialization.py:1383] model.layers.57.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.605 [mindspore/train/serialization.py:1383] model.layers.58.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.661 [mindspore/train/serialization.py:1383] model.layers.58.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.716 [mindspore/train/serialization.py:1383] model.layers.59.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.772 [mindspore/train/serialization.py:1383] model.layers.59.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.828 [mindspore/train/serialization.py:1383] model.layers.60.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.882 [mindspore/train/serialization.py:1383] model.layers.60.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.937 [mindspore/train/serialization.py:1383] model.layers.61.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.855.999 [mindspore/train/serialization.py:1383] model.layers.61.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.054 [mindspore/train/serialization.py:1383] model.layers.62.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.109 [mindspore/train/serialization.py:1383] model.layers.62.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.165 [mindspore/train/serialization.py:1383] model.layers.63.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.219 [mindspore/train/serialization.py:1383] model.layers.63.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.273 [mindspore/train/serialization.py:1383] model.layers.64.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.328 [mindspore/train/serialization.py:1383] model.layers.64.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.383 [mindspore/train/serialization.py:1383] model.layers.65.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.437 [mindspore/train/serialization.py:1383] model.layers.65.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.492 [mindspore/train/serialization.py:1383] model.layers.66.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.547 [mindspore/train/serialization.py:1383] model.layers.66.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.601 [mindspore/train/serialization.py:1383] model.layers.67.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.656 [mindspore/train/serialization.py:1383] model.layers.67.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.711 [mindspore/train/serialization.py:1383] model.layers.68.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.766 [mindspore/train/serialization.py:1383] model.layers.68.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.820 [mindspore/train/serialization.py:1383] model.layers.69.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.875 [mindspore/train/serialization.py:1383] model.layers.69.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.930 [mindspore/train/serialization.py:1383] model.layers.70.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.856.984 [mindspore/train/serialization.py:1383] model.layers.70.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.039 [mindspore/train/serialization.py:1383] model.layers.71.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.094 [mindspore/train/serialization.py:1383] model.layers.71.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.149 [mindspore/train/serialization.py:1383] model.layers.72.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.222 [mindspore/train/serialization.py:1383] model.layers.72.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.336 [mindspore/train/serialization.py:1383] model.layers.73.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.394 [mindspore/train/serialization.py:1383] model.layers.73.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.450 [mindspore/train/serialization.py:1383] model.layers.74.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.506 [mindspore/train/serialization.py:1383] model.layers.74.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.561 [mindspore/train/serialization.py:1383] model.layers.75.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.616 [mindspore/train/serialization.py:1383] model.layers.75.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.671 [mindspore/train/serialization.py:1383] model.layers.76.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.727 [mindspore/train/serialization.py:1383] model.layers.76.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.782 [mindspore/train/serialization.py:1383] model.layers.77.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.837 [mindspore/train/serialization.py:1383] model.layers.77.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.891 [mindspore/train/serialization.py:1383] model.layers.78.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.857.946 [mindspore/train/serialization.py:1383] model.layers.78.attention.kvcache_mgr.value_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.858.002 [mindspore/train/serialization.py:1383] model.layers.79.attention.kvcache_mgr.key_past is not loaded.
[WARNING] ME(1693966:281473659944976,MainProcess):2024-06-19-10:54:58.858.057 [mindspore/train/serialization.py:1383] model.layers.79.attention.kvcache_mgr.value_past is not loaded.
2024-06-19 10:54:58,858 - mindformers[mindformers/trainer/utils.py:768] - INFO - Network parameters are not loaded: (['model.layers.0.attention.kvcache_mgr.key_past', 'model.layers.0.attention.kvcache_mgr.value_past', 'model.layers.1.attention.kvcache_mgr.key_past', 'model.layers.1.attention.kvcache_mgr.value_past', 'model.layers.2.attention.kvcache_mgr.key_past', 'model.layers.2.attention.kvcache_mgr.value_past', 'model.layers.3.attention.kvcache_mgr.key_past', 'model.layers.3.attention.kvcache_mgr.value_past', 'model.layers.4.attention.kvcache_mgr.key_past', 'model.layers.4.attention.kvcache_mgr.value_past', 'model.layers.5.attention.kvcache_mgr.key_past', 'model.layers.5.attention.kvcache_mgr.value_past', 'model.layers.6.attention.kvcache_mgr.key_past', 'model.layers.6.attention.kvcache_mgr.value_past', 'model.layers.7.attention.kvcache_mgr.key_past', 'model.layers.7.attention.kvcache_mgr.value_past', 'model.layers.8.attention.kvcache_mgr.key_past', 'model.layers.8.attention.kvcache_mgr.value_past', 'model.layers.9.attention.kvcache_mgr.key_past', 'model.layers.9.attention.kvcache_mgr.value_past', 'model.layers.10.attention.kvcache_mgr.key_past', 'model.layers.10.attention.kvcache_mgr.value_past', 'model.layers.11.attention.kvcache_mgr.key_past', 'model.layers.11.attention.kvcache_mgr.value_past', 'model.layers.12.attention.kvcache_mgr.key_past', 'model.layers.12.attention.kvcache_mgr.value_past', 'model.layers.13.attention.kvcache_mgr.key_past', 'model.layers.13.attention.kvcache_mgr.value_past', 'model.layers.14.attention.kvcache_mgr.key_past', 'model.layers.14.attention.kvcache_mgr.value_past', 'model.layers.15.attention.kvcache_mgr.key_past', 'model.layers.15.attention.kvcache_mgr.value_past', 'model.layers.16.attention.kvcache_mgr.key_past', 'model.layers.16.attention.kvcache_mgr.value_past', 'model.layers.17.attention.kvcache_mgr.key_past', 'model.layers.17.attention.kvcache_mgr.value_past', 'model.layers.18.attention.kvcache_mgr.key_past', 'model.layers.18.attention.kvcache_mgr.value_past', 'model.layers.19.attention.kvcache_mgr.key_past', 'model.layers.19.attention.kvcache_mgr.value_past', 'model.layers.20.attention.kvcache_mgr.key_past', 'model.layers.20.attention.kvcache_mgr.value_past', 'model.layers.21.attention.kvcache_mgr.key_past', 'model.layers.21.attention.kvcache_mgr.value_past', 'model.layers.22.attention.kvcache_mgr.key_past', 'model.layers.22.attention.kvcache_mgr.value_past', 'model.layers.23.attention.kvcache_mgr.key_past', 'model.layers.23.attention.kvcache_mgr.value_past', 'model.layers.24.attention.kvcache_mgr.key_past', 'model.layers.24.attention.kvcache_mgr.value_past', 'model.layers.25.attention.kvcache_mgr.key_past', 'model.layers.25.attention.kvcache_mgr.value_past', 'model.layers.26.attention.kvcache_mgr.key_past', 'model.layers.26.attention.kvcache_mgr.value_past', 'model.layers.27.attention.kvcache_mgr.key_past', 'model.layers.27.attention.kvcache_mgr.value_past', 'model.layers.28.attention.kvcache_mgr.key_past', 'model.layers.28.attention.kvcache_mgr.value_past', 'model.layers.29.attention.kvcache_mgr.key_past', 'model.layers.29.attention.kvcache_mgr.value_past', 'model.layers.30.attention.kvcache_mgr.key_past', 'model.layers.30.attention.kvcache_mgr.value_past', 'model.layers.31.attention.kvcache_mgr.key_past', 'model.layers.31.attention.kvcache_mgr.value_past', 'model.layers.32.attention.kvcache_mgr.key_past', 'model.layers.32.attention.kvcache_mgr.value_past', 'model.layers.33.attention.kvcache_mgr.key_past', 'model.layers.33.attention.kvcache_mgr.value_past', 'model.layers.34.attention.kvcache_mgr.key_past', 'model.layers.34.attention.kvcache_mgr.value_past', 'model.layers.35.attention.kvcache_mgr.key_past', 'model.layers.35.attention.kvcache_mgr.value_past', 'model.layers.36.attention.kvcache_mgr.key_past', 'model.layers.36.attention.kvcache_mgr.value_past', 'model.layers.37.attention.kvcache_mgr.key_past', 'model.layers.37.attention.kvcache_mgr.value_past', 'model.layers.38.attention.kvcache_mgr.key_past', 'model.layers.38.attention.kvcache_mgr.value_past', 'model.layers.39.attention.kvcache_mgr.key_past', 'model.layers.39.attention.kvcache_mgr.value_past', 'model.layers.40.attention.kvcache_mgr.key_past', 'model.layers.40.attention.kvcache_mgr.value_past', 'model.layers.41.attention.kvcache_mgr.key_past', 'model.layers.41.attention.kvcache_mgr.value_past', 'model.layers.42.attention.kvcache_mgr.key_past', 'model.layers.42.attention.kvcache_mgr.value_past', 'model.layers.43.attention.kvcache_mgr.key_past', 'model.layers.43.attention.kvcache_mgr.value_past', 'model.layers.44.attention.kvcache_mgr.key_past', 'model.layers.44.attention.kvcache_mgr.value_past', 'model.layers.45.attention.kvcache_mgr.key_past', 'model.layers.45.attention.kvcache_mgr.value_past', 'model.layers.46.attention.kvcache_mgr.key_past', 'model.layers.46.attention.kvcache_mgr.value_past', 'model.layers.47.attention.kvcache_mgr.key_past', 'model.layers.47.attention.kvcache_mgr.value_past', 'model.layers.48.attention.kvcache_mgr.key_past', 'model.layers.48.attention.kvcache_mgr.value_past', 'model.layers.49.attention.kvcache_mgr.key_past', 'model.layers.49.attention.kvcache_mgr.value_past', 'model.layers.50.attention.kvcache_mgr.key_past', 'model.layers.50.attention.kvcache_mgr.value_past', 'model.layers.51.attention.kvcache_mgr.key_past', 'model.layers.51.attention.kvcache_mgr.value_past', 'model.layers.52.attention.kvcache_mgr.key_past', 'model.layers.52.attention.kvcache_mgr.value_past', 'model.layers.53.attention.kvcache_mgr.key_past', 'model.layers.53.attention.kvcache_mgr.value_past', 'model.layers.54.attention.kvcache_mgr.key_past', 'model.layers.54.attention.kvcache_mgr.value_past', 'model.layers.55.attention.kvcache_mgr.key_past', 'model.layers.55.attention.kvcache_mgr.value_past', 'model.layers.56.attention.kvcache_mgr.key_past', 'model.layers.56.attention.kvcache_mgr.value_past', 'model.layers.57.attention.kvcache_mgr.key_past', 'model.layers.57.attention.kvcache_mgr.value_past', 'model.layers.58.attention.kvcache_mgr.key_past', 'model.layers.58.attention.kvcache_mgr.value_past', 'model.layers.59.attention.kvcache_mgr.key_past', 'model.layers.59.attention.kvcache_mgr.value_past', 'model.layers.60.attention.kvcache_mgr.key_past', 'model.layers.60.attention.kvcache_mgr.value_past', 'model.layers.61.attention.kvcache_mgr.key_past', 'model.layers.61.attention.kvcache_mgr.value_past', 'model.layers.62.attention.kvcache_mgr.key_past', 'model.layers.62.attention.kvcache_mgr.value_past', 'model.layers.63.attention.kvcache_mgr.key_past', 'model.layers.63.attention.kvcache_mgr.value_past', 'model.layers.64.attention.kvcache_mgr.key_past', 'model.layers.64.attention.kvcache_mgr.value_past', 'model.layers.65.attention.kvcache_mgr.key_past', 'model.layers.65.attention.kvcache_mgr.value_past', 'model.layers.66.attention.kvcache_mgr.key_past', 'model.layers.66.attention.kvcache_mgr.value_past', 'model.layers.67.attention.kvcache_mgr.key_past', 'model.layers.67.attention.kvcache_mgr.value_past', 'model.layers.68.attention.kvcache_mgr.key_past', 'model.layers.68.attention.kvcache_mgr.value_past', 'model.layers.69.attention.kvcache_mgr.key_past', 'model.layers.69.attention.kvcache_mgr.value_past', 'model.layers.70.attention.kvcache_mgr.key_past', 'model.layers.70.attention.kvcache_mgr.value_past', 'model.layers.71.attention.kvcache_mgr.key_past', 'model.layers.71.attention.kvcache_mgr.value_past', 'model.layers.72.attention.kvcache_mgr.key_past', 'model.layers.72.attention.kvcache_mgr.value_past', 'model.layers.73.attention.kvcache_mgr.key_past', 'model.layers.73.attention.kvcache_mgr.value_past', 'model.layers.74.attention.kvcache_mgr.key_past', 'model.layers.74.attention.kvcache_mgr.value_past', 'model.layers.75.attention.kvcache_mgr.key_past', 'model.layers.75.attention.kvcache_mgr.value_past', 'model.layers.76.attention.kvcache_mgr.key_past', 'model.layers.76.attention.kvcache_mgr.value_past', 'model.layers.77.attention.kvcache_mgr.key_past', 'model.layers.77.attention.kvcache_mgr.value_past', 'model.layers.78.attention.kvcache_mgr.key_past', 'model.layers.78.attention.kvcache_mgr.value_past', 'model.layers.79.attention.kvcache_mgr.key_past', 'model.layers.79.attention.kvcache_mgr.value_past'], [])
{'auto_trans_ckpt': True,
 'callbacks': [OrderedDict([('type', 'MFLossMonitor')]),
               OrderedDict([('type', 'CheckpointMointor'),
                            ('prefix', 'qwen'),
                            ('save_checkpoint_steps', 10000),
                            ('keep_checkpoint_max', 1),
                            ('integrated_save', False),
                            ('async_save', False)]),
               OrderedDict([('type', 'ObsMonitor')])],
 'context': {'ascend_config': {'precision_mode': 'must_keep_origin_dtype'},
             'device_id': 0,
             'device_target': 'Ascend',
             'enable_graph_kernel': False,
             'graph_kernel_flags': '--disable_expand_ops=Softmax,Dropout '
                                   '--enable_parallel_fusion=true '
                                   '--reduce_fuse_depth=8 '
                                   '--enable_auto_tensor_inplace=true',
             'max_call_depth': 10000,
             'save_graphs': False,
             'save_graphs_path': './graph'},
 'device_num': 8,
 'load_checkpoint': './output/transformed_checkpoint',
 'local_rank': 0,
 'micro_batch_interleave_num': 1,
 'model': {'arch': {'type': 'LlamaForCausalLM'},
           'model_config': {'batch_size': 1,
                            'checkpoint_name_or_path': None,
                            'compute_dtype': 'float16',
                            'compute_in_2d': True,
                            'do_sample': False,
                            'emb_dropout_prob': 0.0,
                            'eos_token_id': 151643,
                            'hidden_size': 8192,
                            'intermediate_size': 24576,
                            'layernorm_compute_type': 'float32',
                            'max_decode_length': 512,
                            'num_heads': 64,
                            'num_layers': 80,
                            'offset': 0,
                            'pad_token_id': 151643,
                            'param_init_type': 'float16',
                            'qkv_has_bias': True,
                            'repetition_penalty': 1,
                            'rms_norm_eps': 1e-05,
                            'rotary_dtype': 'float16',
                            'seq_length': 8192,
                            'softmax_compute_type': 'float16',
                            'theta': 1000000.0,
                            'top_k': 0,
                            'top_p': 0.8,
                            'type': 'LlamaConfig',
                            'use_flash_attention': False,
                            'use_past': True,
                            'use_past_shard': False,
                            'vocab_size': 152064}},
 'moe_config': <mindformers.modules.transformer.moe.MoEConfig object at 0xfffecb0ad850>,
 'only_save_strategy': False,
 'output_dir': './output',
 'parallel': {'device_num': 8,
              'enable_alltoall': False,
              'enable_parallel_optimizer': True,
              'full_batch': True,
              'gradients_mean': False,
              'parallel_mode': 'semi_auto_parallel',
              'parallel_optimizer_config': {'gradient_accumulation_shard': False,
                                            'parallel_optimizer_threshold': 64},
              'search_mode': 'sharding_propagation',
              'strategy_ckpt_config': {'only_trainable_params': False,
                                       'save_file': './ckpt_strategy.ckpt'},
              'strategy_ckpt_save_file': './output/strategy/ckpt_strategy_rank_0_rank_0.ckpt'},
 'parallel_config': <mindformers.modules.transformer.transformer.TransformerOpParallelConfig object at 0xfffdc406beb0>,
 'processor': {'return_tensors': 'ms',
               'tokenizer': {'eos_token': '<|endoftext|>',
                             'merges_file': '/home/ma-user/work/mindformers/research/qwen1_5/72b/merges.txt',
                             'model_max_length': 32768,
                             'pad_token': '<|endoftext|>',
                             'type': 'Qwen2Tokenizer',
                             'unk_token': '<|endoftext|>',
                             'vocab_file': '/home/ma-user/work/mindformers/research/qwen1_5/72b/vocab.json'},
               'type': 'Qwen2Processor'},
 'rank_id': 0,
 'recompute_config': <mindformers.modules.transformer.transformer.TransformerRecomputeConfig object at 0xfffdc406b1c0>,
 'resume_training': False,
 'run_mode': 'predict',
 'runner_config': {'batch_size': 1,
                   'epochs': 5,
                   'gradient_accumulation_steps': 1,
                   'sink_mode': True,
                   'sink_size': 2},
 'runner_wrapper': {'scale_sense': {'loss_scale_value': 4294967296,
                                    'scale_factor': 2,
                                    'scale_window': 1000,
                                    'type': 'DynamicLossScaleUpdateCell'},
                    'type': 'MFTrainOneStepCell',
                    'use_clip_grad': True},
 'seed': 0,
 'src_strategy_path_or_dir': '',
 'trainer': {'model_name': 'qwen2_72b',
             'type': 'CausalLanguageModelingTrainer'},
 'use_parallel': True}
2024-06-19 10:54:58,908 - mindformers[mindformers/generation/text_generator.py:1099] - WARNING - When do_sample is set to False, top_k will be set to 1 and top_p will be set to 0, making them inactive.
2024-06-19 10:54:58,909 - mindformers[mindformers/generation/text_generator.py:1103] - INFO - Generation Config is: {'max_length': 8192, 'max_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1.0, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 151643, 'bos_token_id': 1, 'eos_token_id': 151643, '_from_model_config': True}
2024-06-19 10:54:58,909 - mindformers[mindformers/generation/text_generator.py:176] - INFO - The generation mode will be **GREEDY_SEARCH**.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.309 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 1 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.394 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 3 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.415 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 4 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.432 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 5 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.467 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 8 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.484 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 9 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.509 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 10 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:54:58.958.533 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 11 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:57:02.950.008 [mindspore/ccsrc/frontend/parallel/pass/pass_utils.cc:119] ExtractBackwardMatMul] backward_matmul_dx_dw_map size:0
|[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.290 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 1 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.367 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 3 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.383 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 4 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.398 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 5 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.425 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 8 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.441 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 9 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.457 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 10 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-10:59:28.819.474 [mindspore/ccsrc/frontend/parallel/step_parallel_utils.cc:1543] ExtendInputArgsAbstractShape] The input 11 is not a tensor.
[WARNING] PARALLEL(1693966,ffffb183c010,python):2024-06-19-11:02:00.232.448 [mindspore/ccsrc/frontend/parallel/pass/pass_utils.cc:119] ExtractBackwardMatMul] backward_matmul_dx_dw_map size:0
/2024-06-19 11:03:41,407 - mindformers[mindformers/generation/text_generator.py:478] - INFO - total time: 522.4972851276398 s; generated tokens: 393 tokens; generate speed: 0.7521570182015297 tokens/s
2024-06-19 11:03:41,455 - mindformers[mindformers/trainer/base_trainer.py:946] - INFO - output result is: [{'text_generation_text': ['帮助我制定一份去杭州的旅游攻略 好的，以下是一份为期三天的杭州旅游攻略，供你参考：\n\n**第一天：西湖区**\n\n- **上午：** 从杭州站或杭州东站出发，首先前往西湖景区。你可以乘坐公交车或地铁，也可以选择打车。西湖是杭州的标志性景点，包括苏堤春晓、曲院风荷、平湖秋月等十景，建议租一辆自行车慢慢游览。\n\n- **中午：** 在湖边的餐厅享用午餐，推荐尝试杭州特色菜如西湖醋鱼、龙井虾仁。\n\n- **下午：** 游览雷峰塔，然后前往花港观鱼，欣赏美丽的园林景色。\n\n- **晚上：** 在湖滨步行街散步，享受夜色，晚餐可以选择品尝杭州的小吃。\n\n**第二天：灵隐寺和西溪湿地**\n\n- **上午：** 前往灵隐寺，这是中国最著名的佛教寺庙之一，环境清幽，适合静心。\n\n- **中午：** 在寺庙附近的餐厅用餐，体验素食。\n\n- **下午：** 前往西溪湿地，乘船游览，欣赏湿地风光。\n\n- **晚上：** 返回市区，可以去南宋御街体验古街风情，晚餐选择一家有特色的餐厅。\n\n**第三天：宋城和河坊街**\n\n- **上午：** 前往宋城，观看大型实景演出《宋城千古情》，了解杭州的历史文化。\n\n- **中午：** 在宋城内的餐厅用餐。\n\n- **下午：** 游览河坊街，这里有许多传统工艺品店和小吃摊，可以购买一些纪念品。\n\n- **晚上：** 在河坊街享用晚餐，结束杭州之旅。\n\n以上只是一个基本的行程，你可以根据自己的兴趣和体力进行调整。记得提前预订酒店和演出票，以确保行程顺利。祝你旅途愉快！\n']}]
2024-06-19 11:03:41,455 - mindformers[mindformers/trainer/base_trainer.py:947] - INFO - output result is saved at: text_generation_result.txt
2024-06-19 11:03:41,456 - mindformers[mindformers/trainer/base_trainer.py:948] - INFO - .........Predict Over!.............
帮助我制定一份去杭州的旅游攻略 好的，以下是一份为期三天的杭州旅游攻略，供你参考：

**第一天：西湖区**

- **上午：** 从杭州站或杭州东站出发，首先前往西湖景区。你可以乘坐公交车或地铁，也可以选择打车。西湖是杭州的标志性景点，包括苏堤春晓、曲院风荷、平湖秋月等十景，建议租一辆自行车慢慢游览。

- **中午：** 在湖边的餐厅享用午餐，推荐尝试杭州特色菜如西湖醋鱼、龙井虾仁。

- **下午：** 游览雷峰塔，然后前往花港观鱼，欣赏美丽的园林景色。

- **晚上：** 在湖滨步行街散步，享受夜色，晚餐可以选择品尝杭州的小吃。

**第二天：灵隐寺和西溪湿地**

- **上午：** 前往灵隐寺，这是中国最著名的佛教寺庙之一，环境清幽，适合静心。

- **中午：** 在寺庙附近的餐厅用餐，体验素食。

- **下午：** 前往西溪湿地，乘船游览，欣赏湿地风光。

- **晚上：** 返回市区，可以去南宋御街体验古街风情，晚餐选择一家有特色的餐厅。

**第三天：宋城和河坊街**

- **上午：** 前往宋城，观看大型实景演出《宋城千古情》，了解杭州的历史文化。

- **中午：** 在宋城内的餐厅用餐。

- **下午：** 游览河坊街，这里有许多传统工艺品店和小吃摊，可以购买一些纪念品。

- **晚上：** 在河坊街享用晚餐，结束杭州之旅。

以上只是一个基本的行程，你可以根据自己的兴趣和体力进行调整。记得提前预订酒店和演出票，以确保行程顺利。祝你旅途愉快！

